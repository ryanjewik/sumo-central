eb021f2c8a8b
*** Found local files:
***   * /opt/airflow/logs/dag_id=sumo_data_pipeline/run_id=manual__2025-11-07T08:55:11.359292+00:00/task_id=run_new_matches_mongo/attempt=4.log
[2025-11-12T22:24:43.040+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sumo_data_pipeline.run_new_matches_mongo manual__2025-11-07T08:55:11.359292+00:00 [queued]>
[2025-11-12T22:24:43.050+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sumo_data_pipeline.run_new_matches_mongo manual__2025-11-07T08:55:11.359292+00:00 [queued]>
[2025-11-12T22:24:43.051+0000] {taskinstance.py:2170} INFO - Starting attempt 4 of 4
[2025-11-12T22:24:43.062+0000] {taskinstance.py:2191} INFO - Executing <Task(SparkSubmitOperator): run_new_matches_mongo> on 2025-11-07 08:55:11.359292+00:00
[2025-11-12T22:24:43.068+0000] {standard_task_runner.py:60} INFO - Started process 3878 to run task
[2025-11-12T22:24:43.071+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'sumo_data_pipeline', 'run_new_matches_mongo', 'manual__2025-11-07T08:55:11.359292+00:00', '--job-id', '136', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp4o3h4z3g']
[2025-11-12T22:24:43.074+0000] {standard_task_runner.py:88} INFO - Job 136: Subtask run_new_matches_mongo
[2025-11-12T22:24:43.169+0000] {task_command.py:423} INFO - Running <TaskInstance: sumo_data_pipeline.run_new_matches_mongo manual__2025-11-07T08:55:11.359292+00:00 [running]> on host eb021f2c8a8b
[2025-11-12T22:24:43.370+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='sumo_data_pipeline' AIRFLOW_CTX_TASK_ID='run_new_matches_mongo' AIRFLOW_CTX_EXECUTION_DATE='2025-11-07T08:55:11.359292+00:00' AIRFLOW_CTX_TRY_NUMBER='4' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-11-07T08:55:11.359292+00:00'
[2025-11-12T22:24:43.381+0000] {base.py:83} INFO - Using connection ID 'spark_default' for task execution.
[2025-11-12T22:24:43.385+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.pyspark.python=python3 --conf spark.executorEnv.PYSPARK_PYTHON=python3 --conf spark.pyspark.driver.python=python3 --conf spark.executorEnv.MONGO_URI=mongodb+srv://sumo-***:ILoveFumi%21@sumo.jrywipx.mongodb.net/sumo --conf spark.executorEnv.MONGO_DB_NAME=sumo --conf spark.executorEnv.MONGO_COLL_NAME=homepage --conf spark.driverEnv.MONGO_URI=mongodb+srv://sumo-***:ILoveFumi%21@sumo.jrywipx.mongodb.net/sumo --conf spark.driverEnv.MONGO_DB_NAME=sumo --conf spark.driverEnv.MONGO_COLL_NAME=homepage --conf spark.executor.instances=1 --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain --conf spark.executorEnv.AWS_REGION=us-west-2 --conf spark.executorEnv.AWS_ACCESS_KEY_ID=AKIAQXPZDDBLZGNPBDZR --conf spark.executorEnv.AWS_SECRET_ACCESS_KEY=****** --jars /opt/spark/jars/hadoop-aws-3.3.4.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark /opt/airflow/jobs/spark_mongoNewMatches.py "{\"payload\": [{\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 39, \"eastRank\": \"Maegashira 17 East\", \"eastShikona\": \"Chiyoshoma\", \"id\": \"202511-2-0-39-82\", \"kimarite\": \"\", \"matchNo\": 1, \"westId\": 82, \"westRank\": \"Juryo 1 West\", \"westShikona\": \"Fujiseiun\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 95, \"eastRank\": \"Maegashira 16 East\", \"eastShikona\": \"Oshoumi\", \"id\": \"202511-2-1-95-164\", \"kimarite\": \"\", \"matchNo\": 2, \"westId\": 164, \"westRank\": \"Maegashira 17 West\", \"westShikona\": \"Asakoryu\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 35, \"eastRank\": \"Maegashira 16 West\", \"eastShikona\": \"Sadanoumi\", \"id\": \"202511-2-2-35-49\", \"kimarite\": \"\", \"matchNo\": 3, \"westId\": 49, \"westRank\": \"Maegashira 15 West\", \"westShikona\": \"Shonannoumi\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 15, \"eastRank\": \"Maegashira 14 East\", \"eastShikona\": \"Ryuden\", \"id\": \"202511-2-3-15-40\", \"kimarite\": \"\", \"matchNo\": 4, \"westId\": 40, \"westRank\": \"Maegashira 15 East\", \"westShikona\": \"Nishikifuji\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 83, \"eastRank\": \"Maegashira 14 West\", \"eastShikona\": \"Tokihayate\", \"id\": \"202511-2-4-83-26\", \"kimarite\": \"\", \"matchNo\": 5, \"westId\": 26, \"westRank\": \"Maegashira 13 West\", \"westShikona\": \"Mitakeumi\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 615, \"eastRank\": \"Maegashira 12 East\", \"eastShikona\": \"Fujinokawa\", \"id\": \"202511-2-5-615-56\", \"kimarite\": \"\", \"matchNo\": 6, \"westId\": 56, \"westRank\": \"Maegashira 13 East\", \"westShikona\": \"Gonoyama\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 102, \"eastRank\": \"Maegashira 12 West\", \"eastShikona\": \"Tomokaze\", \"id\": \"202511-2-6-102-55\", \"kimarite\": \"\", \"matchNo\": 7, \"westId\": 55, \"westRank\": \"Maegashira 11 West\", \"westShikona\": \"Roga\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 9, \"eastRank\": \"Maegashira 10 East\", \"eastShikona\": \"Daieisho\", \"id\": \"202511-2-7-9-8\", \"kimarite\": \"\", \"matchNo\": 8, \"westId\": 8, \"westRank\": \"Maegashira 10 West\", \"westShikona\": \"Kotoshoho\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 86, \"eastRank\": \"Maegashira 11 East\", \"eastShikona\": \"Shishi\", \"id\": \"202511-2-8-86-21\", \"kimarite\": \"\", \"matchNo\": 9, \"westId\": 21, \"westRank\": \"Maegashira 9 West\", \"westShikona\": \"Tobizaru\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 11, \"eastRank\": \"Maegashira 8 East\", \"eastShikona\": \"Ichiyamamoto\", \"id\": \"202511-2-9-11-34\", \"kimarite\": \"\", \"matchNo\": 10, \"westId\": 34, \"westRank\": \"Maegashira 9 East\", \"westShikona\": \"Midorifuji\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 50, \"eastRank\": \"Maegashira 8 West\", \"eastShikona\": \"Kinbozan\", \"id\": \"202511-2-10-50-22\", \"kimarite\": \"\", \"matchNo\": 11, \"westId\": 22, \"westRank\": \"Maegashira 7 West\", \"westShikona\": \"Abi\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 74, \"eastRank\": \"Maegashira 6 East\", \"eastShikona\": \"Atamifuji\", \"id\": \"202511-2-11-74-71\", \"kimarite\": \"\", \"matchNo\": 12, \"westId\": 71, \"westRank\": \"Maegashira 7 East\", \"westShikona\": \"Churanoumi\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 8853, \"eastRank\": \"Maegashira 6 West\", \"eastShikona\": \"Onokatsu\", \"id\": \"202511-2-12-8853-33\", \"kimarite\": \"\", \"matchNo\": 13, \"westId\": 33, \"westRank\": \"Maegashira 5 West\", \"westShikona\": \"Shodai\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 14, \"eastRank\": \"Maegashira 4 East\", \"eastShikona\": \"Tamawashi\", \"id\": \"202511-2-13-14-8857\", \"kimarite\": \"\", \"matchNo\": 14, \"westId\": 8857, \"westRank\": \"Maegashira 5 East\", \"westShikona\": \"Yoshinofuji\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 61, \"eastRank\": \"Maegashira 4 West\", \"eastShikona\": \"Oshoma\", \"id\": \"202511-2-14-61-28\", \"kimarite\": \"\", \"matchNo\": 15, \"westId\": 28, \"westRank\": \"Maegashira 3 West\", \"westShikona\": \"Ura\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 24, \"eastRank\": \"Maegashira 3 East\", \"eastShikona\": \"Hiradoumi\", \"id\": \"202511-2-15-24-44\", \"kimarite\": \"\", \"matchNo\": 16, \"westId\": 44, \"westRank\": \"Komusubi 1 West\", \"westShikona\": \"Takayasu\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 8854, \"eastRank\": \"Sekiwake 1 East\", \"eastShikona\": \"Aonishiki\", \"id\": \"202511-2-16-8854-13\", \"kimarite\": \"\", \"matchNo\": 17, \"westId\": 13, \"westRank\": \"Maegashira 2 West\", \"westShikona\": \"Wakamotoharu\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 12, \"eastRank\": \"Maegashira 1 West\", \"eastShikona\": \"Wakatakakage\", \"id\": \"202511-2-17-12-41\", \"kimarite\": \"\", \"matchNo\": 18, \"westId\": 41, \"westRank\": \"Sekiwake 1 West\", \"westShikona\": \"Oho\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 20, \"eastRank\": \"Ozeki 1 East\", \"eastShikona\": \"Kotozakura\", \"id\": \"202511-2-18-20-7\", \"kimarite\": \"\", \"matchNo\": 19, \"westId\": 7, \"westRank\": \"Maegashira 2 East\", \"westShikona\": \"Kirishima\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 8850, \"eastRank\": \"Yokozuna 1 East\", \"eastShikona\": \"Onosato\", \"id\": \"202511-2-19-8850-3\", \"kimarite\": \"\", \"matchNo\": 20, \"westId\": 3, \"westRank\": \"Maegashira 1 East\", \"westShikona\": \"Hakuoho\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 37, \"eastRank\": \"Komusubi 1 East\", \"eastShikona\": \"Takanosho\", \"id\": \"202511-2-20-37-19\", \"kimarite\": \"\", \"matchNo\": 21, \"westId\": 19, \"westRank\": \"Yokozuna 1 West\", \"westShikona\": \"Hoshoryu\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}], \"type\": \"newMatches\"}"
[2025-11-12T22:24:44.601+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-11-12T22:24:44.651+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-11-12T22:24:44.652+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-11-12T22:24:44.655+0000] {spark_submit.py:571} INFO - org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency
[2025-11-12T22:24:44.655+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-91fb87c8-ce68-4377-902c-4bed234a509c;1.0
[2025-11-12T22:24:44.656+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-11-12T22:24:44.737+0000] {spark_submit.py:571} INFO - found org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central
[2025-11-12T22:24:44.757+0000] {spark_submit.py:571} INFO - found org.mongodb#mongodb-driver-sync;4.0.5 in central
[2025-11-12T22:24:44.773+0000] {spark_submit.py:571} INFO - found org.mongodb#bson;4.0.5 in central
[2025-11-12T22:24:44.790+0000] {spark_submit.py:571} INFO - found org.mongodb#mongodb-driver-core;4.0.5 in central
[2025-11-12T22:24:44.810+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 149ms :: artifacts dl 5ms
[2025-11-12T22:24:44.810+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-11-12T22:24:44.811+0000] {spark_submit.py:571} INFO - org.mongodb#bson;4.0.5 from central in [default]
[2025-11-12T22:24:44.811+0000] {spark_submit.py:571} INFO - org.mongodb#mongodb-driver-core;4.0.5 from central in [default]
[2025-11-12T22:24:44.812+0000] {spark_submit.py:571} INFO - org.mongodb#mongodb-driver-sync;4.0.5 from central in [default]
[2025-11-12T22:24:44.812+0000] {spark_submit.py:571} INFO - org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]
[2025-11-12T22:24:44.812+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-11-12T22:24:44.812+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-11-12T22:24:44.813+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-11-12T22:24:44.813+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-11-12T22:24:44.813+0000] {spark_submit.py:571} INFO - |      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
[2025-11-12T22:24:44.813+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-11-12T22:24:44.814+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-91fb87c8-ce68-4377-902c-4bed234a509c
[2025-11-12T22:24:44.814+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-11-12T22:24:44.818+0000] {spark_submit.py:571} INFO - 0 artifacts copied, 4 already retrieved (0kB/5ms)
[2025-11-12T22:24:44.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-11-12T22:24:45.629+0000] {spark_submit.py:571} INFO - [spark_mongoNewMatches] raw arg: "{\"payload\": [{\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 39, \"eastRank\": \"Maegashira 17 East\", \"eastShikona\": \"Chiyoshoma\", \"id\": \"202511-2-0-39-82\", \"kimarite\": \"\", \"matchNo\": 1, \"westId\": 82, \"westRank\": \"Juryo 1 West\", \"westShikona\":  ...
[2025-11-12T22:24:45.698+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO SparkContext: Running Spark version 3.5.2
[2025-11-12T22:24:45.698+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
[2025-11-12T22:24:45.699+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO SparkContext: Java version 17.0.17
[2025-11-12T22:24:45.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO ResourceUtils: ==============================================================
[2025-11-12T22:24:45.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-11-12T22:24:45.715+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO ResourceUtils: ==============================================================
[2025-11-12T22:24:45.715+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO SparkContext: Submitted application: spark_mongoNewMatches
[2025-11-12T22:24:45.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-11-12T22:24:45.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-11-12T22:24:45.739+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-11-12T22:24:45.791+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO SecurityManager: Changing view acls to: airflow
[2025-11-12T22:24:45.791+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO SecurityManager: Changing modify acls to: airflow
[2025-11-12T22:24:45.792+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO SecurityManager: Changing view acls groups to:
[2025-11-12T22:24:45.792+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO SecurityManager: Changing modify acls groups to:
[2025-11-12T22:24:45.792+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY
[2025-11-12T22:24:45.960+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO Utils: Successfully started service 'sparkDriver' on port 38347.
[2025-11-12T22:24:45.978+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:45 INFO SparkEnv: Registering MapOutputTracker
[2025-11-12T22:24:46.008+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkEnv: Registering BlockManagerMaster
[2025-11-12T22:24:46.020+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-11-12T22:24:46.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-11-12T22:24:46.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-11-12T22:24:46.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fe0dcd7d-dbf8-4d68-9f14-44eaf5be5806
[2025-11-12T22:24:46.050+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-11-12T22:24:46.061+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-11-12T22:24:46.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-11-12T22:24:46.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-11-12T22:24:46.219+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkContext: Added JAR file:///opt/spark/jars/hadoop-aws-3.3.4.jar at spark://eb021f2c8a8b:38347/jars/hadoop-aws-3.3.4.jar with timestamp 1762986285692
[2025-11-12T22:24:46.219+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkContext: Added JAR file:///opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar at spark://eb021f2c8a8b:38347/jars/aws-java-sdk-bundle-1.12.262.jar with timestamp 1762986285692
[2025-11-12T22:24:46.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar at spark://eb021f2c8a8b:38347/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1762986285692
[2025-11-12T22:24:46.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar at spark://eb021f2c8a8b:38347/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1762986285692
[2025-11-12T22:24:46.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.mongodb_bson-4.0.5.jar at spark://eb021f2c8a8b:38347/jars/org.mongodb_bson-4.0.5.jar with timestamp 1762986285692
[2025-11-12T22:24:46.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar at spark://eb021f2c8a8b:38347/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1762986285692
[2025-11-12T22:24:46.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar at spark://eb021f2c8a8b:38347/files/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1762986285692
[2025-11-12T22:24:46.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO Utils: Copying /home/airflow/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar to /tmp/spark-48be39f9-d8f5-4664-835c-5ec646c6eba7/userFiles-1bf59594-2761-4a3e-ba57-2e5b9e869480/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar
[2025-11-12T22:24:46.235+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar at spark://eb021f2c8a8b:38347/files/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1762986285692
[2025-11-12T22:24:46.235+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO Utils: Copying /home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar to /tmp/spark-48be39f9-d8f5-4664-835c-5ec646c6eba7/userFiles-1bf59594-2761-4a3e-ba57-2e5b9e869480/org.mongodb_mongodb-driver-sync-4.0.5.jar
[2025-11-12T22:24:46.241+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.mongodb_bson-4.0.5.jar at spark://eb021f2c8a8b:38347/files/org.mongodb_bson-4.0.5.jar with timestamp 1762986285692
[2025-11-12T22:24:46.242+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO Utils: Copying /home/airflow/.ivy2/jars/org.mongodb_bson-4.0.5.jar to /tmp/spark-48be39f9-d8f5-4664-835c-5ec646c6eba7/userFiles-1bf59594-2761-4a3e-ba57-2e5b9e869480/org.mongodb_bson-4.0.5.jar
[2025-11-12T22:24:46.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar at spark://eb021f2c8a8b:38347/files/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1762986285692
[2025-11-12T22:24:46.249+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO Utils: Copying /home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar to /tmp/spark-48be39f9-d8f5-4664-835c-5ec646c6eba7/userFiles-1bf59594-2761-4a3e-ba57-2e5b9e869480/org.mongodb_mongodb-driver-core-4.0.5.jar
[2025-11-12T22:24:46.304+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-11-12T22:24:46.334+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 17 ms (0 ms spent in bootstraps)
[2025-11-12T22:24:46.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251112222446-0008
[2025-11-12T22:24:46.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251112222446-0008/0 on worker-20251112212940-172.18.0.5-43185 (172.18.0.5:43185) with 1 core(s)
[2025-11-12T22:24:46.439+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20251112222446-0008/0 on hostPort 172.18.0.5:43185 with 1 core(s), 1024.0 MiB RAM
[2025-11-12T22:24:46.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251112222446-0008/1 on worker-20251112212940-172.18.0.5-43185 (172.18.0.5:43185) with 1 core(s)
[2025-11-12T22:24:46.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20251112222446-0008/1 on hostPort 172.18.0.5:43185 with 1 core(s), 1024.0 MiB RAM
[2025-11-12T22:24:46.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40023.
[2025-11-12T22:24:46.444+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO NettyBlockTransferService: Server created on eb021f2c8a8b:40023
[2025-11-12T22:24:46.447+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-11-12T22:24:46.458+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, eb021f2c8a8b, 40023, None)
[2025-11-12T22:24:46.462+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO BlockManagerMasterEndpoint: Registering block manager eb021f2c8a8b:40023 with 434.4 MiB RAM, BlockManagerId(driver, eb021f2c8a8b, 40023, None)
[2025-11-12T22:24:46.464+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, eb021f2c8a8b, 40023, None)
[2025-11-12T22:24:46.467+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, eb021f2c8a8b, 40023, None)
[2025-11-12T22:24:46.471+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251112222446-0008/0 is now RUNNING
[2025-11-12T22:24:46.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251112222446-0008/1 is now RUNNING
[2025-11-12T22:24:46.737+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:46 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-11-12T22:24:47.309+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:47 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-11-12T22:24:47.312+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:47 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-11-12T22:24:48.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:48 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:50960) with ID 0,  ResourceProfileId 0
[2025-11-12T22:24:48.780+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:48 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:50962) with ID 1,  ResourceProfileId 0
[2025-11-12T22:24:48.804+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:48 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:42325 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.5, 42325, None)
[2025-11-12T22:24:48.834+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:48 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:43045 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.5, 43045, None)
[2025-11-12T22:24:49.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO CodeGenerator: Code generated in 164.983479 ms
[2025-11-12T22:24:49.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO DAGScheduler: Registering RDD 6 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-11-12T22:24:49.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:24:49.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:24:49.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:24:49.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:24:49.712+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:24:49.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 16.7 KiB, free 434.4 MiB)
[2025-11-12T22:24:49.827+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.4 MiB)
[2025-11-12T22:24:49.830+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on eb021f2c8a8b:40023 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:24:49.833+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:24:49.844+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:24:49.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
[2025-11-12T22:24:50.289+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 11355 bytes)
[2025-11-12T22:24:50.320+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11479 bytes)
[2025-11-12T22:24:51.020+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:42325 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:24:51.020+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:43045 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:24:51.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1706 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:24:51.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1665 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:24:51.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-11-12T22:24:51.988+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 51563
[2025-11-12T22:24:51.992+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 2.271 s
[2025-11-12T22:24:51.992+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:24:51.992+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO DAGScheduler: running: Set()
[2025-11-12T22:24:51.992+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:24:51.993+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:51 INFO DAGScheduler: failed: Set()
[2025-11-12T22:24:52.022+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO CodeGenerator: Code generated in 9.882936 ms
[2025-11-12T22:24:52.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-12T22:24:52.042+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:24:52.042+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:24:52.043+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-11-12T22:24:52.043+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:24:52.044+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[9] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:24:52.050+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.5 KiB, free 434.4 MiB)
[2025-11-12T22:24:52.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.4 MiB)
[2025-11-12T22:24:52.057+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on eb021f2c8a8b:40023 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.057+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:24:52.059+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:24:52.059+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-11-12T22:24:52.063+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:24:52.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.5:42325 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.133+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.5:50960
[2025-11-12T22:24:52.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on eb021f2c8a8b:40023 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.162+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.5:42325 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.163+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.5:43045 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.242+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 180 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:24:52.242+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-11-12T22:24:52.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.193 s
[2025-11-12T22:24:52.244+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:24:52.244+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-11-12T22:24:52.245+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.205950 s
[2025-11-12T22:24:52.252+0000] {spark_submit.py:571} INFO - Loaded 21 matches from webhook payload.
[2025-11-12T22:24:52.363+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO CodeGenerator: Code generated in 10.665971 ms
[2025-11-12T22:24:52.369+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO SparkContext: Starting job: collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102
[2025-11-12T22:24:52.370+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Got job 2 (collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102) with 1 output partitions
[2025-11-12T22:24:52.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Final stage: ResultStage 3 (collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102)
[2025-11-12T22:24:52.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:24:52.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:24:52.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102), which has no missing parents
[2025-11-12T22:24:52.374+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.5 KiB, free 434.4 MiB)
[2025-11-12T22:24:52.376+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 434.4 MiB)
[2025-11-12T22:24:52.378+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on eb021f2c8a8b:40023 (size: 7.1 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.379+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:24:52.379+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:24:52.380+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-11-12T22:24:52.381+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 11366 bytes)
[2025-11-12T22:24:52.396+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:42325 (size: 7.1 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.458+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 78 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:24:52.459+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-11-12T22:24:52.460+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: ResultStage 3 (collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102) finished in 0.087 s
[2025-11-12T22:24:52.460+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:24:52.460+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-11-12T22:24:52.461+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO DAGScheduler: Job 2 finished: collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102, took 0.090804 s
[2025-11-12T22:24:52.480+0000] {spark_submit.py:571} INFO - passing basho id for join: 202511
[2025-11-12T22:24:52.504+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on eb021f2c8a8b:40023 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.507+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.5:42325 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.513+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on eb021f2c8a8b:40023 in memory (size: 7.1 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.518+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:42325 in memory (size: 7.1 KiB, free: 434.4 MiB)
[2025-11-12T22:24:52.654+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 264.0 B, free 434.4 MiB)
[2025-11-12T22:24:52.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 467.0 B, free 434.4 MiB)
[2025-11-12T22:24:52.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on eb021f2c8a8b:40023 (size: 467.0 B, free: 434.4 MiB)
[2025-11-12T22:24:52.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO SparkContext: Created broadcast 3 from broadcast at MongoSpark.scala:530
[2025-11-12T22:24:52.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO cluster: Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=sumo.jrywipx.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='atlas-efvaxv-shard-0'}
[2025-11-12T22:24:52.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO MongoClientCache: Creating MongoClient: []
[2025-11-12T22:24:52.711+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO cluster: Cluster description not yet available. Waiting for 30000 ms before timing out
[2025-11-12T22:24:52.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:24:52.757+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:24:52.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:24:52.761+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:52 INFO cluster: No server chosen by com.mongodb.client.internal.MongoClientDelegate$1@351c42b7 from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 30000 ms before timing out
[2025-11-12T22:24:53.307+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO connection: Opened connection [connectionId{localValue:1, serverValue:99372}] to ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017
[2025-11-12T22:24:53.308+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO connection: Opened connection [connectionId{localValue:2, serverValue:108844}] to ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017
[2025-11-12T22:24:53.308+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO connection: Opened connection [connectionId{localValue:3, serverValue:102302}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:24:53.355+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=45867224, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az3'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff0000000000000045, setVersion=7, lastWriteDate=Wed Nov 12 22:24:53 UTC 2025, lastUpdateTimeNanos=7214777929527}
[2025-11-12T22:24:53.356+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=46027331, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az1'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:24:53 UTC 2025, lastUpdateTimeNanos=7214777929527}
[2025-11-12T22:24:53.357+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO cluster: Setting max election id to 7fffffff0000000000000045 from replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:24:53.357+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO cluster: Setting max set version to 7 from replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:24:53.358+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO cluster: Discovered replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:24:53.366+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=57854352, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:24:53 UTC 2025, lastUpdateTimeNanos=7214789364032}
[2025-11-12T22:24:53.667+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO connection: Opened connection [connectionId{localValue:4, serverValue:102333}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:24:53.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO SparkContext: Starting job: treeAggregate at MongoInferSchema.scala:88
[2025-11-12T22:24:53.757+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO DAGScheduler: Got job 3 (treeAggregate at MongoInferSchema.scala:88) with 1 output partitions
[2025-11-12T22:24:53.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO DAGScheduler: Final stage: ResultStage 4 (treeAggregate at MongoInferSchema.scala:88)
[2025-11-12T22:24:53.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:24:53.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:24:53.759+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at treeAggregate at MongoInferSchema.scala:88), which has no missing parents
[2025-11-12T22:24:53.760+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.2 KiB, free 434.4 MiB)
[2025-11-12T22:24:53.766+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.4 MiB)
[2025-11-12T22:24:53.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on eb021f2c8a8b:40023 (size: 4.2 KiB, free: 434.4 MiB)
[2025-11-12T22:24:53.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:24:53.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at treeAggregate at MongoInferSchema.scala:88) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:24:53.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-11-12T22:24:53.771+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.5, executor 0, partition 0, ANY, 10290 bytes)
[2025-11-12T22:24:53.803+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.5:42325 (size: 4.2 KiB, free: 434.4 MiB)
[2025-11-12T22:24:53.842+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:53 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:42325 (size: 467.0 B, free: 434.4 MiB)
[2025-11-12T22:24:54.809+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:54 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 1039 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:24:54.809+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:54 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-11-12T22:24:54.810+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:54 INFO DAGScheduler: ResultStage 4 (treeAggregate at MongoInferSchema.scala:88) finished in 1.051 s
[2025-11-12T22:24:54.810+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:54 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:24:54.810+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2025-11-12T22:24:54.810+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:54 INFO DAGScheduler: Job 3 finished: treeAggregate at MongoInferSchema.scala:88, took 1.054009 s
[2025-11-12T22:24:54.817+0000] {spark_submit.py:571} INFO - successfully loaded basho_pages for join
[2025-11-12T22:24:54.865+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:54 INFO CodeGenerator: Code generated in 4.820612 ms
[2025-11-12T22:24:55.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:24:55.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:24:55.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:24:55.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:24:55.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:24:55.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:24:55.125+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KiB, free 434.4 MiB)
[2025-11-12T22:24:55.130+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 434.4 MiB)
[2025-11-12T22:24:55.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO BlockManagerInfo: Removed broadcast_4_piece0 on eb021f2c8a8b:40023 in memory (size: 4.2 KiB, free: 434.4 MiB)
[2025-11-12T22:24:55.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on eb021f2c8a8b:40023 (size: 5.6 KiB, free: 434.4 MiB)
[2025-11-12T22:24:55.133+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:24:55.133+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:24:55.134+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-11-12T22:24:55.134+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.5:42325 in memory (size: 4.2 KiB, free: 434.4 MiB)
[2025-11-12T22:24:55.135+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.5, executor 0, partition 0, ANY, 10290 bytes)
[2025-11-12T22:24:55.147+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:42325 (size: 5.6 KiB, free: 434.4 MiB)
[2025-11-12T22:24:55.247+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 113 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:24:55.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-11-12T22:24:55.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0) finished in 0.124 s
[2025-11-12T22:24:55.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:24:55.249+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-11-12T22:24:55.249+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 0.126895 s
[2025-11-12T22:24:55.251+0000] {spark_submit.py:571} INFO - ++
[2025-11-12T22:24:55.252+0000] {spark_submit.py:571} INFO - ||
[2025-11-12T22:24:55.252+0000] {spark_submit.py:571} INFO - ++
[2025-11-12T22:24:55.253+0000] {spark_submit.py:571} INFO - 
[2025-11-12T22:24:55.253+0000] {spark_submit.py:571} INFO - None
[2025-11-12T22:24:55.431+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181
[2025-11-12T22:24:55.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Got job 5 (runJob at PythonRDD.scala:181) with 1 output partitions
[2025-11-12T22:24:55.433+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Final stage: ResultStage 6 (runJob at PythonRDD.scala:181)
[2025-11-12T22:24:55.433+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:24:55.433+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:24:55.433+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Submitting ResultStage 6 (PythonRDD[29] at RDD at PythonRDD.scala:53), which has no missing parents
[2025-11-12T22:24:55.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 21.0 KiB, free 434.4 MiB)
[2025-11-12T22:24:55.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.7 KiB, free 434.4 MiB)
[2025-11-12T22:24:55.442+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on eb021f2c8a8b:40023 (size: 9.7 KiB, free: 434.4 MiB)
[2025-11-12T22:24:55.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO BlockManagerInfo: Removed broadcast_5_piece0 on eb021f2c8a8b:40023 in memory (size: 5.6 KiB, free: 434.4 MiB)
[2025-11-12T22:24:55.444+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:24:55.444+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (PythonRDD[29] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:24:55.445+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-11-12T22:24:55.445+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (172.18.0.5, executor 0, partition 0, ANY, 10290 bytes)
[2025-11-12T22:24:55.446+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.5:42325 in memory (size: 5.6 KiB, free: 434.4 MiB)
[2025-11-12T22:24:55.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:42325 (size: 9.7 KiB, free: 434.4 MiB)
[2025-11-12T22:24:55.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 158 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:24:55.604+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-11-12T22:24:55.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: ResultStage 6 (runJob at PythonRDD.scala:181) finished in 0.170 s
[2025-11-12T22:24:55.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:24:55.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
[2025-11-12T22:24:55.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:55 INFO DAGScheduler: Job 5 finished: runJob at PythonRDD.scala:181, took 0.173370 s
[2025-11-12T22:24:57.948+0000] {spark_submit.py:571} INFO - [[34m2025-11-12T22:24:57.947+0000[0m] {[34mcrypto.py:[0m82} WARNING[0m - empty cryptography key - values will not be stored encrypted.[0m
[2025-11-12T22:24:57.948+0000] {spark_submit.py:571} INFO - [[34m2025-11-12T22:24:57.948+0000[0m] {[34mbase.py:[0m83} INFO[0m - Using connection ID 'sumo_db' for task execution.[0m
[2025-11-12T22:24:58.018+0000] {spark_submit.py:571} INFO - Inserted initial basho_pages document for id=202511
[2025-11-12T22:24:58.146+0000] {spark_submit.py:571} INFO - Appended 21 upcoming match(es) to homepage document
[2025-11-12T22:24:58.319+0000] {spark_submit.py:571} INFO - failed to join basho start dates: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column or function parameter with name `basho`.`start_date` cannot be resolved. ;
[2025-11-12T22:24:58.320+0000] {spark_submit.py:571} INFO - 'Project ['basho.start_date AS basho_start_date#52, cast('id as bigint) AS basho_id_int#53, cast('id as string) AS basho_id_str#54]
[2025-11-12T22:24:58.320+0000] {spark_submit.py:571} INFO - +- Relation [] MongoRelation(MongoRDD[12] at RDD at MongoRDD.scala:51,Some(StructType()))
[2025-11-12T22:24:58.320+0000] {spark_submit.py:571} INFO - 
[2025-11-12T22:24:58.342+0000] {spark_submit.py:571} INFO - failed to compute match_date: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `basho_start_date` cannot be resolved. Did you mean one of the following? [`bashoId`, `eastId`, `kimarite`, `westId`, `day`].;
[2025-11-12T22:24:58.343+0000] {spark_submit.py:571} INFO - 'Project [bashoId#0, day#1L, division#2, eastId#3L, eastRank#4, eastShikona#5, id#6, kimarite#7, matchNo#8L, westId#9L, westRank#10, westShikona#11, winnerEn#12, winnerId#13L, winnerJp#14, to_date('basho_start_date, None, Some(Etc/UTC), false) AS basho_start_date#55]
[2025-11-12T22:24:58.343+0000] {spark_submit.py:571} INFO - +- LogicalRDD [bashoId#0, day#1L, division#2, eastId#3L, eastRank#4, eastShikona#5, id#6, kimarite#7, matchNo#8L, westId#9L, westRank#10, westShikona#11, winnerEn#12, winnerId#13L, winnerJp#14], false
[2025-11-12T22:24:58.343+0000] {spark_submit.py:571} INFO - 
[2025-11-12T22:24:58.750+0000] {spark_submit.py:571} INFO - Reading cleaned snapshots from s3a://ryans-sumo-bucket/gold/cleaned_data/
[2025-11-12T22:24:58.819+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:58 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-11-12T22:24:58.826+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:58 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-11-12T22:24:58.827+0000] {spark_submit.py:571} INFO - 25/11/12 22:24:58 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-11-12T22:25:00.064+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO BlockManagerInfo: Removed broadcast_6_piece0 on eb021f2c8a8b:40023 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-11-12T22:25:00.067+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.5:42325 in memory (size: 9.7 KiB, free: 434.4 MiB)
[2025-11-12T22:25:00.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO InMemoryFileIndex: It took 103 ms to list leaf files for 1 paths.
[2025-11-12T22:25:00.205+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:00.206+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO DAGScheduler: Got job 6 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:25:00.206+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO DAGScheduler: Final stage: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:00.207+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:00.207+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:00.207+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[31] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:00.213+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 108.5 KiB, free 434.3 MiB)
[2025-11-12T22:25:00.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 39.7 KiB, free 434.3 MiB)
[2025-11-12T22:25:00.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on eb021f2c8a8b:40023 (size: 39.7 KiB, free: 434.4 MiB)
[2025-11-12T22:25:00.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:00.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[31] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:25:00.229+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
[2025-11-12T22:25:00.229+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10300 bytes)
[2025-11-12T22:25:00.245+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:42325 (size: 39.7 KiB, free: 434.4 MiB)
[2025-11-12T22:25:00.444+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO MongoClientCache: Closing MongoClient: [ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017,ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017,ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017]
[2025-11-12T22:25:00.505+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:00 INFO connection: Closed connection [connectionId{localValue:4, serverValue:102333}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017 because the pool has been closed.
[2025-11-12T22:25:01.533+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 1307 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:25:01.534+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-11-12T22:25:01.534+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO DAGScheduler: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.327 s
[2025-11-12T22:25:01.534+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:25:01.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-11-12T22:25:01.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO DAGScheduler: Job 6 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.329563 s
[2025-11-12T22:25:01.563+0000] {spark_submit.py:571} INFO - Preview of cleaned_data (main_all):
[2025-11-12T22:25:01.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:01.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:01.674+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2025-11-12T22:25:01.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO CodeGenerator: Code generated in 95.127015 ms
[2025-11-12T22:25:01.850+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 230.1 KiB, free 434.0 MiB)
[2025-11-12T22:25:01.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO BlockManagerInfo: Removed broadcast_7_piece0 on eb021f2c8a8b:40023 in memory (size: 39.7 KiB, free: 434.4 MiB)
[2025-11-12T22:25:01.860+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 38.7 KiB, free 434.1 MiB)
[2025-11-12T22:25:01.861+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.5:42325 in memory (size: 39.7 KiB, free: 434.4 MiB)
[2025-11-12T22:25:01.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on eb021f2c8a8b:40023 (size: 38.7 KiB, free: 434.4 MiB)
[2025-11-12T22:25:01.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO SparkContext: Created broadcast 8 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:01.871+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:25:01.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:01.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:25:01.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO DAGScheduler: Final stage: ResultStage 8 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:01.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:01.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:01.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:01.904+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 61.5 KiB, free 434.1 MiB)
[2025-11-12T22:25:01.907+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 434.1 MiB)
[2025-11-12T22:25:01.908+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on eb021f2c8a8b:40023 (size: 14.1 KiB, free: 434.3 MiB)
[2025-11-12T22:25:01.908+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:01.909+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:25:01.910+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-11-12T22:25:01.912+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10805 bytes)
[2025-11-12T22:25:01.937+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:01 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.5:42325 (size: 14.1 KiB, free: 434.4 MiB)
[2025-11-12T22:25:02.093+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:02 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.5:42325 (size: 38.7 KiB, free: 434.3 MiB)
[2025-11-12T22:25:21.324+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:21 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 19414 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:25:21.325+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:21 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-11-12T22:25:21.328+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:21 INFO DAGScheduler: ResultStage 8 (showString at NativeMethodAccessorImpl.java:0) finished in 19.429 s
[2025-11-12T22:25:21.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:21 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:25:21.333+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-11-12T22:25:21.333+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:21 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 19.432667 s
[2025-11-12T22:25:21.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:21 INFO BlockManagerInfo: Removed broadcast_9_piece0 on eb021f2c8a8b:40023 in memory (size: 14.1 KiB, free: 434.4 MiB)
[2025-11-12T22:25:21.919+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:21 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.5:42325 in memory (size: 14.1 KiB, free: 434.4 MiB)
[2025-11-12T22:25:21.937+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:21 INFO CodeGenerator: Code generated in 34.171154 ms
[2025-11-12T22:25:22.005+0000] {spark_submit.py:571} INFO - +---+---------+------+-----------------+------------+-----------+-------+------+-----------------+-----------+-----------+--------+--------+----------+-------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+-----------------+--------------+----------+-----------------+--------------+----------+---------------------+---------------------+----------+--------+--------+----------------+----------------+-----------------+-----------------+-----------------+-----------------+
[2025-11-12T22:25:22.005+0000] {spark_submit.py:571} INFO - |day|division |eastId|eastRank         |eastShikona |kimarite   |matchNo|westId|westRank         |westShikona|winnerEn   |winnerId|winnerJp|match_id  |westWin|west_currentRank|west_debut|west_height|west_id|west_intai          |west_weight|west_rikishi_id|west_yusho|west_makuuchi_yusho|west_totalWins|west_totalLosses|west_totalMatches|west_makuuchiWins|west_basho|west_Makuuchi_basho|west_Gino_sho|west_Kanto_sho|west_Shukun_sho|east_currentRank|east_debut|east_height|east_id|east_intai          |east_weight|east_rikishi_id|east_yusho|east_makuuchi_yusho|east_totalWins|east_totalLosses|east_totalMatches|east_makuuchiWins|east_basho|east_Makuuchi_basho|east_Gino_sho|east_Kanto_sho|east_Shukun_sho|west_rank        |west_rankValue|west_order|east_rank        |east_rankValue|east_order|east_birthdate_parsed|west_birthdate_parsed|match_date|east_age|west_age|east_debut_clean|west_debut_clean|east_debut_parsed|west_debut_parsed|east_years_active|west_years_active|
[2025-11-12T22:25:22.006+0000] {spark_submit.py:571} INFO - +---+---------+------+-----------------+------------+-----------+-------+------+-----------------+-----------+-----------+--------+--------+----------+-------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+-----------------+--------------+----------+-----------------+--------------+----------+---------------------+---------------------+----------+--------+--------+----------------+----------------+-----------------+-----------------+-----------------+-----------------+
[2025-11-12T22:25:22.006+0000] {spark_submit.py:571} INFO - |1  |Makushita|5394  |Makushita 40 East|Tokuoyama   |oshitaoshi |11     |5409  |Makushita 40 West|Masakaze   |Tokuoyama  |5394    |        |1992050111|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198503    |180.0      |5394   |1997-07-01T00:00:00Z|161.5      |5394           |0         |NULL               |256           |262             |518              |NULL             |74        |NULL               |NULL         |NULL          |NULL           |Makushita 40 West|740           |207       |Makushita 40 East|740           |206       |1970-03-11           |1970-12-15           |1992-05-01|22      |21      |1985-03-01      |1987-09-01      |1985-03-01       |1987-09-01       |7                |4                |
[2025-11-12T22:25:22.006+0000] {spark_submit.py:571} INFO - |15 |Makushita|5609  |Makushita 43 West|Daikaizan   |uwatenage  |6      |5409  |Makushita 40 West|Masakaze   |Daikaizan  |5609    |        |199205156 |0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198305    |185.0      |5609   |1996-09-01T00:00:00Z|155.0      |5609           |1         |NULL               |285           |263             |548              |NULL             |80        |NULL               |NULL         |NULL          |NULL           |Makushita 40 West|740           |207       |Makushita 43 West|743           |213       |1967-04-12           |1970-12-15           |1992-05-15|25      |21      |1983-05-01      |1987-09-01      |1983-05-01       |1987-09-01       |9                |4                |
[2025-11-12T22:25:22.006+0000] {spark_submit.py:571} INFO - |5  |Makushita|5894  |Makushita 41 East|Kotodaiei   |oshidashi  |9      |5409  |Makushita 40 West|Masakaze   |Masakaze   |5409    |        |199205059 |1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198101    |178.4      |5894   |1993-01-01T00:00:00Z|112.6      |5894           |0         |NULL               |256           |241             |497              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |Makushita 40 West|740           |207       |Makushita 41 East|741           |208       |1963-02-16           |1970-12-15           |1992-05-05|29      |21      |1981-01-01      |1987-09-01      |1981-01-01       |1987-09-01       |11               |4                |
[2025-11-12T22:25:22.007+0000] {spark_submit.py:571} INFO - |5  |Sandanme |5820  |Sandanme 52 East |Hokudozan   |kotenage   |26     |4894  |Sandanme 48 West |Kantoryu   |Kantoryu   |4894    |        |1992050526|1      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198705    |180.0      |5820   |1994-03-01T00:00:00Z|88.0       |5820           |0         |NULL               |129           |127             |256              |NULL             |41        |NULL               |NULL         |NULL          |NULL           |Sandanme 48 West |848           |435       |Sandanme 52 East |852           |442       |1971-04-17           |1970-11-18           |1992-05-05|21      |21      |1987-05-01      |1989-01-01      |1987-05-01       |1989-01-01       |5                |3                |
[2025-11-12T22:25:22.007+0000] {spark_submit.py:571} INFO - |13 |Sandanme |3844  |Sandanme 13 East |Takaozaki   |yorikiri   |28     |5409  |Sandanme 21 East |Masakaze   |Takaozaki  |3844    |        |1995091328|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |199203    |190.0      |3844   |2007-09-01T00:00:00Z|147.5      |3844           |2         |NULL               |505           |470             |975              |229              |93        |34                 |NULL         |3             |NULL           |Sandanme 21 East |821           |378       |Sandanme 13 East |813           |360       |1976-04-02           |1970-12-15           |1995-09-13|19      |24      |1992-03-01      |1987-09-01      |1992-03-01       |1987-09-01       |3                |8                |
[2025-11-12T22:25:22.007+0000] {spark_submit.py:571} INFO - |11 |Jonidan  |3922  |Jonidan 121 East |Minami      |hikiotoshi |31     |4823  |Jonidan 123 West |Hirohata   |Minami     |3922    |        |1995091131|0      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199503    |181.0      |3922   |2013-11-01T00:00:00Z|134.0      |3922           |1         |NULL               |409           |354             |763              |NULL             |111       |NULL               |NULL         |NULL          |NULL           |Jonidan 123 West |1023          |873       |Jonidan 121 East |1021          |863       |1979-05-23           |1975-12-10           |1995-09-11|16      |19      |1995-03-01      |1994-01-01      |1995-03-01       |1994-01-01       |0                |1                |
[2025-11-12T22:25:22.007+0000] {spark_submit.py:571} INFO - |6  |Sandanme |3657  |Sandanme 32 East |Takanosho   |yorikiri   |33     |4894  |Sandanme 40 East |Kantoryu   |Takanosho  |3657    |        |1995090633|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198703    |188.1      |3657   |2005-03-01T00:00:00Z|181.0      |3657           |1         |NULL               |368           |388             |756              |NULL             |108       |NULL               |NULL         |NULL          |NULL           |Sandanme 40 East |840           |418       |Sandanme 32 East |832           |402       |1971-08-05           |1970-11-18           |1995-09-06|24      |24      |1987-03-01      |1989-01-01      |1987-03-01       |1989-01-01       |8                |6                |
[2025-11-12T22:25:22.007+0000] {spark_submit.py:571} INFO - |13 |Jonidan  |3571  |Jonidan 127 West |Dewanoyu    |oshidashi  |20     |4823  |Jonidan 123 West |Hirohata   |Hirohata   |4823    |        |1995091320|1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199209    |171.5      |3571   |2005-03-01T00:00:00Z|135.0      |3571           |0         |NULL               |242           |241             |483              |NULL             |75        |NULL               |NULL         |NULL          |NULL           |Jonidan 123 West |1023          |873       |Jonidan 127 West |1027          |889       |1976-04-16           |1975-12-10           |1995-09-13|19      |19      |1992-09-01      |1994-01-01      |1992-09-01       |1994-01-01       |3                |1                |
[2025-11-12T22:25:22.008+0000] {spark_submit.py:571} INFO - |9  |Sandanme |5835  |Sandanme 39 East |Kuroiwa     |kimedashi  |30     |4894  |Sandanme 40 East |Kantoryu   |Kantoryu   |4894    |        |1995090930|1      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198303    |187.5      |5835   |1996-03-01T00:00:00Z|93.5       |5835           |0         |NULL               |265           |274             |539              |NULL             |78        |NULL               |NULL         |NULL          |NULL           |Sandanme 40 East |840           |418       |Sandanme 39 East |839           |416       |1967-06-02           |1970-11-18           |1995-09-09|28      |24      |1983-03-01      |1989-01-01      |1983-03-01       |1989-01-01       |12               |6                |
[2025-11-12T22:25:22.008+0000] {spark_submit.py:571} INFO - |4  |Jonidan  |4018  |Jonidan 89 West  |Raiho       |hatakikomi |47     |5385  |Jonidan 87 West  |Fujiwaka   |Raiho      |4018    |        |1995090447|0      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199203    |179.0      |4018   |2003-01-01T00:00:00Z|145.5      |4018           |1         |NULL               |221           |224             |445              |NULL             |65        |NULL               |NULL         |NULL          |NULL           |Jonidan 87 West  |987           |754       |Jonidan 89 West  |989           |758       |1976-07-22           |1976-02-17           |1995-09-04|19      |19      |1992-03-01      |1992-09-01      |1992-03-01       |1992-09-01       |3                |3                |
[2025-11-12T22:25:22.008+0000] {spark_submit.py:571} INFO - |3  |Jonidan  |3585  |Jonidan 124 East |Ogiryu      |tsukiotoshi|31     |4823  |Jonidan 123 West |Hirohata   |Hirohata   |4823    |        |1995090331|1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199011    |171.0      |3585   |2009-01-01T00:00:00Z|82.0       |3585           |0         |NULL               |356           |407             |763              |NULL             |109       |NULL               |NULL         |NULL          |NULL           |Jonidan 123 West |1023          |873       |Jonidan 124 East |1024          |875       |1972-10-15           |1975-12-10           |1995-09-03|22      |19      |1990-11-01      |1994-01-01      |1990-11-01       |1994-01-01       |4                |1                |
[2025-11-12T22:25:22.009+0000] {spark_submit.py:571} INFO - |10 |Jonidan  |4822  |Jonidan 126 West |Oazuma      |uwatenage  |30     |4823  |Jonidan 123 West |Hirohata   |Hirohata   |4823    |        |1995091030|1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199201    |182.0      |4822   |2001-07-01T00:00:00Z|97.5       |4822           |0         |NULL               |179           |185             |364              |NULL             |56        |NULL               |NULL         |NULL          |NULL           |Jonidan 123 West |1023          |873       |Jonidan 126 West |1026          |886       |1973-12-30           |1975-12-10           |1995-09-10|21      |19      |1992-01-01      |1994-01-01      |1992-01-01       |1994-01-01       |3                |1                |
[2025-11-12T22:25:22.009+0000] {spark_submit.py:571} INFO - |6  |Jonidan  |5312  |Jonidan 124 West |Hideyoshi   |yorikiri   |30     |4823  |Jonidan 123 West |Hirohata   |Hirohata   |4823    |        |1995090630|1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199405    |170.0      |5312   |1998-03-01T00:00:00Z|85.0       |5312           |0         |NULL               |77            |78              |155              |NULL             |23        |NULL               |NULL         |NULL          |NULL           |Jonidan 123 West |1023          |873       |Jonidan 124 West |1024          |878       |1978-07-23           |1975-12-10           |1995-09-06|17      |19      |1994-05-01      |1994-01-01      |1994-05-01       |1994-01-01       |1                |1                |
[2025-11-12T22:25:22.009+0000] {spark_submit.py:571} INFO - |11 |Jonidan  |4976  |Jonidan 86 East  |Hirosawa    |tsukiotoshi|47     |5385  |Jonidan 87 West  |Fujiwaka   |Fujiwaka   |5385    |        |1995091147|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199403    |180.0      |4976   |2000-07-01T00:00:00Z|143.0      |4976           |0         |NULL               |135           |117             |252              |NULL             |38        |NULL               |NULL         |NULL          |NULL           |Jonidan 87 West  |987           |754       |Jonidan 86 East  |986           |751       |1975-07-22           |1976-02-17           |1995-09-11|20      |19      |1994-03-01      |1992-09-01      |1994-03-01       |1992-09-01       |1                |3                |
[2025-11-12T22:25:22.009+0000] {spark_submit.py:571} INFO - |10 |Jonidan  |5069  |Jonidan 83 East  |Fujishiro   |uwatenage  |48     |5385  |Jonidan 87 West  |Fujiwaka   |Fujishiro  |5069    |        |1995091048|0      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199409    |187.5      |5069   |2000-01-01T00:00:00Z|133.0      |5069           |0         |NULL               |102           |94              |196              |NULL             |32        |NULL               |NULL         |NULL          |NULL           |Jonidan 87 West  |987           |754       |Jonidan 83 East  |983           |745       |1977-05-26           |1976-02-17           |1995-09-10|18      |19      |1994-09-01      |1992-09-01      |1994-09-01       |1992-09-01       |1                |3                |
[2025-11-12T22:25:22.010+0000] {spark_submit.py:571} INFO - |6  |Sandanme |3290  |Sandanme 20 East |Akinohana   |sukuinage  |39     |5409  |Sandanme 21 East |Masakaze   |Masakaze   |5409    |        |1995090639|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |181.0      |3290   |2019-01-01T00:00:00Z|147.5      |3290           |0         |NULL               |535           |524             |1059             |NULL             |154       |NULL               |NULL         |NULL          |NULL           |Sandanme 21 East |821           |378       |Sandanme 20 East |820           |376       |1975-01-03           |1970-12-15           |1995-09-06|20      |24      |1993-03-01      |1987-09-01      |1993-03-01       |1987-09-01       |2                |8                |
[2025-11-12T22:25:22.010+0000] {spark_submit.py:571} INFO - |6  |Jonidan  |4003  |Jonidan 88 West  |Hokutenzan  |oshidashi  |47     |5385  |Jonidan 87 West  |Fujiwaka   |Fujiwaka   |5385    |        |1995090647|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199403    |177.0      |4003   |2003-09-01T00:00:00Z|116.5      |4003           |0         |NULL               |185           |190             |375              |NULL             |57        |NULL               |NULL         |NULL          |NULL           |Jonidan 87 West  |987           |754       |Jonidan 88 West  |988           |756       |1979-03-30           |1976-02-17           |1995-09-06|16      |19      |1994-03-01      |1992-09-01      |1994-03-01       |1992-09-01       |1                |3                |
[2025-11-12T22:25:22.010+0000] {spark_submit.py:571} INFO - |9  |Sandanme |5137  |Sandanme 68 East |Ryutenzan   |yorikiri   |16     |4894  |Sandanme 71 East |Kantoryu   |Kantoryu   |4894    |        |1997070916|1      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |199509    |187.0      |5137   |1999-05-01T00:00:00Z|134.0      |5137           |0         |NULL               |81            |65              |146              |NULL             |22        |NULL               |NULL         |NULL          |NULL           |Sandanme 71 East |871           |480       |Sandanme 68 East |868           |474       |1976-06-11           |1970-11-18           |1997-07-09|21      |26      |1995-09-01      |1989-01-01      |1995-09-01       |1989-01-01       |1                |8                |
[2025-11-12T22:25:22.010+0000] {spark_submit.py:571} INFO - |7  |Jonidan  |4915  |Jonidan 173 West |Neya        |yorikiri   |2      |3506  |Jonidan 171 West |Kokubushu  |Neya       |4915    |        |199805072 |0      |NULL            |199505    |176.0      |3506   |2003-01-01T00:00:00Z|126.0      |3506           |0         |NULL               |119           |168             |287              |NULL             |43        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |175.0      |4915   |2001-01-01T00:00:00Z|107.5      |4915           |0         |NULL               |142           |178             |320              |NULL             |47        |NULL               |NULL         |NULL          |NULL           |Jonidan 171 West |1071          |1065      |Jonidan 173 West |1073          |1073      |1977-06-23           |1973-07-30           |1998-05-07|20      |24      |1993-03-01      |1995-05-01      |1993-03-01       |1995-05-01       |5                |3                |
[2025-11-12T22:25:22.011+0000] {spark_submit.py:571} INFO - |15 |Jonidan  |3595  |Jonidan 172 West |Imanishi    |oshitaoshi |1      |3506  |Jonidan 171 West |Kokubushu  |Kokubushu  |3506    |        |199805151 |1      |NULL            |199505    |176.0      |3506   |2003-01-01T00:00:00Z|126.0      |3506           |0         |NULL               |119           |168             |287              |NULL             |43        |NULL               |NULL         |NULL          |NULL           |NULL            |199603    |177.0      |3595   |2002-01-01T00:00:00Z|100.5      |3595           |0         |NULL               |110           |120             |230              |NULL             |35        |NULL               |NULL         |NULL          |NULL           |Jonidan 171 West |1071          |1065      |Jonidan 172 West |1072          |1069      |1980-09-05           |1973-07-30           |1998-05-15|17      |24      |1996-03-01      |1995-05-01      |1996-03-01       |1995-05-01       |2                |3                |
[2025-11-12T22:25:22.011+0000] {spark_submit.py:571} INFO - |5  |Sandanme |3726  |Sandanme 38 East |Torafusuyama|yorikiri   |30     |5409  |Sandanme 42 East |Masakaze   |Masakaze   |5409    |        |1994030530|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198703    |188.0      |3726   |2004-01-01T00:00:00Z|133.5      |3726           |0         |NULL               |360           |340             |700              |NULL             |101       |NULL               |NULL         |NULL          |NULL           |Sandanme 42 East |842           |422       |Sandanme 38 East |838           |414       |1971-06-06           |1970-12-15           |1994-03-05|22      |23      |1987-03-01      |1987-09-01      |1987-03-01       |1987-09-01       |7                |6                |
[2025-11-12T22:25:22.011+0000] {spark_submit.py:571} INFO - |8  |Sandanme |5437  |Sandanme 31 East |Amagifuji   |oshidashi  |34     |4894  |Sandanme 33 West |Kantoryu   |Amagifuji  |5437    |        |1994030834|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198703    |180.0      |5437   |1997-05-01T00:00:00Z|132.0      |5437           |0         |NULL               |217           |203             |420              |NULL             |61        |NULL               |NULL         |NULL          |NULL           |Sandanme 33 West |833           |405       |Sandanme 31 East |831           |400       |1972-01-23           |1970-11-18           |1994-03-08|22      |23      |1987-03-01      |1989-01-01      |1987-03-01       |1989-01-01       |7                |5                |
[2025-11-12T22:25:22.011+0000] {spark_submit.py:571} INFO - |4  |Sandanme |5754  |Sandanme 40 East |Tsugarufuji |uwatenage  |30     |5409  |Sandanme 42 East |Masakaze   |Tsugarufuji|5754    |        |1994030430|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198803    |186.5      |5754   |1995-09-01T00:00:00Z|124.0      |5754           |0         |NULL               |150           |158             |308              |NULL             |45        |NULL               |NULL         |NULL          |NULL           |Sandanme 42 East |842           |422       |Sandanme 40 East |840           |418       |1972-12-17           |1970-12-15           |1994-03-04|21      |23      |1988-03-01      |1987-09-01      |1988-03-01       |1987-09-01       |6                |6                |
[2025-11-12T22:25:22.012+0000] {spark_submit.py:571} INFO - |3  |Jonokuchi|5033  |Jonokuchi 49 East|Dewasakai   |yorikiri   |5      |4823  |Jonokuchi 50 West|Hirohata   |Dewasakai  |5033    |        |199403035 |0      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199401    |179.5      |5033   |2000-03-01T00:00:00Z|99.0       |5033           |0         |NULL               |132           |127             |259              |NULL             |37        |NULL               |NULL         |NULL          |NULL           |Jonokuchi 50 West|1050          |981       |Jonokuchi 49 East|1049          |975       |1975-07-19           |1975-12-10           |1994-03-03|18      |18      |1994-01-01      |1994-01-01      |1994-01-01       |1994-01-01       |0                |0                |
[2025-11-12T22:25:22.012+0000] {spark_submit.py:571} INFO - |14 |Jonokuchi|5424  |Jonokuchi 44 East|Chida       |oshidashi  |3      |4823  |Jonokuchi 50 West|Hirohata   |Hirohata   |4823    |        |199403143 |1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |174.0      |5424   |1997-05-01T00:00:00Z|109.0      |5424           |0         |NULL               |57            |104             |161              |NULL             |24        |NULL               |NULL         |NULL          |NULL           |Jonokuchi 50 West|1050          |981       |Jonokuchi 44 East|1044          |956       |1977-05-07           |1975-12-10           |1994-03-14|16      |18      |1993-03-01      |1994-01-01      |1993-03-01       |1994-01-01       |1                |0                |
[2025-11-12T22:25:22.012+0000] {spark_submit.py:571} INFO - |5  |Jonokuchi|5991  |Jonokuchi 47 East|Ishiyama    |oshitaoshi |6      |4823  |Jonokuchi 50 West|Hirohata   |Ishiyama   |5991    |        |199403056 |0      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199401    |183.0      |5991   |1996-03-01T00:00:00Z|106.0      |5991           |0         |NULL               |28            |14              |42               |NULL             |11        |NULL               |NULL         |NULL          |NULL           |Jonokuchi 50 West|1050          |981       |Jonokuchi 47 East|1047          |967       |1975-05-19           |1975-12-10           |1994-03-05|18      |18      |1994-01-01      |1994-01-01      |1994-01-01       |1994-01-01       |0                |0                |
[2025-11-12T22:25:22.013+0000] {spark_submit.py:571} INFO - |10 |Sandanme |3858  |Sandanme 40 East |Chiyotaikai |yoritaoshi |29     |4894  |Sandanme 47 East |Kantoryu   |Kantoryu   |4894    |        |1993111029|1      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |199211    |181.5      |3858   |2010-01-01T00:00:00Z|158.0      |3858           |7         |3                  |771           |528             |1299             |597              |103       |75                 |3            |1             |1              |Sandanme 47 East |847           |432       |Sandanme 40 East |840           |418       |1976-04-29           |1970-11-18           |1993-11-10|17      |22      |1992-11-01      |1989-01-01      |1992-11-01       |1989-01-01       |1                |4                |
[2025-11-12T22:25:22.013+0000] {spark_submit.py:571} INFO - |3  |Jonokuchi|4042  |Jonokuchi 6 East |Ken         |tsukiotoshi|24     |5385  |Jonokuchi 7 East |Fujiwaka   |Ken        |4042    |        |1993110324|0      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |180.0      |4042   |2011-05-01T00:00:00Z|137.7      |4042           |1         |NULL               |512           |493             |1005             |4                |108       |1                  |NULL         |NULL          |NULL           |Jonokuchi 7 East |1007          |808       |Jonokuchi 6 East |1006          |803       |1977-12-14           |1976-02-17           |1993-11-03|15      |17      |1993-03-01      |1992-09-01      |1993-03-01       |1992-09-01       |0                |1                |
[2025-11-12T22:25:22.013+0000] {spark_submit.py:571} INFO - |11 |Jonidan  |4066  |Jonidan 52 East  |Gojoro      |oshidashi  |64     |5409  |Jonidan 61 East  |Masakaze   |Gojoro     |4066    |        |1993111164|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198911    |190.0      |4066   |2005-11-01T00:00:00Z|147.0      |4066           |4         |NULL               |504           |446             |950              |113              |96        |17                 |NULL         |NULL          |NULL           |Jonidan 61 East  |961           |701       |Jonidan 52 East  |952           |683       |1973-08-18           |1970-12-15           |1993-11-11|20      |22      |1989-11-01      |1987-09-01      |1989-11-01       |1987-09-01       |4                |6                |
[2025-11-12T22:25:22.013+0000] {spark_submit.py:571} INFO - |12 |Jonokuchi|3571  |Jonokuchi 3 East |Dewanoyu    |yoritaoshi |25     |5385  |Jonokuchi 7 East |Fujiwaka   |Fujiwaka   |5385    |        |1993111225|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199209    |171.5      |3571   |2005-03-01T00:00:00Z|135.0      |3571           |0         |NULL               |242           |241             |483              |NULL             |75        |NULL               |NULL         |NULL          |NULL           |Jonokuchi 7 East |1007          |808       |Jonokuchi 3 East |1003          |791       |1976-04-16           |1976-02-17           |1993-11-12|17      |17      |1992-09-01      |1992-09-01      |1992-09-01       |1992-09-01       |1                |1                |
[2025-11-12T22:25:22.013+0000] {spark_submit.py:571} INFO - |14 |Jonidan  |5098  |Jonidan 44 East  |Denryu      |yorikiri   |43     |5409  |Jonidan 61 East  |Masakaze   |Masakaze   |5409    |        |1993111443|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198903    |178.0      |5098   |1999-05-01T00:00:00Z|105.0      |5098           |0         |NULL               |181           |192             |373              |NULL             |56        |NULL               |NULL         |NULL          |NULL           |Jonidan 61 East  |961           |701       |Jonidan 44 East  |944           |667       |1973-11-22           |1970-12-15           |1993-11-14|19      |22      |1989-03-01      |1987-09-01      |1989-03-01       |1987-09-01       |4                |6                |
[2025-11-12T22:25:22.014+0000] {spark_submit.py:571} INFO - |4  |Jonidan  |5972  |Jonidan 60 East  |Yutoyama    |yoritaoshi |57     |5409  |Jonidan 61 East  |Masakaze   |Masakaze   |5409    |        |1993110457|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |199103    |177.0      |5972   |1994-11-01T00:00:00Z|88.0       |5972           |0         |NULL               |68            |73              |141              |NULL             |22        |NULL               |NULL         |NULL          |NULL           |Jonidan 61 East  |961           |701       |Jonidan 60 East  |960           |699       |1975-07-04           |1970-12-15           |1993-11-04|18      |22      |1991-03-01      |1987-09-01      |1991-03-01       |1987-09-01       |2                |6                |
[2025-11-12T22:25:22.014+0000] {spark_submit.py:571} INFO - |9  |Jonidan  |4873  |Jonidan 42 East  |Tsurunohana |hatakikomi |61     |4823  |Jonidan 47 East  |Hirohata   |Tsurunohana|4873    |        |1996010961|0      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |198903    |180.0      |4873   |2001-03-01T00:00:00Z|131.5      |4873           |0         |NULL               |225           |260             |485              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |Jonidan 47 East  |947           |673       |Jonidan 42 East  |942           |663       |1973-06-09           |1975-12-10           |1996-01-09|22      |20      |1989-03-01      |1994-01-01      |1989-03-01       |1994-01-01       |6                |2                |
[2025-11-12T22:25:22.014+0000] {spark_submit.py:571} INFO - |8  |Jonidan  |3966  |Jonidan 98 West  |Sano        |oshidashi  |38     |5385  |Jonidan 97 West  |Fujiwaka   |Fujiwaka   |5385    |        |1996010838|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199211    |177.5      |3966   |2007-07-01T00:00:00Z|166.5      |3966           |0         |NULL               |271           |325             |596              |NULL             |88        |NULL               |NULL         |NULL          |NULL           |Jonidan 97 West  |997           |774       |Jonidan 98 West  |998           |776       |1976-05-07           |1976-02-17           |1996-01-08|19      |19      |1992-11-01      |1992-09-01      |1992-11-01       |1992-09-01       |3                |3                |
[2025-11-12T22:25:22.014+0000] {spark_submit.py:571} INFO - |4  |Sandanme |5100  |Sandanme 22 East |Senshinryu  |yorikiri   |38     |4894  |Sandanme 23 East |Kantoryu   |Senshinryu |5100    |        |1996010438|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198903    |178.0      |5100   |1999-07-01T00:00:00Z|114.0      |5100           |0         |NULL               |214           |213             |427              |NULL             |62        |NULL               |NULL         |NULL          |NULL           |Sandanme 23 East |823           |383       |Sandanme 22 East |822           |380       |1973-08-17           |1970-11-18           |1996-01-04|22      |25      |1989-03-01      |1989-01-01      |1989-03-01       |1989-01-01       |6                |7                |
[2025-11-12T22:25:22.015+0000] {spark_submit.py:571} INFO - |13 |Jonidan  |5708  |Jonidan 38 East  |Hoken       |yorikiri   |42     |4823  |Jonidan 47 East  |Hirohata   |Hirohata   |4823    |        |1996011342|1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199211    |189.0      |5708   |1996-07-01T00:00:00Z|116.0      |5708           |0         |NULL               |58            |62              |120              |NULL             |21        |NULL               |NULL         |NULL          |NULL           |Jonidan 47 East  |947           |673       |Jonidan 38 East  |938           |655       |1974-09-28           |1975-12-10           |1996-01-13|21      |20      |1992-11-01      |1994-01-01      |1992-11-01       |1994-01-01       |3                |2                |
[2025-11-12T22:25:22.015+0000] {spark_submit.py:571} INFO - |8  |Sandanme |4061  |Sandanme 17 East |Kanenoumi   |yorikiri   |42     |4894  |Sandanme 13 West |Kantoryu   |Kanenoumi  |4061    |        |1993090842|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |199103    |184.0      |4061   |2006-05-01T00:00:00Z|156.0      |4061           |4         |NULL               |469           |453             |922              |102              |91        |17                 |NULL         |NULL          |NULL           |Sandanme 13 West |813           |361       |Sandanme 17 East |817           |369       |1976-01-07           |1970-11-18           |1993-09-08|17      |22      |1991-03-01      |1989-01-01      |1991-03-01       |1989-01-01       |2                |4                |
[2025-11-12T22:25:22.015+0000] {spark_submit.py:571} INFO - |1  |Sandanme |5554  |Sandanme 13 East |Fukuda      |oshidashi  |42     |4894  |Sandanme 13 West |Kantoryu   |Fukuda     |5554    |        |1993090142|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198603    |190.5      |5554   |1994-11-01T00:00:00Z|132.2      |5554           |0         |NULL               |175           |181             |356              |NULL             |52        |NULL               |NULL         |NULL          |NULL           |Sandanme 13 West |813           |361       |Sandanme 13 East |813           |360       |1970-07-15           |1970-11-18           |1993-09-01|23      |22      |1986-03-01      |1989-01-01      |1986-03-01       |1989-01-01       |7                |4                |
[2025-11-12T22:25:22.015+0000] {spark_submit.py:571} INFO - |13 |Jonidan  |5328  |Jonidan 176 East |Uemura      |uwatenage  |7      |5385  |Jonidan 171 West |Fujiwaka   |Uemura     |5328    |        |199309137 |0      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |176.0      |5328   |1998-01-01T00:00:00Z|126.5      |5328           |0         |NULL               |96            |89              |185              |NULL             |29        |NULL               |NULL         |NULL          |NULL           |Jonidan 171 West |1071          |1065      |Jonidan 176 East |1076          |1083      |1977-05-02           |1976-02-17           |1993-09-13|16      |17      |1993-03-01      |1992-09-01      |1993-03-01       |1992-09-01       |0                |1                |
[2025-11-12T22:25:22.016+0000] {spark_submit.py:571} INFO - |12 |Makushita|3749  |Makushita 25 East|Wakakosho   |yorikiri   |18     |5409  |Makushita 26 West|Masakaze   |Masakaze   |5409    |        |1996031218|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |199005    |184.5      |3749   |2005-03-01T00:00:00Z|176.0      |3749           |0         |NULL               |415           |400             |815              |13               |89        |2                  |NULL         |NULL          |NULL           |Makushita 26 West|726           |177       |Makushita 25 East|725           |174       |1975-03-04           |1970-12-15           |1996-03-12|21      |25      |1990-05-01      |1987-09-01      |1990-05-01       |1987-09-01       |5                |8                |
[2025-11-12T22:25:22.016+0000] {spark_submit.py:571} INFO - |15 |Makushita|3669  |Makushita 30 West|Tsuchihashi |hatakikomi |11     |5409  |Makushita 26 West|Masakaze   |Masakaze   |5409    |        |1996031511|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198905    |174.0      |3669   |2006-11-01T00:00:00Z|88.0       |3669           |2         |NULL               |365           |369             |734              |NULL             |105       |NULL               |NULL         |NULL          |NULL           |Makushita 26 West|726           |177       |Makushita 30 West|730           |186       |1973-09-25           |1970-12-15           |1996-03-15|22      |25      |1989-05-01      |1987-09-01      |1989-05-01       |1987-09-01       |6                |8                |
[2025-11-12T22:25:22.016+0000] {spark_submit.py:571} INFO - |9  |Sandanme |4984  |Sandanme 57 East |Tsukasaryu  |yorikiri   |22     |4894  |Sandanme 59 East |Kantoryu   |Tsukasaryu |4984    |        |1996030922|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198805    |172.0      |4984   |1999-11-01T00:00:00Z|123.0      |4984           |0         |NULL               |235           |248             |483              |NULL             |69        |NULL               |NULL         |NULL          |NULL           |Sandanme 59 East |859           |456       |Sandanme 57 East |857           |452       |1972-11-04           |1970-11-18           |1996-03-09|23      |25      |1988-05-01      |1989-01-01      |1988-05-01       |1989-01-01       |7                |7                |
[2025-11-12T22:25:22.017+0000] {spark_submit.py:571} INFO - |4  |Sandanme |5068  |Sandanme 58 East |Kamisawa    |yorikiri   |21     |4894  |Sandanme 59 East |Kantoryu   |Kantoryu   |4894    |        |1996030421|1      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198901    |182.0      |5068   |2000-03-01T00:00:00Z|110.0      |5068           |0         |NULL               |227           |214             |441              |NULL             |67        |NULL               |NULL         |NULL          |NULL           |Sandanme 59 East |859           |456       |Sandanme 58 East |858           |454       |1970-09-06           |1970-11-18           |1996-03-04|25      |25      |1989-01-01      |1989-01-01      |1989-01-01       |1989-01-01       |7                |7                |
[2025-11-12T22:25:22.017+0000] {spark_submit.py:571} INFO - |9  |Makushita|3907  |Makushita 27 West|Kimenryu    |yorikiri   |17     |5409  |Makushita 26 West|Masakaze   |Kimenryu   |3907    |        |1996030917|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198503    |189.5      |3907   |2010-09-01T00:00:00Z|144.5      |3907           |1         |NULL               |534           |519             |1053             |NULL             |153       |NULL               |NULL         |NULL          |NULL           |Makushita 26 West|726           |177       |Makushita 27 West|727           |179       |1969-09-29           |1970-12-15           |1996-03-09|26      |25      |1985-03-01      |1987-09-01      |1985-03-01       |1987-09-01       |11               |8                |
[2025-11-12T22:25:22.017+0000] {spark_submit.py:571} INFO - |13 |Jonidan  |4959  |Jonidan 65 East  |Kai         |uwatenage  |34     |5385  |Jonidan 69 West  |Fujiwaka   |Kai        |4959    |        |1996031334|0      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |186.0      |4959   |2000-07-01T00:00:00Z|134.0      |4959           |0         |NULL               |149           |133             |282              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |Jonidan 69 West  |969           |718       |Jonidan 65 East  |965           |709       |1977-05-17           |1976-02-17           |1996-03-13|18      |20      |1993-03-01      |1992-09-01      |1993-03-01       |1992-09-01       |3                |3                |
[2025-11-12T22:25:22.017+0000] {spark_submit.py:571} INFO - |1  |Jonidan  |4942  |Jonidan 70 East  |Wakayanagi  |hatakikomi |50     |5385  |Jonidan 69 West  |Fujiwaka   |Fujiwaka   |5385    |        |1996030150|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |174.0      |4942   |2000-05-01T00:00:00Z|117.0      |4942           |1         |NULL               |140           |143             |283              |NULL             |43        |NULL               |NULL         |NULL          |NULL           |Jonidan 69 West  |969           |718       |Jonidan 70 East  |970           |719       |1977-05-10           |1976-02-17           |1996-03-01|18      |20      |1993-03-01      |1992-09-01      |1993-03-01       |1992-09-01       |3                |3                |
[2025-11-12T22:25:22.018+0000] {spark_submit.py:571} INFO - |3  |Jonidan  |5310  |Jonidan 71 East  |Asanishiharu|yoritaoshi |50     |5385  |Jonidan 69 West  |Fujiwaka   |Fujiwaka   |5385    |        |1996030350|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199305    |176.0      |5310   |1998-01-01T00:00:00Z|96.0       |5310           |0         |NULL               |90            |94              |184              |NULL             |28        |NULL               |NULL         |NULL          |NULL           |Jonidan 69 West  |969           |718       |Jonidan 71 East  |971           |721       |1973-09-15           |1976-02-17           |1996-03-03|22      |20      |1993-05-01      |1992-09-01      |1993-05-01       |1992-09-01       |2                |3                |
[2025-11-12T22:25:22.018+0000] {spark_submit.py:571} INFO - |12 |Jonidan  |3599  |Jonidan 78 East  |Tamanosho   |yorikiri   |45     |4823  |Jonidan 82 East  |Hirohata   |Tamanosho  |3599    |        |1996031245|0      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199105    |176.0      |3599   |2008-03-01T00:00:00Z|141.0      |3599           |0         |NULL               |322           |362             |684              |NULL             |101       |NULL               |NULL         |NULL          |NULL           |Jonidan 82 East  |982           |743       |Jonidan 78 East  |978           |735       |1972-04-28           |1975-12-10           |1996-03-12|23      |20      |1991-05-01      |1994-01-01      |1991-05-01       |1994-01-01       |4                |2                |
[2025-11-12T22:25:22.018+0000] {spark_submit.py:571} INFO - |1  |Makushita|1147  |Makushita 34 East|Saganobori  |yorikiri   |14     |5409  |Makushita 34 West|Masakaze   |Saganobori |1147    |        |1994110114|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |197703    |190.0      |1147   |1996-01-01T00:00:00Z|117.0      |1147           |0         |NULL               |516           |497             |1013             |5                |113       |1                  |NULL         |NULL          |NULL           |Makushita 34 West|734           |195       |Makushita 34 East|734           |194       |1961-11-27           |1970-12-15           |1994-11-01|32      |23      |1977-03-01      |1987-09-01      |1977-03-01       |1987-09-01       |17               |7                |
[2025-11-12T22:25:22.019+0000] {spark_submit.py:571} INFO - |15 |Makushita|4619  |Makushita 44 East|Nakanoyama  |oshidashi  |8      |5409  |Makushita 34 West|Masakaze   |Masakaze   |5409    |        |199411158 |1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |199003    |183.0      |4619   |2003-09-01T00:00:00Z|138.0      |4619           |1         |NULL               |280           |247             |527              |NULL             |81        |NULL               |NULL         |NULL          |NULL           |Makushita 34 West|734           |195       |Makushita 44 East|744           |214       |1974-06-03           |1970-12-15           |1994-11-15|20      |23      |1990-03-01      |1987-09-01      |1990-03-01       |1987-09-01       |4                |7                |
[2025-11-12T22:25:22.019+0000] {spark_submit.py:571} INFO - +---+---------+------+-----------------+------------+-----------+-------+------+-----------------+-----------+-----------+--------+--------+----------+-------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+-----------------+--------------+----------+-----------------+--------------+----------+---------------------+---------------------+----------+--------+--------+----------------+----------------+-----------------+-----------------+-----------------+-----------------+
[2025-11-12T22:25:22.019+0000] {spark_submit.py:571} INFO - only showing top 50 rows
[2025-11-12T22:25:22.019+0000] {spark_submit.py:571} INFO - 
[2025-11-12T22:25:22.447+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:22.448+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:22.523+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO CodeGenerator: Code generated in 29.582159 ms
[2025-11-12T22:25:22.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 221.7 KiB, free 433.9 MiB)
[2025-11-12T22:25:22.532+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 433.9 MiB)
[2025-11-12T22:25:22.533+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on eb021f2c8a8b:40023 (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:25:22.533+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO SparkContext: Created broadcast 10 from head at Imputer.scala:170
[2025-11-12T22:25:22.534+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:25:22.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO DAGScheduler: Registering RDD 39 (head at Imputer.scala:170) as input to shuffle 1
[2025-11-12T22:25:22.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO DAGScheduler: Got map stage job 8 (head at Imputer.scala:170) with 2 output partitions
[2025-11-12T22:25:22.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (head at Imputer.scala:170)
[2025-11-12T22:25:22.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:22.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:22.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[39] at head at Imputer.scala:170), which has no missing parents
[2025-11-12T22:25:22.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 42.0 KiB, free 433.8 MiB)
[2025-11-12T22:25:22.543+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 433.8 MiB)
[2025-11-12T22:25:22.543+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on eb021f2c8a8b:40023 (size: 14.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:22.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:22.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[39] at head at Imputer.scala:170) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:25:22.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0
[2025-11-12T22:25:22.545+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:25:22.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:25:22.562+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:42325 (size: 14.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:22.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:43045 (size: 14.3 KiB, free: 434.4 MiB)
[2025-11-12T22:25:22.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:42325 (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:25:22.769+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:22 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:43045 (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:25:25.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:25 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 2949 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:25:26.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 4239 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:25:26.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-11-12T22:25:26.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: ShuffleMapStage 9 (head at Imputer.scala:170) finished in 4.245 s
[2025-11-12T22:25:26.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:25:26.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: running: Set()
[2025-11-12T22:25:26.787+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:25:26.787+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: failed: Set()
[2025-11-12T22:25:26.808+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO CodeGenerator: Code generated in 10.736457 ms
[2025-11-12T22:25:26.813+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO SparkContext: Starting job: head at Imputer.scala:170
[2025-11-12T22:25:26.814+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: Got job 9 (head at Imputer.scala:170) with 1 output partitions
[2025-11-12T22:25:26.815+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: Final stage: ResultStage 11 (head at Imputer.scala:170)
[2025-11-12T22:25:26.815+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2025-11-12T22:25:26.816+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:26.816+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[42] at head at Imputer.scala:170), which has no missing parents
[2025-11-12T22:25:26.817+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.7 KiB, free 433.8 MiB)
[2025-11-12T22:25:26.818+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 433.8 MiB)
[2025-11-12T22:25:26.822+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on eb021f2c8a8b:40023 (size: 9.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:26.823+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:26.825+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[42] at head at Imputer.scala:170) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:25:26.825+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-11-12T22:25:26.826+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO BlockManagerInfo: Removed broadcast_11_piece0 on eb021f2c8a8b:40023 in memory (size: 14.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:26.827+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:25:26.827+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.5:43045 in memory (size: 14.3 KiB, free: 434.4 MiB)
[2025-11-12T22:25:26.828+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.5:42325 in memory (size: 14.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:26.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.5:43045 (size: 9.3 KiB, free: 434.4 MiB)
[2025-11-12T22:25:26.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:50962
[2025-11-12T22:25:26.969+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 143 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:25:26.969+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-11-12T22:25:26.970+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: ResultStage 11 (head at Imputer.scala:170) finished in 0.154 s
[2025-11-12T22:25:26.970+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:25:26.970+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2025-11-12T22:25:26.971+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO DAGScheduler: Job 9 finished: head at Imputer.scala:170, took 0.156495 s
[2025-11-12T22:25:26.982+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO BlockManagerInfo: Removed broadcast_12_piece0 on eb021f2c8a8b:40023 in memory (size: 9.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:26.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.5:43045 in memory (size: 9.3 KiB, free: 434.4 MiB)
[2025-11-12T22:25:26.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:26 INFO CodeGenerator: Code generated in 11.25988 ms
[2025-11-12T22:25:27.022+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO CodeGenerator: Code generated in 4.570194 ms
[2025-11-12T22:25:27.026+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO SparkContext: Starting job: head at Imputer.scala:259
[2025-11-12T22:25:27.027+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Got job 10 (head at Imputer.scala:259) with 1 output partitions
[2025-11-12T22:25:27.027+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Final stage: ResultStage 12 (head at Imputer.scala:259)
[2025-11-12T22:25:27.027+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:27.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:27.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[46] at head at Imputer.scala:259), which has no missing parents
[2025-11-12T22:25:27.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 22.5 KiB, free 433.9 MiB)
[2025-11-12T22:25:27.038+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 433.9 MiB)
[2025-11-12T22:25:27.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on eb021f2c8a8b:40023 (size: 9.0 KiB, free: 434.3 MiB)
[2025-11-12T22:25:27.040+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:27.040+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[46] at head at Imputer.scala:259) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:25:27.041+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-11-12T22:25:27.042+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10137 bytes)
[2025-11-12T22:25:27.057+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.5:43045 (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:25:27.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO BlockManagerInfo: Removed broadcast_8_piece0 on eb021f2c8a8b:40023 in memory (size: 38.7 KiB, free: 434.4 MiB)
[2025-11-12T22:25:27.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.5:42325 in memory (size: 38.7 KiB, free: 434.4 MiB)
[2025-11-12T22:25:27.076+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO BlockManagerInfo: Removed broadcast_10_piece0 on eb021f2c8a8b:40023 in memory (size: 37.4 KiB, free: 434.4 MiB)
[2025-11-12T22:25:27.077+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.5:42325 in memory (size: 37.4 KiB, free: 434.4 MiB)
[2025-11-12T22:25:27.078+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.5:43045 in memory (size: 37.4 KiB, free: 434.4 MiB)
[2025-11-12T22:25:27.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 71 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:25:27.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-11-12T22:25:27.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: ResultStage 12 (head at Imputer.scala:259) finished in 0.085 s
[2025-11-12T22:25:27.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:25:27.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
[2025-11-12T22:25:27.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Job 10 finished: head at Imputer.scala:259, took 0.087348 s
[2025-11-12T22:25:27.117+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO SparkContext: Starting job: head at Imputer.scala:259
[2025-11-12T22:25:27.118+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Got job 11 (head at Imputer.scala:259) with 1 output partitions
[2025-11-12T22:25:27.118+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Final stage: ResultStage 13 (head at Imputer.scala:259)
[2025-11-12T22:25:27.118+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:27.118+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:27.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[46] at head at Imputer.scala:259), which has no missing parents
[2025-11-12T22:25:27.120+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 22.5 KiB, free 434.3 MiB)
[2025-11-12T22:25:27.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 434.3 MiB)
[2025-11-12T22:25:27.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on eb021f2c8a8b:40023 (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:25:27.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:27.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[46] at head at Imputer.scala:259) (first 15 tasks are for partitions Vector(1))
[2025-11-12T22:25:27.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2025-11-12T22:25:27.124+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10383 bytes)
[2025-11-12T22:25:27.136+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.5:42325 (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:25:27.825+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 702 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:25:27.826+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-11-12T22:25:27.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: ResultStage 13 (head at Imputer.scala:259) finished in 0.706 s
[2025-11-12T22:25:27.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:25:27.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
[2025-11-12T22:25:27.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO DAGScheduler: Job 11 finished: head at Imputer.scala:259, took 0.709084 s
[2025-11-12T22:25:27.837+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:27 INFO CodeGenerator: Code generated in 8.413858 ms
[2025-11-12T22:25:28.030+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:28 INFO BlockManagerInfo: Removed broadcast_14_piece0 on eb021f2c8a8b:40023 in memory (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:25:28.037+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:28 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.18.0.5:42325 in memory (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:25:28.044+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:28 INFO BlockManagerInfo: Removed broadcast_13_piece0 on eb021f2c8a8b:40023 in memory (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:25:28.046+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:28 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.5:43045 in memory (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:25:35.413+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.414+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:35.416+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.417+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2244 = ) THEN false ELSE isnull(kimarite#2244) END OR CASE WHEN (kimarite#2244 = ) THEN true ELSE (kimarite#2244 = NA) END) THEN false ELSE CASE WHEN (kimarite#2244 = ) THEN true ELSE isnotnull(kimarite#2244) END END
[2025-11-12T22:25:35.419+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.419+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2698 = ) THEN false ELSE isnull(kimarite#2698) END OR CASE WHEN (kimarite#2698 = ) THEN true ELSE (kimarite#2698 = NA) END) THEN false ELSE CASE WHEN (kimarite#2698 = ) THEN true ELSE isnotnull(kimarite#2698) END END
[2025-11-12T22:25:35.421+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.421+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:35.422+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.422+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7603 = ) THEN false ELSE isnull(kimarite#7603) END OR CASE WHEN (kimarite#7603 = ) THEN true ELSE (kimarite#7603 = NA) END) THEN false ELSE CASE WHEN (kimarite#7603 = ) THEN true ELSE isnotnull(kimarite#7603) END END
[2025-11-12T22:25:35.423+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.423+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7807 = ) THEN false ELSE isnull(kimarite#7807) END OR CASE WHEN (kimarite#7807 = ) THEN true ELSE (kimarite#7807 = NA) END) THEN false ELSE CASE WHEN (kimarite#7807 = ) THEN true ELSE isnotnull(kimarite#7807) END END
[2025-11-12T22:25:35.426+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.426+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:35.426+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.427+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11148 = ) THEN false ELSE isnull(kimarite#11148) END OR CASE WHEN (kimarite#11148 = ) THEN true ELSE (kimarite#11148 = NA) END) THEN false ELSE CASE WHEN (kimarite#11148 = ) THEN true ELSE isnotnull(kimarite#11148) END END
[2025-11-12T22:25:35.428+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.428+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11352 = ) THEN false ELSE isnull(kimarite#11352) END OR CASE WHEN (kimarite#11352 = ) THEN true ELSE (kimarite#11352 = NA) END) THEN false ELSE CASE WHEN (kimarite#11352 = ) THEN true ELSE isnotnull(kimarite#11352) END END
[2025-11-12T22:25:35.429+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.429+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:35.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14208 = ) THEN false ELSE isnull(kimarite#14208) END OR CASE WHEN (kimarite#14208 = ) THEN true ELSE (kimarite#14208 = NA) END) THEN false ELSE CASE WHEN (kimarite#14208 = ) THEN true ELSE isnotnull(kimarite#14208) END END
[2025-11-12T22:25:35.431+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.431+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14412 = ) THEN false ELSE isnull(kimarite#14412) END OR CASE WHEN (kimarite#14412 = ) THEN true ELSE (kimarite#14412 = NA) END) THEN false ELSE CASE WHEN (kimarite#14412 = ) THEN true ELSE isnotnull(kimarite#14412) END END
[2025-11-12T22:25:35.531+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO CodeGenerator: Code generated in 5.006117 ms
[2025-11-12T22:25:35.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Registering RDD 48 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2025-11-12T22:25:35.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Got map stage job 12 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:25:35.536+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:35.536+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:35.536+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:35.537+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:35.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.7 KiB, free 434.4 MiB)
[2025-11-12T22:25:35.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 434.4 MiB)
[2025-11-12T22:25:35.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on eb021f2c8a8b:40023 (size: 8.8 KiB, free: 434.4 MiB)
[2025-11-12T22:25:35.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:35.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:25:35.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks resource profile 0
[2025-11-12T22:25:35.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 11355 bytes)
[2025-11-12T22:25:35.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 15) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 11479 bytes)
[2025-11-12T22:25:35.557+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.5:42325 (size: 8.8 KiB, free: 434.4 MiB)
[2025-11-12T22:25:35.559+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.5:43045 (size: 8.8 KiB, free: 434.4 MiB)
[2025-11-12T22:25:35.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO CodeGenerator: Code generated in 47.752766 ms
[2025-11-12T22:25:35.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 221.4 KiB, free 434.2 MiB)
[2025-11-12T22:25:35.615+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 434.1 MiB)
[2025-11-12T22:25:35.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 434.4 MiB)
[2025-11-12T22:25:35.619+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO SparkContext: Created broadcast 16 from count at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:35.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:25:35.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Registering RDD 52 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2025-11-12T22:25:35.654+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Got map stage job 13 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:25:35.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:35.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:35.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:35.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[52] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:35.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 43.7 KiB, free 434.1 MiB)
[2025-11-12T22:25:35.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 15) in 118 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:25:35.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 434.1 MiB)
[2025-11-12T22:25:35.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on eb021f2c8a8b:40023 (size: 18.9 KiB, free: 434.3 MiB)
[2025-11-12T22:25:35.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:35.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[52] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:25:35.661+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO TaskSchedulerImpl: Adding task set 15.0 with 2 tasks resource profile 0
[2025-11-12T22:25:35.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:25:35.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.5:42325 (size: 18.9 KiB, free: 434.4 MiB)
[2025-11-12T22:25:35.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 17) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:25:35.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 207 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:25:35.755+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-11-12T22:25:35.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.214 s
[2025-11-12T22:25:35.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:25:35.769+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: running: Set(ShuffleMapStage 15)
[2025-11-12T22:25:35.770+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:25:35.770+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO DAGScheduler: failed: Set()
[2025-11-12T22:25:35.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.5:43045 (size: 18.9 KiB, free: 434.4 MiB)
[2025-11-12T22:25:35.797+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.804+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:35.807+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.807+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:35.808+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.812+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:35.812+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:35.813+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:35.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:35 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:36.074+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:36 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:38.562+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 2901 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:25:38.720+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 17) in 2975 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:25:38.721+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-11-12T22:25:38.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 3.067 s
[2025-11-12T22:25:38.723+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:25:38.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: running: Set()
[2025-11-12T22:25:38.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:25:38.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: failed: Set()
[2025-11-12T22:25:38.737+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:38.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:38.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:38.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:38.744+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:38.744+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:38.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:38.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:38.770+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:38.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:38.788+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:38.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:38.790+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:38.792+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:38.793+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:38.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:38.819+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO BlockManagerInfo: Removed broadcast_17_piece0 on eb021f2c8a8b:40023 in memory (size: 18.9 KiB, free: 434.4 MiB)
[2025-11-12T22:25:38.822+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.5:43045 in memory (size: 18.9 KiB, free: 434.4 MiB)
[2025-11-12T22:25:38.827+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.5:42325 in memory (size: 18.9 KiB, free: 434.4 MiB)
[2025-11-12T22:25:38.828+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO BlockManagerInfo: Removed broadcast_15_piece0 on eb021f2c8a8b:40023 in memory (size: 8.8 KiB, free: 434.4 MiB)
[2025-11-12T22:25:38.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.5:43045 in memory (size: 8.8 KiB, free: 434.4 MiB)
[2025-11-12T22:25:38.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.5:42325 in memory (size: 8.8 KiB, free: 434.4 MiB)
[2025-11-12T22:25:38.842+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:38.843+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:38.843+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:38.844+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:38.844+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:38.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:38.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:38.846+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:38.856+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO CodeGenerator: Code generated in 22.327379 ms
[2025-11-12T22:25:38.876+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:25:38.877+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: Got job 14 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:25:38.878+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: Final stage: ResultStage 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:25:38.878+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
[2025-11-12T22:25:38.879+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:38.879+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[55] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:25:38.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 45.4 KiB, free 434.1 MiB)
[2025-11-12T22:25:38.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 20.4 KiB, free 434.1 MiB)
[2025-11-12T22:25:38.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on eb021f2c8a8b:40023 (size: 20.4 KiB, free: 434.3 MiB)
[2025-11-12T22:25:38.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:38.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[55] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:25:38.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2025-11-12T22:25:38.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 18) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:25:38.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.5:43045 (size: 20.4 KiB, free: 434.3 MiB)
[2025-11-12T22:25:38.919+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.5:50962
[2025-11-12T22:25:38.995+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 18) in 107 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:25:38.999+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2025-11-12T22:25:39.000+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: ResultStage 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.112 s
[2025-11-12T22:25:39.000+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:25:39.004+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
[2025-11-12T22:25:39.004+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:38 INFO DAGScheduler: Job 14 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.120496 s
[2025-11-12T22:25:39.017+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO CodeGenerator: Code generated in 4.583401 ms
[2025-11-12T22:25:39.030+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 46.9 KiB, free 434.0 MiB)
[2025-11-12T22:25:39.031+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on eb021f2c8a8b:40023 (size: 46.9 KiB, free: 434.3 MiB)
[2025-11-12T22:25:39.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO SparkContext: Created broadcast 19 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:25:39.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:39.040+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:39.042+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:39.042+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:39.045+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:39.046+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:39.049+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:39.049+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:39.094+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO CodeGenerator: Code generated in 6.836199 ms
[2025-11-12T22:25:39.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO CodeGenerator: Code generated in 14.747346 ms
[2025-11-12T22:25:39.127+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 221.6 KiB, free 433.8 MiB)
[2025-11-12T22:25:39.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 433.8 MiB)
[2025-11-12T22:25:39.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on eb021f2c8a8b:40023 (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:25:39.133+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO SparkContext: Created broadcast 20 from count at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:39.135+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:25:39.172+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO CodeGenerator: Code generated in 18.364605 ms
[2025-11-12T22:25:39.177+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 221.6 KiB, free 433.6 MiB)
[2025-11-12T22:25:39.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 433.5 MiB)
[2025-11-12T22:25:39.185+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on eb021f2c8a8b:40023 (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:25:39.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO SparkContext: Created broadcast 21 from count at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:39.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:25:39.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO DAGScheduler: Registering RDD 65 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2025-11-12T22:25:39.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO DAGScheduler: Got map stage job 15 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:25:39.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO DAGScheduler: Final stage: ShuffleMapStage 18 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:39.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:39.229+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:39.229+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[65] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:39.250+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 78.7 KiB, free 433.5 MiB)
[2025-11-12T22:25:39.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 433.4 MiB)
[2025-11-12T22:25:39.253+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on eb021f2c8a8b:40023 (size: 29.3 KiB, free: 434.2 MiB)
[2025-11-12T22:25:39.253+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:39.253+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[65] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:25:39.254+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks resource profile 0
[2025-11-12T22:25:39.257+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 19) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:25:39.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 20) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:25:39.276+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.5:43045 (size: 29.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:39.278+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.5:42325 (size: 29.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:39.417+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.5:43045 (size: 46.9 KiB, free: 434.3 MiB)
[2025-11-12T22:25:39.451+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.5:42325 (size: 46.9 KiB, free: 434.3 MiB)
[2025-11-12T22:25:39.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.5:43045 (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:25:39.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:39 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.5:42325 (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:25:42.630+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:42 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 21) (172.18.0.5, executor 1, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:25:42.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:42 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 20) in 3374 ms on 172.18.0.5 (executor 1) (1/4)
[2025-11-12T22:25:42.679+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:42 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.5:43045 (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:25:43.251+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:43 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 22) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:25:43.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:43 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 19) in 3997 ms on 172.18.0.5 (executor 0) (2/4)
[2025-11-12T22:25:43.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:43 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.5:42325 (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:25:46.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 21) in 3463 ms on 172.18.0.5 (executor 1) (3/4)
[2025-11-12T22:25:46.152+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 22) in 2900 ms on 172.18.0.5 (executor 0) (4/4)
[2025-11-12T22:25:46.152+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-11-12T22:25:46.153+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: ShuffleMapStage 18 (count at NativeMethodAccessorImpl.java:0) finished in 6.925 s
[2025-11-12T22:25:46.153+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:25:46.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: running: Set()
[2025-11-12T22:25:46.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:25:46.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: failed: Set()
[2025-11-12T22:25:46.161+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:46.163+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:46.179+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO CodeGenerator: Code generated in 3.339246 ms
[2025-11-12T22:25:46.185+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO CodeGenerator: Code generated in 3.478652 ms
[2025-11-12T22:25:46.197+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:25:46.199+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Got job 16 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:25:46.199+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Final stage: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:25:46.200+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2025-11-12T22:25:46.202+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:46.202+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[71] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:25:46.203+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 69.5 KiB, free 433.4 MiB)
[2025-11-12T22:25:46.205+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 433.3 MiB)
[2025-11-12T22:25:46.205+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on eb021f2c8a8b:40023 (size: 29.0 KiB, free: 434.2 MiB)
[2025-11-12T22:25:46.205+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:46.206+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[71] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:25:46.206+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2025-11-12T22:25:46.206+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:25:46.215+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.5:42325 (size: 29.0 KiB, free: 434.2 MiB)
[2025-11-12T22:25:46.235+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.5:50960
[2025-11-12T22:25:46.344+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 137 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:25:46.345+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-11-12T22:25:46.347+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.143 s
[2025-11-12T22:25:46.347+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:25:46.348+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2025-11-12T22:25:46.348+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Job 16 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.148207 s
[2025-11-12T22:25:46.357+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 108.4 KiB, free 433.2 MiB)
[2025-11-12T22:25:46.358+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on eb021f2c8a8b:40023 (size: 108.4 KiB, free: 434.1 MiB)
[2025-11-12T22:25:46.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO SparkContext: Created broadcast 24 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:25:46.367+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:46.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO CodeGenerator: Code generated in 25.510518 ms
[2025-11-12T22:25:46.455+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Registering RDD 74 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2025-11-12T22:25:46.456+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Got map stage job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:25:46.456+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:46.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
[2025-11-12T22:25:46.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:46.458+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[74] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:46.462+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 96.8 KiB, free 433.1 MiB)
[2025-11-12T22:25:46.464+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 39.7 KiB, free 433.1 MiB)
[2025-11-12T22:25:46.465+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on eb021f2c8a8b:40023 (size: 39.7 KiB, free: 434.0 MiB)
[2025-11-12T22:25:46.466+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:46.466+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[74] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:25:46.466+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-11-12T22:25:46.468+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 24) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10138 bytes)
[2025-11-12T22:25:46.484+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.5:42325 (size: 39.7 KiB, free: 434.1 MiB)
[2025-11-12T22:25:46.506+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.5:50960
[2025-11-12T22:25:46.551+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.5:42325 (size: 108.4 KiB, free: 434.0 MiB)
[2025-11-12T22:25:46.645+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 24) in 178 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:25:46.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-11-12T22:25:46.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 0.188 s
[2025-11-12T22:25:46.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:25:46.648+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: running: Set()
[2025-11-12T22:25:46.648+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:25:46.649+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: failed: Set()
[2025-11-12T22:25:46.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:46.673+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:25:46.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO CodeGenerator: Code generated in 22.101169 ms
[2025-11-12T22:25:46.720+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Registering RDD 77 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
[2025-11-12T22:25:46.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Got map stage job 18 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:25:46.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Final stage: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:46.723+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
[2025-11-12T22:25:46.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:46.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[77] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:46.731+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 101.2 KiB, free 433.0 MiB)
[2025-11-12T22:25:46.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 41.1 KiB, free 433.0 MiB)
[2025-11-12T22:25:46.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on eb021f2c8a8b:40023 (size: 41.1 KiB, free: 434.0 MiB)
[2025-11-12T22:25:46.736+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:46.736+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[77] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:25:46.736+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
[2025-11-12T22:25:46.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:25:46.755+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.5:42325 (size: 41.1 KiB, free: 434.0 MiB)
[2025-11-12T22:25:46.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.5:50960
[2025-11-12T22:25:46.823+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 85 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:25:46.824+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool
[2025-11-12T22:25:46.827+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0.101 s
[2025-11-12T22:25:46.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:25:46.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: running: Set()
[2025-11-12T22:25:46.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:25:46.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: failed: Set()
[2025-11-12T22:25:46.856+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO CodeGenerator: Code generated in 7.916047 ms
[2025-11-12T22:25:46.865+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:46.866+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Got job 19 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:25:46.867+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Final stage: ResultStage 29 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:46.868+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
[2025-11-12T22:25:46.868+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:46.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[80] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:46.870+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 12.5 KiB, free 432.9 MiB)
[2025-11-12T22:25:46.872+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 432.9 MiB)
[2025-11-12T22:25:46.873+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on eb021f2c8a8b:40023 (size: 5.9 KiB, free: 434.0 MiB)
[2025-11-12T22:25:46.873+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:46.873+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[80] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:25:46.874+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
[2025-11-12T22:25:46.875+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 26) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:25:46.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.18.0.5:43045 (size: 5.9 KiB, free: 434.2 MiB)
[2025-11-12T22:25:46.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.18.0.5:50962
[2025-11-12T22:25:46.919+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 26) in 45 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:25:46.920+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool
[2025-11-12T22:25:46.920+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: ResultStage 29 (count at NativeMethodAccessorImpl.java:0) finished in 0.051 s
[2025-11-12T22:25:46.921+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:25:46.921+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
[2025-11-12T22:25:46.922+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:46 INFO DAGScheduler: Job 19 finished: count at NativeMethodAccessorImpl.java:0, took 0.055183 s
[2025-11-12T22:25:46.923+0000] {spark_submit.py:571} INFO - Preparing to score 21 match(es) where both rikishi have profiles
[2025-11-12T22:25:47.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_25_piece0 on eb021f2c8a8b:40023 in memory (size: 39.7 KiB, free: 434.0 MiB)
[2025-11-12T22:25:47.111+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.18.0.5:42325 in memory (size: 39.7 KiB, free: 434.0 MiB)
[2025-11-12T22:25:47.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_23_piece0 on eb021f2c8a8b:40023 in memory (size: 29.0 KiB, free: 434.0 MiB)
[2025-11-12T22:25:47.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.5:42325 in memory (size: 29.0 KiB, free: 434.1 MiB)
[2025-11-12T22:25:47.118+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_27_piece0 on eb021f2c8a8b:40023 in memory (size: 5.9 KiB, free: 434.0 MiB)
[2025-11-12T22:25:47.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.18.0.5:43045 in memory (size: 5.9 KiB, free: 434.2 MiB)
[2025-11-12T22:25:47.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_18_piece0 on eb021f2c8a8b:40023 in memory (size: 20.4 KiB, free: 434.1 MiB)
[2025-11-12T22:25:47.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.5:43045 in memory (size: 20.4 KiB, free: 434.2 MiB)
[2025-11-12T22:25:47.126+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_22_piece0 on eb021f2c8a8b:40023 in memory (size: 29.3 KiB, free: 434.1 MiB)
[2025-11-12T22:25:47.127+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.18.0.5:43045 in memory (size: 29.3 KiB, free: 434.2 MiB)
[2025-11-12T22:25:47.128+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.18.0.5:42325 in memory (size: 29.3 KiB, free: 434.1 MiB)
[2025-11-12T22:25:47.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_26_piece0 on eb021f2c8a8b:40023 in memory (size: 41.1 KiB, free: 434.1 MiB)
[2025-11-12T22:25:47.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:47 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.18.0.5:42325 in memory (size: 41.1 KiB, free: 434.1 MiB)
[2025-11-12T22:25:47.589+0000] {spark_submit.py:571} INFO - Rows being sent to model.transform (sample):
[2025-11-12T22:25:49.560+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.562+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.563+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2244 = ) THEN false ELSE isnull(kimarite#2244) END OR CASE WHEN (kimarite#2244 = ) THEN true ELSE (kimarite#2244 = NA) END) THEN false ELSE CASE WHEN (kimarite#2244 = ) THEN true ELSE isnotnull(kimarite#2244) END END
[2025-11-12T22:25:49.571+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.572+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2698 = ) THEN false ELSE isnull(kimarite#2698) END OR CASE WHEN (kimarite#2698 = ) THEN true ELSE (kimarite#2698 = NA) END) THEN false ELSE CASE WHEN (kimarite#2698 = ) THEN true ELSE isnotnull(kimarite#2698) END END
[2025-11-12T22:25:49.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:49.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:25:49.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4564 = ) THEN false ELSE isnull(kimarite#4564) END OR CASE WHEN (kimarite#4564 = ) THEN true ELSE (kimarite#4564 = NA) END) THEN false ELSE CASE WHEN (kimarite#4564 = ) THEN true ELSE isnotnull(kimarite#4564) END END
[2025-11-12T22:25:49.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4768 = ) THEN false ELSE isnull(kimarite#4768) END OR CASE WHEN (kimarite#4768 = ) THEN true ELSE (kimarite#4768 = NA) END) THEN false ELSE CASE WHEN (kimarite#4768 = ) THEN true ELSE isnotnull(kimarite#4768) END END
[2025-11-12T22:25:49.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:49.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:25:49.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#3879 = ) THEN false ELSE isnull(kimarite#3879) END OR CASE WHEN (kimarite#3879 = ) THEN true ELSE (kimarite#3879 = NA) END) THEN false ELSE CASE WHEN (kimarite#3879 = ) THEN true ELSE isnotnull(kimarite#3879) END END
[2025-11-12T22:25:49.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4083 = ) THEN false ELSE isnull(kimarite#4083) END OR CASE WHEN (kimarite#4083 = ) THEN true ELSE (kimarite#4083 = NA) END) THEN false ELSE CASE WHEN (kimarite#4083 = ) THEN true ELSE isnotnull(kimarite#4083) END END
[2025-11-12T22:25:49.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7603 = ) THEN false ELSE isnull(kimarite#7603) END OR CASE WHEN (kimarite#7603 = ) THEN true ELSE (kimarite#7603 = NA) END) THEN false ELSE CASE WHEN (kimarite#7603 = ) THEN true ELSE isnotnull(kimarite#7603) END END
[2025-11-12T22:25:49.598+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.599+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7807 = ) THEN false ELSE isnull(kimarite#7807) END OR CASE WHEN (kimarite#7807 = ) THEN true ELSE (kimarite#7807 = NA) END) THEN false ELSE CASE WHEN (kimarite#7807 = ) THEN true ELSE isnotnull(kimarite#7807) END END
[2025-11-12T22:25:49.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:49.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:25:49.602+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.602+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#9439 = ) THEN false ELSE isnull(kimarite#9439) END OR CASE WHEN (kimarite#9439 = ) THEN true ELSE (kimarite#9439 = NA) END) THEN false ELSE CASE WHEN (kimarite#9439 = ) THEN true ELSE isnotnull(kimarite#9439) END END
[2025-11-12T22:25:49.604+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.605+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#9643 = ) THEN false ELSE isnull(kimarite#9643) END OR CASE WHEN (kimarite#9643 = ) THEN true ELSE (kimarite#9643 = NA) END) THEN false ELSE CASE WHEN (kimarite#9643 = ) THEN true ELSE isnotnull(kimarite#9643) END END
[2025-11-12T22:25:49.605+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:49.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:25:49.609+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.609+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#10051 = ) THEN false ELSE isnull(kimarite#10051) END OR CASE WHEN (kimarite#10051 = ) THEN true ELSE (kimarite#10051 = NA) END) THEN false ELSE CASE WHEN (kimarite#10051 = ) THEN true ELSE isnotnull(kimarite#10051) END END
[2025-11-12T22:25:49.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#10255 = ) THEN false ELSE isnull(kimarite#10255) END OR CASE WHEN (kimarite#10255 = ) THEN true ELSE (kimarite#10255 = NA) END) THEN false ELSE CASE WHEN (kimarite#10255 = ) THEN true ELSE isnotnull(kimarite#10255) END END
[2025-11-12T22:25:49.614+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.615+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11148 = ) THEN false ELSE isnull(kimarite#11148) END OR CASE WHEN (kimarite#11148 = ) THEN true ELSE (kimarite#11148 = NA) END) THEN false ELSE CASE WHEN (kimarite#11148 = ) THEN true ELSE isnotnull(kimarite#11148) END END
[2025-11-12T22:25:49.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11352 = ) THEN false ELSE isnull(kimarite#11352) END OR CASE WHEN (kimarite#11352 = ) THEN true ELSE (kimarite#11352 = NA) END) THEN false ELSE CASE WHEN (kimarite#11352 = ) THEN true ELSE isnotnull(kimarite#11352) END END
[2025-11-12T22:25:49.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:49.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:25:49.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.627+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11760 = ) THEN false ELSE isnull(kimarite#11760) END OR CASE WHEN (kimarite#11760 = ) THEN true ELSE (kimarite#11760 = NA) END) THEN false ELSE CASE WHEN (kimarite#11760 = ) THEN true ELSE isnotnull(kimarite#11760) END END
[2025-11-12T22:25:49.630+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11964 = ) THEN false ELSE isnull(kimarite#11964) END OR CASE WHEN (kimarite#11964 = ) THEN true ELSE (kimarite#11964 = NA) END) THEN false ELSE CASE WHEN (kimarite#11964 = ) THEN true ELSE isnotnull(kimarite#11964) END END
[2025-11-12T22:25:49.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:49.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:25:49.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#12372 = ) THEN false ELSE isnull(kimarite#12372) END OR CASE WHEN (kimarite#12372 = ) THEN true ELSE (kimarite#12372 = NA) END) THEN false ELSE CASE WHEN (kimarite#12372 = ) THEN true ELSE isnotnull(kimarite#12372) END END
[2025-11-12T22:25:49.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#12576 = ) THEN false ELSE isnull(kimarite#12576) END OR CASE WHEN (kimarite#12576 = ) THEN true ELSE (kimarite#12576 = NA) END) THEN false ELSE CASE WHEN (kimarite#12576 = ) THEN true ELSE isnotnull(kimarite#12576) END END
[2025-11-12T22:25:49.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:49.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14208 = ) THEN false ELSE isnull(kimarite#14208) END OR CASE WHEN (kimarite#14208 = ) THEN true ELSE (kimarite#14208 = NA) END) THEN false ELSE CASE WHEN (kimarite#14208 = ) THEN true ELSE isnotnull(kimarite#14208) END END
[2025-11-12T22:25:49.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14412 = ) THEN false ELSE isnull(kimarite#14412) END OR CASE WHEN (kimarite#14412 = ) THEN true ELSE (kimarite#14412 = NA) END) THEN false ELSE CASE WHEN (kimarite#14412 = ) THEN true ELSE isnotnull(kimarite#14412) END END
[2025-11-12T22:25:49.648+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:49.648+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:25:49.648+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.649+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16044 = ) THEN false ELSE isnull(kimarite#16044) END OR CASE WHEN (kimarite#16044 = ) THEN true ELSE (kimarite#16044 = NA) END) THEN false ELSE CASE WHEN (kimarite#16044 = ) THEN true ELSE isnotnull(kimarite#16044) END END
[2025-11-12T22:25:49.651+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16248 = ) THEN false ELSE isnull(kimarite#16248) END OR CASE WHEN (kimarite#16248 = ) THEN true ELSE (kimarite#16248 = NA) END) THEN false ELSE CASE WHEN (kimarite#16248 = ) THEN true ELSE isnotnull(kimarite#16248) END END
[2025-11-12T22:25:49.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:49.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:25:49.655+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16656 = ) THEN false ELSE isnull(kimarite#16656) END OR CASE WHEN (kimarite#16656 = ) THEN true ELSE (kimarite#16656 = NA) END) THEN false ELSE CASE WHEN (kimarite#16656 = ) THEN true ELSE isnotnull(kimarite#16656) END END
[2025-11-12T22:25:49.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:49.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16860 = ) THEN false ELSE isnull(kimarite#16860) END OR CASE WHEN (kimarite#16860 = ) THEN true ELSE (kimarite#16860 = NA) END) THEN false ELSE CASE WHEN (kimarite#16860 = ) THEN true ELSE isnotnull(kimarite#16860) END END
[2025-11-12T22:25:49.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_21_piece0 on eb021f2c8a8b:40023 in memory (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:25:49.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.18.0.5:43045 in memory (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:25:49.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.18.0.5:42325 in memory (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:25:49.898+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_19_piece0 on eb021f2c8a8b:40023 in memory (size: 46.9 KiB, free: 434.2 MiB)
[2025-11-12T22:25:49.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.5:43045 in memory (size: 46.9 KiB, free: 434.3 MiB)
[2025-11-12T22:25:49.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.5:42325 in memory (size: 46.9 KiB, free: 434.2 MiB)
[2025-11-12T22:25:49.906+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_20_piece0 on eb021f2c8a8b:40023 in memory (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:25:49.907+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.5:42325 in memory (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:25:49.908+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.5:43045 in memory (size: 37.4 KiB, free: 434.4 MiB)
[2025-11-12T22:25:49.914+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_16_piece0 on eb021f2c8a8b:40023 in memory (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:49.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.5:43045 in memory (size: 37.3 KiB, free: 434.4 MiB)
[2025-11-12T22:25:49.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.5:42325 in memory (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:49.923+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_24_piece0 on eb021f2c8a8b:40023 in memory (size: 108.4 KiB, free: 434.4 MiB)
[2025-11-12T22:25:49.924+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Registering RDD 82 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 7
[2025-11-12T22:25:49.925+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Got map stage job 20 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:25:49.925+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Final stage: ShuffleMapStage 30 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:49.926+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:49.926+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:49.926+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[82] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:49.927+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.5:42325 in memory (size: 108.4 KiB, free: 434.4 MiB)
[2025-11-12T22:25:49.927+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 16.7 KiB, free 434.4 MiB)
[2025-11-12T22:25:49.927+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 434.4 MiB)
[2025-11-12T22:25:49.928+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on eb021f2c8a8b:40023 (size: 8.8 KiB, free: 434.4 MiB)
[2025-11-12T22:25:49.928+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:49.928+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[82] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:25:49.928+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO TaskSchedulerImpl: Adding task set 30.0 with 2 tasks resource profile 0
[2025-11-12T22:25:49.929+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 27) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 11355 bytes)
[2025-11-12T22:25:49.929+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 28) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11479 bytes)
[2025-11-12T22:25:49.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO CodeGenerator: Code generated in 10.793173 ms
[2025-11-12T22:25:49.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.18.0.5:42325 (size: 8.8 KiB, free: 434.4 MiB)
[2025-11-12T22:25:49.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.18.0.5:43045 (size: 8.8 KiB, free: 434.4 MiB)
[2025-11-12T22:25:49.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 221.4 KiB, free 434.2 MiB)
[2025-11-12T22:25:49.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 434.1 MiB)
[2025-11-12T22:25:49.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 434.4 MiB)
[2025-11-12T22:25:49.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO SparkContext: Created broadcast 29 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:49.950+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:25:49.961+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO CodeGenerator: Code generated in 7.235917 ms
[2025-11-12T22:25:49.964+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 221.4 KiB, free 433.9 MiB)
[2025-11-12T22:25:49.969+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.9 MiB)
[2025-11-12T22:25:49.970+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:49.970+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO SparkContext: Created broadcast 30 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:49.971+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:25:49.974+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Registering RDD 90 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 8
[2025-11-12T22:25:49.975+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Got map stage job 21 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:25:49.975+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:49.976+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:49.976+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:49.976+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[90] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:49.976+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 26.9 KiB, free 433.8 MiB)
[2025-11-12T22:25:49.977+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 433.8 MiB)
[2025-11-12T22:25:49.978+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on eb021f2c8a8b:40023 (size: 9.5 KiB, free: 434.3 MiB)
[2025-11-12T22:25:49.978+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:49.978+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[90] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:25:49.979+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:49 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks resource profile 0
[2025-11-12T22:25:50.010+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 29) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:25:50.011+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO CodeGenerator: Code generated in 28.085931 ms
[2025-11-12T22:25:50.015+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 27) in 82 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:25:50.017+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 221.4 KiB, free 433.6 MiB)
[2025-11-12T22:25:50.018+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 30) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:25:50.019+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 28) in 88 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:25:50.021+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2025-11-12T22:25:50.021+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: ShuffleMapStage 30 (showString at NativeMethodAccessorImpl.java:0) finished in 0.092 s
[2025-11-12T22:25:50.022+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:25:50.022+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: running: Set(ShuffleMapStage 31)
[2025-11-12T22:25:50.023+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:25:50.024+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: failed: Set()
[2025-11-12T22:25:50.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.6 MiB)
[2025-11-12T22:25:50.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:50.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO SparkContext: Created broadcast 32 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:50.029+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:25:50.032+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.18.0.5:42325 (size: 9.5 KiB, free: 434.4 MiB)
[2025-11-12T22:25:50.041+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.18.0.5:43045 (size: 9.5 KiB, free: 434.4 MiB)
[2025-11-12T22:25:50.048+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Registering RDD 94 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 9
[2025-11-12T22:25:50.049+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Got map stage job 22 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:25:50.050+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:50.051+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:50.051+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:50.051+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[94] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:50.053+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 52.1 KiB, free 433.5 MiB)
[2025-11-12T22:25:50.054+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 433.5 MiB)
[2025-11-12T22:25:50.054+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on eb021f2c8a8b:40023 (size: 22.1 KiB, free: 434.3 MiB)
[2025-11-12T22:25:50.055+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:50.055+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[94] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:25:50.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks resource profile 0
[2025-11-12T22:25:50.075+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO CodeGenerator: Code generated in 24.598778 ms
[2025-11-12T22:25:50.076+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:50.078+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 221.4 KiB, free 433.3 MiB)
[2025-11-12T22:25:50.085+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.3 MiB)
[2025-11-12T22:25:50.087+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:25:50.088+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO SparkContext: Created broadcast 34 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:25:50.088+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:25:50.094+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Registering RDD 98 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 10
[2025-11-12T22:25:50.095+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Got map stage job 23 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:25:50.096+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:50.096+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:25:50.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:50.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[98] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:50.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 43.7 KiB, free 433.2 MiB)
[2025-11-12T22:25:50.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 433.2 MiB)
[2025-11-12T22:25:50.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on eb021f2c8a8b:40023 (size: 18.9 KiB, free: 434.2 MiB)
[2025-11-12T22:25:50.099+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:50.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[98] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:25:50.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO TaskSchedulerImpl: Adding task set 33.0 with 2 tasks resource profile 0
[2025-11-12T22:25:50.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:50.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:50.165+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:50.167+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:50.168+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:25:50.173+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:50.175+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:25:50.180+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:50.180+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:50.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:50.187+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:25:50.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:50.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:25:50.196+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:50.197+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:50.208+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:50.208+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:25:50.210+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:50.210+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:25:50.214+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:50.215+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:50.220+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:50.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:25:50.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:50.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:50 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:25:52.391+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:52 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 31) (172.18.0.5, executor 1, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:25:52.392+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:52 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 30) in 2377 ms on 172.18.0.5 (executor 1) (1/4)
[2025-11-12T22:25:52.418+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:52 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:54.772+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:54 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 32) (172.18.0.5, executor 1, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:25:54.773+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:54 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 31) in 2381 ms on 172.18.0.5 (executor 1) (2/4)
[2025-11-12T22:25:54.914+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:54 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 33) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:25:54.914+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:54 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 29) in 4905 ms on 172.18.0.5 (executor 0) (3/4)
[2025-11-12T22:25:54.923+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:54 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.18.0.5:42325 (size: 22.1 KiB, free: 434.3 MiB)
[2025-11-12T22:25:54.986+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:54 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:57.272+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 34) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:25:57.273+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 32) in 2502 ms on 172.18.0.5 (executor 1) (4/4)
[2025-11-12T22:25:57.274+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2025-11-12T22:25:57.275+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: ShuffleMapStage 31 (showString at NativeMethodAccessorImpl.java:0) finished in 7.298 s
[2025-11-12T22:25:57.275+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:25:57.276+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: running: Set(ShuffleMapStage 33, ShuffleMapStage 32)
[2025-11-12T22:25:57.276+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:25:57.276+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: failed: Set()
[2025-11-12T22:25:57.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.18.0.5:43045 (size: 22.1 KiB, free: 434.3 MiB)
[2025-11-12T22:25:57.296+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:57.297+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:57.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:57.301+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:25:57.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:57.304+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:25:57.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:57.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:57.310+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:57.311+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:25:57.313+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:57.313+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:25:57.319+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:57.319+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:57.331+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Removed broadcast_28_piece0 on eb021f2c8a8b:40023 in memory (size: 8.8 KiB, free: 434.2 MiB)
[2025-11-12T22:25:57.333+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.18.0.5:43045 in memory (size: 8.8 KiB, free: 434.3 MiB)
[2025-11-12T22:25:57.334+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.18.0.5:42325 in memory (size: 8.8 KiB, free: 434.3 MiB)
[2025-11-12T22:25:57.335+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:57.336+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:25:57.345+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:57.346+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:25:57.347+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Removed broadcast_31_piece0 on eb021f2c8a8b:40023 in memory (size: 9.5 KiB, free: 434.2 MiB)
[2025-11-12T22:25:57.348+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.18.0.5:43045 in memory (size: 9.5 KiB, free: 434.3 MiB)
[2025-11-12T22:25:57.348+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.18.0.5:42325 in memory (size: 9.5 KiB, free: 434.3 MiB)
[2025-11-12T22:25:57.350+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:57.351+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:57.356+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:57.357+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:25:57.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:57.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:25:57.384+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:57.404+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:25:57.408+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:25:57.413+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:25:57.418+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:25:57.465+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:25:57.466+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 33) in 2553 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:25:57.475+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.5:42325 (size: 18.9 KiB, free: 434.3 MiB)
[2025-11-12T22:25:57.496+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO CodeGenerator: Code generated in 17.54643 ms
[2025-11-12T22:25:57.504+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO CodeGenerator: Code generated in 5.219017 ms
[2025-11-12T22:25:57.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:25:57.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Registering RDD 103 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 11
[2025-11-12T22:25:57.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Got map stage job 24 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:25:57.518+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Final stage: ShuffleMapStage 35 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:57.518+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
[2025-11-12T22:25:57.519+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:57.519+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[103] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:57.523+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 63.5 KiB, free 433.2 MiB)
[2025-11-12T22:25:57.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 433.2 MiB)
[2025-11-12T22:25:57.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on eb021f2c8a8b:40023 (size: 27.9 KiB, free: 434.2 MiB)
[2025-11-12T22:25:57.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:57.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[103] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:25:57.531+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO TaskSchedulerImpl: Adding task set 35.0 with 2 tasks resource profile 0
[2025-11-12T22:25:57.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO CodeGenerator: Code generated in 22.788749 ms
[2025-11-12T22:25:57.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO CodeGenerator: Code generated in 5.199916 ms
[2025-11-12T22:25:57.562+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Registering RDD 108 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 12
[2025-11-12T22:25:57.563+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Got map stage job 25 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:25:57.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Final stage: ShuffleMapStage 36 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:57.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
[2025-11-12T22:25:57.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:57.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[108] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:57.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 64.7 KiB, free 433.1 MiB)
[2025-11-12T22:25:57.567+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 28.4 KiB, free 433.1 MiB)
[2025-11-12T22:25:57.567+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on eb021f2c8a8b:40023 (size: 28.4 KiB, free: 434.2 MiB)
[2025-11-12T22:25:57.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:57.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[108] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:25:57.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO TaskSchedulerImpl: Adding task set 36.0 with 2 tasks resource profile 0
[2025-11-12T22:25:57.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:57.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:57.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:57.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:25:57.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:57.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:25:57.590+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:57.590+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:57.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:57.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:25:57.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:57.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:25:57.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:57.598+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:57.600+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:57.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:25:57.602+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:57.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:25:57.605+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:57.605+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:57.608+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:57.608+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:25:57.609+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:57.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:25:59.576+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 36) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:25:59.576+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 34) in 2304 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:25:59.577+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-11-12T22:25:59.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: ShuffleMapStage 32 (showString at NativeMethodAccessorImpl.java:0) finished in 9.528 s
[2025-11-12T22:25:59.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:25:59.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: running: Set(ShuffleMapStage 33, ShuffleMapStage 35, ShuffleMapStage 36)
[2025-11-12T22:25:59.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:25:59.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: failed: Set()
[2025-11-12T22:25:59.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.5:43045 (size: 18.9 KiB, free: 434.3 MiB)
[2025-11-12T22:25:59.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:25:59.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 2122 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:25:59.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.18.0.5:42325 (size: 27.9 KiB, free: 434.2 MiB)
[2025-11-12T22:25:59.604+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:59.605+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:59.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:59.608+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:25:59.609+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:59.609+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:25:59.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:59.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:59.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:59.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:25:59.618+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:59.618+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:25:59.622+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:59.623+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:59.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.18.0.5:50960
[2025-11-12T22:25:59.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:59.627+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:25:59.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:59.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:25:59.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:59.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:59.634+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:25:59.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:59.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:25:59.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:59.638+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:25:59.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.683+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.694+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.696+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.697+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.699+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:25:59.775+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:25:59.803+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO CodeGenerator: Code generated in 22.460536 ms
[2025-11-12T22:25:59.814+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: Registering RDD 112 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 13
[2025-11-12T22:25:59.817+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: Got map stage job 26 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:25:59.819+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: Final stage: ShuffleMapStage 38 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:25:59.820+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
[2025-11-12T22:25:59.820+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:25:59.821+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[112] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:25:59.821+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 70.6 KiB, free 433.0 MiB)
[2025-11-12T22:25:59.826+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.0 MiB)
[2025-11-12T22:25:59.827+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on eb021f2c8a8b:40023 (size: 28.0 KiB, free: 434.1 MiB)
[2025-11-12T22:25:59.828+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:25:59.836+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[112] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:25:59.837+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
[2025-11-12T22:25:59.849+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:59.850+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:59.856+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:59.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:25:59.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:59.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:25:59.863+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:59.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:59.870+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:59.871+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:25:59.872+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:59.873+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:25:59.879+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:59.880+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:59.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:59.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:25:59.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:59.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:25:59.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:25:59.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:25:59.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:25:59.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:25:59.902+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:25:59.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:25:59.936+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO BlockManagerInfo: Removed broadcast_33_piece0 on eb021f2c8a8b:40023 in memory (size: 22.1 KiB, free: 434.2 MiB)
[2025-11-12T22:25:59.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.18.0.5:42325 in memory (size: 22.1 KiB, free: 434.2 MiB)
[2025-11-12T22:25:59.940+0000] {spark_submit.py:571} INFO - 25/11/12 22:25:59 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.18.0.5:43045 in memory (size: 22.1 KiB, free: 434.2 MiB)
[2025-11-12T22:26:01.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 38) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:26:01.743+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 2155 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:26:01.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 39) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:26:01.780+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 36) in 2205 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:26:01.781+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool
[2025-11-12T22:26:01.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: ShuffleMapStage 33 (showString at NativeMethodAccessorImpl.java:0) finished in 11.685 s
[2025-11-12T22:26:01.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:01.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: running: Set(ShuffleMapStage 38, ShuffleMapStage 35, ShuffleMapStage 36)
[2025-11-12T22:26:01.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:01.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:01.790+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.18.0.5:43045 (size: 28.4 KiB, free: 434.2 MiB)
[2025-11-12T22:26:01.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:01.803+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:01.805+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:01.805+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:01.806+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:01.807+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:01.811+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:01.812+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:01.814+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:01.814+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:01.816+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:01.816+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:01.819+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:01.819+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:01.822+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:01.822+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:01.824+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:01.824+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:01.826+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:01.827+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:01.829+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:01.829+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:01.830+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:01.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:01.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.18.0.5:50962
[2025-11-12T22:26:01.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:01.854+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:01.855+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:01.856+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:01.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:01.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:01.859+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:01.860+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:01.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO CodeGenerator: Code generated in 16.926636 ms
[2025-11-12T22:26:01.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:01.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:01.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:01.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:01.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:01.950+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: Got job 27 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:26:01.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: Final stage: ResultStage 40 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:01.954+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
[2025-11-12T22:26:01.954+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:01.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[115] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:01.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:01.956+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:01.956+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 45.4 KiB, free 433.0 MiB)
[2025-11-12T22:26:01.956+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 20.4 KiB, free 433.0 MiB)
[2025-11-12T22:26:01.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:01.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:01.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on eb021f2c8a8b:40023 (size: 20.4 KiB, free: 434.1 MiB)
[2025-11-12T22:26:01.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:01.958+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[115] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:01.958+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-11-12T22:26:01.959+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:01.959+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:01.963+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:01.963+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:01.968+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:01.969+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:01.973+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:01.974+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:01.975+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:01.975+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:01.978+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:01.979+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:01.981+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:01.982+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:01.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:01.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:03.336+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 40) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:26:03.337+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 38) in 1595 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:26:03.337+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool
[2025-11-12T22:26:03.338+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: ShuffleMapStage 35 (showString at NativeMethodAccessorImpl.java:0) finished in 5.817 s
[2025-11-12T22:26:03.338+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:03.338+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: running: Set(ShuffleMapStage 38, ShuffleMapStage 36, ResultStage 40)
[2025-11-12T22:26:03.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:03.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:03.344+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.18.0.5:42325 (size: 28.4 KiB, free: 434.2 MiB)
[2025-11-12T22:26:03.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:03.360+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:03.363+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:03.364+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:03.365+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:03.365+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:03.368+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:03.368+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:03.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:03.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:03.379+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:03.379+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:03.380+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO BlockManagerInfo: Removed broadcast_36_piece0 on eb021f2c8a8b:40023 in memory (size: 27.9 KiB, free: 434.2 MiB)
[2025-11-12T22:26:03.381+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.18.0.5:42325 in memory (size: 27.9 KiB, free: 434.2 MiB)
[2025-11-12T22:26:03.384+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:03.384+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:03.386+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:03.387+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:03.388+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:03.388+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:03.390+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:03.390+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:03.392+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:03.392+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:03.393+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:03.394+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:03.414+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:26:03.415+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:26:03.452+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:26:03.460+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO CodeGenerator: Code generated in 6.187769 ms
[2025-11-12T22:26:03.468+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:03.474+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-11-12T22:26:03.475+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: Final stage: ResultStage 42 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:03.475+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
[2025-11-12T22:26:03.476+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:03.476+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[118] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:03.476+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 60.6 KiB, free 433.0 MiB)
[2025-11-12T22:26:03.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 26.3 KiB, free 433.0 MiB)
[2025-11-12T22:26:03.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on eb021f2c8a8b:40023 (size: 26.3 KiB, free: 434.1 MiB)
[2025-11-12T22:26:03.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:03.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 42 (MapPartitionsRDD[118] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:03.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO TaskSchedulerImpl: Adding task set 42.0 with 2 tasks resource profile 0
[2025-11-12T22:26:03.959+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 41) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:26:03.960+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 39) in 2180 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:26:03.967+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.18.0.5:43045 (size: 28.0 KiB, free: 434.2 MiB)
[2025-11-12T22:26:03.991+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:03 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.18.0.5:50962
[2025-11-12T22:26:04.173+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:04.174+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 41) in 215 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:04.177+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool
[2025-11-12T22:26:04.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: ShuffleMapStage 38 (showString at NativeMethodAccessorImpl.java:0) finished in 4.358 s
[2025-11-12T22:26:04.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:04.179+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: running: Set(ResultStage 42, ShuffleMapStage 36, ResultStage 40)
[2025-11-12T22:26:04.179+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:04.180+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:04.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.18.0.5:43045 (size: 20.4 KiB, free: 434.2 MiB)
[2025-11-12T22:26:04.192+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.18.0.5:50962
[2025-11-12T22:26:04.199+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.200+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.205+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.205+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:04.207+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.207+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:04.211+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.212+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.215+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.216+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:04.218+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.219+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:04.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.224+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:04.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:04.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.229+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.230+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 43) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:04.230+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 58 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:04.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-11-12T22:26:04.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: ResultStage 40 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 2.280 s
[2025-11-12T22:26:04.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:04.232+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
[2025-11-12T22:26:04.232+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Job 27 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 2.283249 s
[2025-11-12T22:26:04.232+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.233+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:04.234+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.235+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:04.240+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 46.9 KiB, free 432.9 MiB)
[2025-11-12T22:26:04.241+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on eb021f2c8a8b:40023 (size: 46.9 KiB, free: 434.1 MiB)
[2025-11-12T22:26:04.242+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 41 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:04.242+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.18.0.5:43045 (size: 26.3 KiB, free: 434.1 MiB)
[2025-11-12T22:26:04.250+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.18.0.5:50962
[2025-11-12T22:26:04.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.265+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.268+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.274+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.275+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.276+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.278+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.280+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.281+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.282+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.283+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.288+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:04.357+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.358+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO CodeGenerator: Code generated in 12.140428 ms
[2025-11-12T22:26:04.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:04.360+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.360+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:04.361+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO CodeGenerator: Code generated in 12.259833 ms
[2025-11-12T22:26:04.361+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.362+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.363+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.363+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:04.364+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.364+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:04.367+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.367+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.368+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.369+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:04.369+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.369+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:04.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:04.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.373+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:04.373+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Got job 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:26:04.373+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Final stage: ResultStage 45 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:04.374+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
[2025-11-12T22:26:04.374+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:04.374+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[123] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:04.375+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.376+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:04.381+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 67.3 KiB, free 432.9 MiB)
[2025-11-12T22:26:04.388+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 432.9 MiB)
[2025-11-12T22:26:04.389+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on eb021f2c8a8b:40023 (size: 27.2 KiB, free: 434.1 MiB)
[2025-11-12T22:26:04.390+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:04.390+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[123] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:04.394+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
[2025-11-12T22:26:04.395+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Got job 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:26:04.395+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Final stage: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:04.396+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
[2025-11-12T22:26:04.397+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:04.398+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[126] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:04.398+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 70.2 KiB, free 432.8 MiB)
[2025-11-12T22:26:04.399+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 432.8 MiB)
[2025-11-12T22:26:04.399+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on eb021f2c8a8b:40023 (size: 27.9 KiB, free: 434.0 MiB)
[2025-11-12T22:26:04.400+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:04.400+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[126] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:04.401+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2025-11-12T22:26:04.422+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added taskresult_43 in memory on 172.18.0.5:43045 (size: 1232.3 KiB, free: 432.9 MiB)
[2025-11-12T22:26:04.428+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 44) (172.18.0.5, executor 1, partition 1, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:04.448+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TransportClientFactory: Successfully created connection to /172.18.0.5:43045 after 2 ms (0 ms spent in bootstraps)
[2025-11-12T22:26:04.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 43) in 247 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:26:04.489+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed taskresult_43 on 172.18.0.5:43045 in memory (size: 1232.3 KiB, free: 434.1 MiB)
[2025-11-12T22:26:04.491+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_35_piece0 on eb021f2c8a8b:40023 in memory (size: 18.9 KiB, free: 434.1 MiB)
[2025-11-12T22:26:04.493+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.18.0.5:43045 in memory (size: 18.9 KiB, free: 434.2 MiB)
[2025-11-12T22:26:04.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.18.0.5:42325 in memory (size: 18.9 KiB, free: 434.3 MiB)
[2025-11-12T22:26:04.500+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_39_piece0 on eb021f2c8a8b:40023 in memory (size: 20.4 KiB, free: 434.1 MiB)
[2025-11-12T22:26:04.503+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.18.0.5:43045 in memory (size: 20.4 KiB, free: 434.2 MiB)
[2025-11-12T22:26:04.512+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_38_piece0 on eb021f2c8a8b:40023 in memory (size: 28.0 KiB, free: 434.1 MiB)
[2025-11-12T22:26:04.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.18.0.5:43045 in memory (size: 28.0 KiB, free: 434.2 MiB)
[2025-11-12T22:26:04.562+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added taskresult_44 in memory on 172.18.0.5:43045 (size: 1257.6 KiB, free: 433.0 MiB)
[2025-11-12T22:26:04.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:04.573+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 44) in 145 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:26:04.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-11-12T22:26:04.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: ResultStage 42 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.103 s
[2025-11-12T22:26:04.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed taskresult_44 on 172.18.0.5:43045 in memory (size: 1257.6 KiB, free: 434.2 MiB)
[2025-11-12T22:26:04.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:04.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
[2025-11-12T22:26:04.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.106636 s
[2025-11-12T22:26:04.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.18.0.5:43045 (size: 27.2 KiB, free: 434.2 MiB)
[2025-11-12T22:26:04.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO CodeGenerator: Code generated in 4.921614 ms
[2025-11-12T22:26:04.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.18.0.5:50962
[2025-11-12T22:26:04.668+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 46) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:04.669+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 103 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:04.669+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool
[2025-11-12T22:26:04.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: ResultStage 45 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.289 s
[2025-11-12T22:26:04.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:04.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
[2025-11-12T22:26:04.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Job 29 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.297124 s
[2025-11-12T22:26:04.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 56.2 KiB, free 432.9 MiB)
[2025-11-12T22:26:04.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on eb021f2c8a8b:40023 (size: 56.2 KiB, free: 434.0 MiB)
[2025-11-12T22:26:04.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 45 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:04.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.18.0.5:43045 (size: 27.9 KiB, free: 434.1 MiB)
[2025-11-12T22:26:04.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 428.9 MiB)
[2025-11-12T22:26:04.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on eb021f2c8a8b:40023 (size: 4.0 MiB, free: 430.0 MiB)
[2025-11-12T22:26:04.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_44_piece1 stored as bytes in memory (estimated size 1049.2 KiB, free 427.9 MiB)
[2025-11-12T22:26:04.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_44_piece1 in memory on eb021f2c8a8b:40023 (size: 1049.2 KiB, free: 429.0 MiB)
[2025-11-12T22:26:04.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 44 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:04.699+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:04.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:04.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.704+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.704+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.704+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:04.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:04.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:04.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:04.712+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.712+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:04.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:04.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:04.715+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:04.731+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 46) in 63 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:04.732+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-11-12T22:26:04.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: ResultStage 46 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.337 s
[2025-11-12T22:26:04.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:04.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
[2025-11-12T22:26:04.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Job 30 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.360317 s
[2025-11-12T22:26:04.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 90.6 KiB, free 427.8 MiB)
[2025-11-12T22:26:04.739+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on eb021f2c8a8b:40023 (size: 90.6 KiB, free: 428.9 MiB)
[2025-11-12T22:26:04.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 46 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:04.787+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO CodeGenerator: Code generated in 11.794513 ms
[2025-11-12T22:26:04.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TorrentBroadcast: Started reading broadcast variable 41 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:04.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TorrentBroadcast: Reading broadcast variable 41 took 1 ms
[2025-11-12T22:26:04.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO CodeGenerator: Code generated in 4.900313 ms
[2025-11-12T22:26:04.804+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 221.3 KiB, free 427.6 MiB)
[2025-11-12T22:26:04.810+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 427.6 MiB)
[2025-11-12T22:26:04.810+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 428.9 MiB)
[2025-11-12T22:26:04.811+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 47 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:04.811+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:04.821+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO CodeGenerator: Code generated in 4.522397 ms
[2025-11-12T22:26:04.822+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 221.3 KiB, free 427.3 MiB)
[2025-11-12T22:26:04.830+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_43_piece0 on eb021f2c8a8b:40023 in memory (size: 27.9 KiB, free: 428.9 MiB)
[2025-11-12T22:26:04.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 427.4 MiB)
[2025-11-12T22:26:04.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 428.9 MiB)
[2025-11-12T22:26:04.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.18.0.5:43045 in memory (size: 27.9 KiB, free: 434.2 MiB)
[2025-11-12T22:26:04.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 48 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:04.833+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:04.835+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_40_piece0 on eb021f2c8a8b:40023 in memory (size: 26.3 KiB, free: 428.9 MiB)
[2025-11-12T22:26:04.836+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.18.0.5:43045 in memory (size: 26.3 KiB, free: 434.2 MiB)
[2025-11-12T22:26:04.840+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_42_piece0 on eb021f2c8a8b:40023 in memory (size: 27.2 KiB, free: 428.9 MiB)
[2025-11-12T22:26:04.841+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.18.0.5:43045 in memory (size: 27.2 KiB, free: 434.2 MiB)
[2025-11-12T22:26:04.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Registering RDD 135 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 14
[2025-11-12T22:26:04.849+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Got map stage job 31 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:26:04.849+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Final stage: ShuffleMapStage 47 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:04.850+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:04.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:04.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[135] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:04.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 120.4 KiB, free 427.5 MiB)
[2025-11-12T22:26:04.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 43.7 KiB, free 427.4 MiB)
[2025-11-12T22:26:04.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on eb021f2c8a8b:40023 (size: 43.7 KiB, free: 428.9 MiB)
[2025-11-12T22:26:04.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:04.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[135] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:26:04.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Adding task set 47.0 with 4 tasks resource profile 0
[2025-11-12T22:26:04.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 47) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:26:04.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.860+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.865+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.866+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.866+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.18.0.5:43045 (size: 43.7 KiB, free: 434.2 MiB)
[2025-11-12T22:26:04.868+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.870+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:04.870+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:04.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.18.0.5:43045 (size: 46.9 KiB, free: 434.1 MiB)
[2025-11-12T22:26:04.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.18.0.5:43045 (size: 56.2 KiB, free: 434.1 MiB)
[2025-11-12T22:26:04.926+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TorrentBroadcast: Started reading broadcast variable 44 with 2 pieces (estimated total size 8.0 MiB)
[2025-11-12T22:26:04.928+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TorrentBroadcast: Reading broadcast variable 44 took 0 ms
[2025-11-12T22:26:04.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TorrentBroadcast: Started reading broadcast variable 46 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:04.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TorrentBroadcast: Reading broadcast variable 46 took 0 ms
[2025-11-12T22:26:04.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TorrentBroadcast: Started reading broadcast variable 45 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:04.950+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TorrentBroadcast: Reading broadcast variable 45 took 0 ms
[2025-11-12T22:26:04.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.0 MiB)
[2025-11-12T22:26:04.969+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO CodeGenerator: Code generated in 14.243919 ms
[2025-11-12T22:26:04.971+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 222.7 KiB, free 427.2 MiB)
[2025-11-12T22:26:04.979+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 427.2 MiB)
[2025-11-12T22:26:04.980+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on eb021f2c8a8b:40023 (size: 37.8 KiB, free: 428.9 MiB)
[2025-11-12T22:26:04.981+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 50 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:04.981+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:04.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Registering RDD 139 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 15
[2025-11-12T22:26:04.988+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Got map stage job 32 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:04.988+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Final stage: ShuffleMapStage 48 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:04.988+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:04.989+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:04.989+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[139] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:04.989+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 37.7 KiB, free 427.1 MiB)
[2025-11-12T22:26:04.990+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 427.1 MiB)
[2025-11-12T22:26:04.990+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on eb021f2c8a8b:40023 (size: 13.5 KiB, free: 428.8 MiB)
[2025-11-12T22:26:04.990+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:04.991+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[139] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:04.991+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:04 INFO TaskSchedulerImpl: Adding task set 48.0 with 2 tasks resource profile 0
[2025-11-12T22:26:05.166+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 48) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:26:05.167+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 40) in 1831 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:26:05.168+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-11-12T22:26:05.168+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: ShuffleMapStage 36 (showString at NativeMethodAccessorImpl.java:0) finished in 7.603 s
[2025-11-12T22:26:05.168+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:05.169+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: running: Set(ShuffleMapStage 48, ShuffleMapStage 47)
[2025-11-12T22:26:05.169+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:05.170+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:05.176+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.18.0.5:42325 (size: 43.7 KiB, free: 434.2 MiB)
[2025-11-12T22:26:05.182+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:05.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:05.187+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:05.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:05.198+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:26:05.199+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:26:05.208+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.18.0.5:42325 (size: 46.9 KiB, free: 434.2 MiB)
[2025-11-12T22:26:05.215+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.18.0.5:42325 (size: 56.2 KiB, free: 434.1 MiB)
[2025-11-12T22:26:05.239+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:26:05.251+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO CodeGenerator: Code generated in 9.684021 ms
[2025-11-12T22:26:05.261+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:05.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: Got job 33 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-11-12T22:26:05.264+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: Final stage: ResultStage 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:05.265+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
[2025-11-12T22:26:05.265+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:05.265+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[142] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:05.267+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 61.9 KiB, free 427.1 MiB)
[2025-11-12T22:26:05.268+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 26.7 KiB, free 427.0 MiB)
[2025-11-12T22:26:05.268+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on eb021f2c8a8b:40023 (size: 26.7 KiB, free: 428.8 MiB)
[2025-11-12T22:26:05.269+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:05.269+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 51 (MapPartitionsRDD[142] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:05.269+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO TaskSchedulerImpl: Adding task set 51.0 with 2 tasks resource profile 0
[2025-11-12T22:26:05.273+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:05 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.1 MiB)
[2025-11-12T22:26:06.375+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:06 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 49) (172.18.0.5, executor 1, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:26:06.376+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:06 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 47) in 1523 ms on 172.18.0.5 (executor 1) (1/4)
[2025-11-12T22:26:06.414+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:06 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.0 MiB)
[2025-11-12T22:26:06.898+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:06 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 50) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:26:06.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:06 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 48) in 1732 ms on 172.18.0.5 (executor 0) (2/4)
[2025-11-12T22:26:06.921+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:06 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.0 MiB)
[2025-11-12T22:26:07.609+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:07 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 51) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:26:07.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:07 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 49) in 1235 ms on 172.18.0.5 (executor 1) (3/4)
[2025-11-12T22:26:07.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:07 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.18.0.5:43045 (size: 13.5 KiB, free: 434.0 MiB)
[2025-11-12T22:26:07.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:07 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.18.0.5:43045 (size: 4.0 MiB, free: 430.0 MiB)
[2025-11-12T22:26:07.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:07 INFO BlockManagerInfo: Added broadcast_44_piece1 in memory on 172.18.0.5:43045 (size: 1049.2 KiB, free: 429.0 MiB)
[2025-11-12T22:26:07.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:07 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.18.0.5:43045 (size: 90.6 KiB, free: 428.9 MiB)
[2025-11-12T22:26:07.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:07 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.18.0.5:43045 (size: 37.8 KiB, free: 428.8 MiB)
[2025-11-12T22:26:08.269+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 52) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:26:08.270+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 50) in 1371 ms on 172.18.0.5 (executor 0) (4/4)
[2025-11-12T22:26:08.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool
[2025-11-12T22:26:08.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: ShuffleMapStage 47 (showString at NativeMethodAccessorImpl.java:0) finished in 3.423 s
[2025-11-12T22:26:08.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:08.272+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: running: Set(ResultStage 51, ShuffleMapStage 48)
[2025-11-12T22:26:08.272+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:08.272+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:08.277+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.18.0.5:42325 (size: 13.5 KiB, free: 434.0 MiB)
[2025-11-12T22:26:08.282+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:08.282+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:08.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:08.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:08.296+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:08.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:08.299+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO BlockManagerInfo: Added broadcast_44_piece1 in memory on 172.18.0.5:42325 (size: 1049.2 KiB, free: 433.0 MiB)
[2025-11-12T22:26:08.299+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:08.301+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:08.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.18.0.5:42325 (size: 4.0 MiB, free: 429.0 MiB)
[2025-11-12T22:26:08.334+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.18.0.5:42325 (size: 90.6 KiB, free: 428.9 MiB)
[2025-11-12T22:26:08.341+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:26:08.342+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:26:08.343+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.18.0.5:42325 (size: 37.8 KiB, free: 428.9 MiB)
[2025-11-12T22:26:08.365+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO CodeGenerator: Code generated in 18.150789 ms
[2025-11-12T22:26:08.373+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: Registering RDD 146 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 16
[2025-11-12T22:26:08.376+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: Got map stage job 34 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:26:08.376+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: Final stage: ShuffleMapStage 53 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:08.376+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
[2025-11-12T22:26:08.377+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:08.377+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[146] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:08.377+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 133.5 KiB, free 426.9 MiB)
[2025-11-12T22:26:08.382+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 48.6 KiB, free 426.8 MiB)
[2025-11-12T22:26:08.383+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on eb021f2c8a8b:40023 (size: 48.6 KiB, free: 428.8 MiB)
[2025-11-12T22:26:08.384+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:08.390+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[146] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:08.390+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2025-11-12T22:26:08.451+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO BlockManagerInfo: Removed broadcast_37_piece0 on eb021f2c8a8b:40023 in memory (size: 28.4 KiB, free: 428.8 MiB)
[2025-11-12T22:26:08.453+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.18.0.5:42325 in memory (size: 28.4 KiB, free: 428.9 MiB)
[2025-11-12T22:26:08.453+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:08 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.18.0.5:43045 in memory (size: 28.4 KiB, free: 428.9 MiB)
[2025-11-12T22:26:12.776+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:12 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 53) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:12.776+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:12 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 52) in 4507 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:26:12.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:12 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.18.0.5:42325 (size: 26.7 KiB, free: 428.9 MiB)
[2025-11-12T22:26:12.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:12 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.18.0.5:50960
[2025-11-12T22:26:12.933+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:12 INFO BlockManagerInfo: Added taskresult_53 in memory on 172.18.0.5:42325 (size: 1247.7 KiB, free: 427.7 MiB)
[2025-11-12T22:26:12.937+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:12 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 54) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:12.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:12 INFO TransportClientFactory: Successfully created connection to /172.18.0.5:42325 after 1 ms (0 ms spent in bootstraps)
[2025-11-12T22:26:12.951+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:12 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 53) in 176 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:26:12.954+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:12 INFO BlockManagerInfo: Removed taskresult_53 on 172.18.0.5:42325 in memory (size: 1247.7 KiB, free: 428.9 MiB)
[2025-11-12T22:26:13.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added taskresult_54 in memory on 172.18.0.5:42325 (size: 1247.7 KiB, free: 427.7 MiB)
[2025-11-12T22:26:13.037+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 55) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:26:13.043+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 54) in 106 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:26:13.044+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool
[2025-11-12T22:26:13.045+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: ResultStage 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 7.778 s
[2025-11-12T22:26:13.045+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:13.046+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
[2025-11-12T22:26:13.046+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Job 33 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 7.782548 s
[2025-11-12T22:26:13.046+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed taskresult_54 on 172.18.0.5:42325 in memory (size: 1247.7 KiB, free: 428.9 MiB)
[2025-11-12T22:26:13.047+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.18.0.5:42325 (size: 48.6 KiB, free: 428.8 MiB)
[2025-11-12T22:26:13.061+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.18.0.5:50960
[2025-11-12T22:26:13.139+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 422.9 MiB)
[2025-11-12T22:26:13.140+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on eb021f2c8a8b:40023 (size: 4.0 MiB, free: 424.8 MiB)
[2025-11-12T22:26:13.140+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MemoryStore: Block broadcast_54_piece1 stored as bytes in memory (estimated size 1055.1 KiB, free 421.9 MiB)
[2025-11-12T22:26:13.140+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_54_piece1 in memory on eb021f2c8a8b:40023 (size: 1055.1 KiB, free: 423.8 MiB)
[2025-11-12T22:26:13.141+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO SparkContext: Created broadcast 54 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:13.151+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:13.152+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:13.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:13.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:13.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 55) in 269 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:26:13.307+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2025-11-12T22:26:13.308+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: ShuffleMapStage 53 (showString at NativeMethodAccessorImpl.java:0) finished in 4.933 s
[2025-11-12T22:26:13.308+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:13.309+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: running: Set(ShuffleMapStage 48)
[2025-11-12T22:26:13.309+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:13.309+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:13.317+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:13.318+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:13.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:13.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:13.330+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:13.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:13.333+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:13.334+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:13.373+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO CodeGenerator: Code generated in 5.666343 ms
[2025-11-12T22:26:13.390+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:13.392+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Got job 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:26:13.393+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Final stage: ResultStage 56 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:13.393+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 55)
[2025-11-12T22:26:13.394+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:13.394+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[150] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:13.397+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 119.0 KiB, free 421.8 MiB)
[2025-11-12T22:26:13.398+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 44.0 KiB, free 421.8 MiB)
[2025-11-12T22:26:13.399+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on eb021f2c8a8b:40023 (size: 44.0 KiB, free: 423.7 MiB)
[2025-11-12T22:26:13.399+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:13.399+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[150] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:13.400+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
[2025-11-12T22:26:13.400+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 56) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:13.410+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.18.0.5:42325 (size: 44.0 KiB, free: 428.8 MiB)
[2025-11-12T22:26:13.419+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.18.0.5:50960
[2025-11-12T22:26:13.499+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 56) in 98 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:26:13.500+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool
[2025-11-12T22:26:13.500+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: ResultStage 56 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.105 s
[2025-11-12T22:26:13.501+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:13.501+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
[2025-11-12T22:26:13.501+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Job 35 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.109621 s
[2025-11-12T22:26:13.507+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 158.7 KiB, free 421.6 MiB)
[2025-11-12T22:26:13.508+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on eb021f2c8a8b:40023 (size: 158.7 KiB, free: 423.6 MiB)
[2025-11-12T22:26:13.508+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO SparkContext: Created broadcast 56 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:13.519+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:13.520+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:13.523+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:13.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:13.745+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 51) in 6136 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:26:13.745+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-11-12T22:26:13.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: ShuffleMapStage 48 (showString at NativeMethodAccessorImpl.java:0) finished in 8.759 s
[2025-11-12T22:26:13.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:13.747+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: running: Set()
[2025-11-12T22:26:13.747+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:13.747+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:13.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:13.753+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:13.754+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:13.755+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:13.760+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 10434230, minimum partition size: 1048576
[2025-11-12T22:26:13.765+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 10434230, minimum partition size: 1048576
[2025-11-12T22:26:13.775+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_51_piece0 on eb021f2c8a8b:40023 in memory (size: 13.5 KiB, free: 423.6 MiB)
[2025-11-12T22:26:13.776+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.18.0.5:43045 in memory (size: 13.5 KiB, free: 428.9 MiB)
[2025-11-12T22:26:13.777+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.18.0.5:42325 in memory (size: 13.5 KiB, free: 428.8 MiB)
[2025-11-12T22:26:13.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_55_piece0 on eb021f2c8a8b:40023 in memory (size: 44.0 KiB, free: 423.6 MiB)
[2025-11-12T22:26:13.780+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.18.0.5:42325 in memory (size: 44.0 KiB, free: 428.9 MiB)
[2025-11-12T22:26:13.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_53_piece0 on eb021f2c8a8b:40023 in memory (size: 48.6 KiB, free: 423.7 MiB)
[2025-11-12T22:26:13.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.18.0.5:42325 in memory (size: 48.6 KiB, free: 428.9 MiB)
[2025-11-12T22:26:13.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_52_piece0 on eb021f2c8a8b:40023 in memory (size: 26.7 KiB, free: 423.7 MiB)
[2025-11-12T22:26:13.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.18.0.5:42325 in memory (size: 26.7 KiB, free: 428.9 MiB)
[2025-11-12T22:26:13.793+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_49_piece0 on eb021f2c8a8b:40023 in memory (size: 43.7 KiB, free: 423.7 MiB)
[2025-11-12T22:26:13.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.18.0.5:43045 in memory (size: 43.7 KiB, free: 428.9 MiB)
[2025-11-12T22:26:13.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.18.0.5:42325 in memory (size: 43.7 KiB, free: 429.0 MiB)
[2025-11-12T22:26:13.822+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO CodeGenerator: Code generated in 5.993857 ms
[2025-11-12T22:26:13.823+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TorrentBroadcast: Started reading broadcast variable 56 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:13.824+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TorrentBroadcast: Reading broadcast variable 56 took 0 ms
[2025-11-12T22:26:13.837+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO CodeGenerator: Code generated in 8.057945 ms
[2025-11-12T22:26:13.841+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TorrentBroadcast: Started reading broadcast variable 54 with 2 pieces (estimated total size 8.0 MiB)
[2025-11-12T22:26:13.842+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TorrentBroadcast: Reading broadcast variable 54 took 0 ms
[2025-11-12T22:26:13.855+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TorrentBroadcast: Started reading broadcast variable 45 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:13.855+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TorrentBroadcast: Reading broadcast variable 45 took 0 ms
[2025-11-12T22:26:13.856+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TorrentBroadcast: Started reading broadcast variable 46 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:13.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TorrentBroadcast: Reading broadcast variable 46 took 0 ms
[2025-11-12T22:26:13.877+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO CodeGenerator: Code generated in 13.277868 ms
[2025-11-12T22:26:13.879+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 222.7 KiB, free 422.0 MiB)
[2025-11-12T22:26:13.883+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 422.0 MiB)
[2025-11-12T22:26:13.883+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on eb021f2c8a8b:40023 (size: 37.8 KiB, free: 423.7 MiB)
[2025-11-12T22:26:13.884+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO SparkContext: Created broadcast 57 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:13.884+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:13.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Registering RDD 159 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 17
[2025-11-12T22:26:13.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Got map stage job 36 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:26:13.896+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Final stage: ShuffleMapStage 58 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:13.896+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
[2025-11-12T22:26:13.896+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:13.897+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[159] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:13.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 264.8 KiB, free 421.7 MiB)
[2025-11-12T22:26:13.901+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 88.1 KiB, free 421.6 MiB)
[2025-11-12T22:26:13.902+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on eb021f2c8a8b:40023 (size: 88.1 KiB, free: 423.6 MiB)
[2025-11-12T22:26:13.902+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:13.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[159] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:26:13.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSchedulerImpl: Adding task set 58.0 with 4 tasks resource profile 0
[2025-11-12T22:26:13.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 57) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10250 bytes)
[2025-11-12T22:26:13.904+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO TaskSetManager: Starting task 1.0 in stage 58.0 (TID 58) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10250 bytes)
[2025-11-12T22:26:13.912+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.18.0.5:43045 (size: 88.1 KiB, free: 428.8 MiB)
[2025-11-12T22:26:13.913+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.18.0.5:42325 (size: 88.1 KiB, free: 428.9 MiB)
[2025-11-12T22:26:13.925+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.5:50962
[2025-11-12T22:26:13.933+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.5:50960
[2025-11-12T22:26:13.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.18.0.5:43045 (size: 158.7 KiB, free: 428.7 MiB)
[2025-11-12T22:26:13.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:13 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.18.0.5:42325 (size: 158.7 KiB, free: 428.7 MiB)
[2025-11-12T22:26:14.240+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:14 INFO TaskSetManager: Starting task 2.0 in stage 58.0 (TID 59) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:26:14.241+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:14 INFO TaskSetManager: Finished task 1.0 in stage 58.0 (TID 58) in 337 ms on 172.18.0.5 (executor 0) (1/4)
[2025-11-12T22:26:14.297+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:14 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.18.0.5:42325 (size: 4.0 MiB, free: 424.7 MiB)
[2025-11-12T22:26:14.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:14 INFO BlockManagerInfo: Added broadcast_54_piece1 in memory on 172.18.0.5:42325 (size: 1055.1 KiB, free: 423.7 MiB)
[2025-11-12T22:26:14.325+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:14 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.18.0.5:42325 (size: 37.8 KiB, free: 423.7 MiB)
[2025-11-12T22:26:14.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:14 INFO TaskSetManager: Starting task 3.0 in stage 58.0 (TID 60) (172.18.0.5, executor 1, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:26:14.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:14 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 57) in 632 ms on 172.18.0.5 (executor 1) (2/4)
[2025-11-12T22:26:14.576+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:14 INFO BlockManagerInfo: Added broadcast_54_piece1 in memory on 172.18.0.5:43045 (size: 1055.1 KiB, free: 427.7 MiB)
[2025-11-12T22:26:14.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:14 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.18.0.5:43045 (size: 4.0 MiB, free: 423.7 MiB)
[2025-11-12T22:26:14.613+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:14 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.18.0.5:43045 (size: 37.8 KiB, free: 423.6 MiB)
[2025-11-12T22:26:21.281+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:21 INFO TaskSetManager: Finished task 2.0 in stage 58.0 (TID 59) in 7041 ms on 172.18.0.5 (executor 0) (3/4)
[2025-11-12T22:26:25.211+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSetManager: Finished task 3.0 in stage 58.0 (TID 60) in 10677 ms on 172.18.0.5 (executor 1) (4/4)
[2025-11-12T22:26:25.212+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool
[2025-11-12T22:26:25.213+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: ShuffleMapStage 58 (showString at NativeMethodAccessorImpl.java:0) finished in 11.317 s
[2025-11-12T22:26:25.213+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:25.214+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: running: Set()
[2025-11-12T22:26:25.214+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:25.214+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:25.220+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:25.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:25.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO CodeGenerator: Code generated in 3.23441 ms
[2025-11-12T22:26:25.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO CodeGenerator: Code generated in 3.350014 ms
[2025-11-12T22:26:25.279+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:25.280+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Got job 37 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:26:25.280+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Final stage: ResultStage 61 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:25.280+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
[2025-11-12T22:26:25.281+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:25.281+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[165] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:25.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 238.4 KiB, free 421.4 MiB)
[2025-11-12T22:26:25.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 80.2 KiB, free 421.3 MiB)
[2025-11-12T22:26:25.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on eb021f2c8a8b:40023 (size: 80.2 KiB, free: 423.5 MiB)
[2025-11-12T22:26:25.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:25.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[165] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:25.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
[2025-11-12T22:26:25.288+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 61) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:25.294+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.18.0.5:42325 (size: 80.2 KiB, free: 423.6 MiB)
[2025-11-12T22:26:25.302+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.18.0.5:50960
[2025-11-12T22:26:25.369+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 61) in 82 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:26:25.370+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool
[2025-11-12T22:26:25.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: ResultStage 61 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.089 s
[2025-11-12T22:26:25.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:25.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
[2025-11-12T22:26:25.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Job 37 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.091610 s
[2025-11-12T22:26:25.377+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 350.0 KiB, free 421.0 MiB)
[2025-11-12T22:26:25.377+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on eb021f2c8a8b:40023 (size: 350.0 KiB, free: 423.2 MiB)
[2025-11-12T22:26:25.378+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO SparkContext: Created broadcast 60 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:25.384+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:25.406+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Removed broadcast_59_piece0 on eb021f2c8a8b:40023 in memory (size: 80.2 KiB, free: 423.3 MiB)
[2025-11-12T22:26:25.407+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.18.0.5:42325 in memory (size: 80.2 KiB, free: 423.7 MiB)
[2025-11-12T22:26:25.411+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Removed broadcast_58_piece0 on eb021f2c8a8b:40023 in memory (size: 88.1 KiB, free: 423.4 MiB)
[2025-11-12T22:26:25.412+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.18.0.5:42325 in memory (size: 88.1 KiB, free: 423.7 MiB)
[2025-11-12T22:26:25.413+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.18.0.5:43045 in memory (size: 88.1 KiB, free: 423.7 MiB)
[2025-11-12T22:26:25.427+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TorrentBroadcast: Started reading broadcast variable 60 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:25.428+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TorrentBroadcast: Reading broadcast variable 60 took 0 ms
[2025-11-12T22:26:25.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO CodeGenerator: Code generated in 32.948468 ms
[2025-11-12T22:26:25.492+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Registering RDD 168 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 18
[2025-11-12T22:26:25.493+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Got map stage job 38 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:26:25.493+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Final stage: ShuffleMapStage 63 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:25.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
[2025-11-12T22:26:25.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:25.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[168] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:25.512+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 346.5 KiB, free 421.3 MiB)
[2025-11-12T22:26:25.514+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 110.8 KiB, free 421.2 MiB)
[2025-11-12T22:26:25.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on eb021f2c8a8b:40023 (size: 110.8 KiB, free: 423.3 MiB)
[2025-11-12T22:26:25.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:25.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[168] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:25.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
[2025-11-12T22:26:25.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 62) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10138 bytes)
[2025-11-12T22:26:25.527+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.18.0.5:42325 (size: 110.8 KiB, free: 423.6 MiB)
[2025-11-12T22:26:25.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.18.0.5:50960
[2025-11-12T22:26:25.599+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.18.0.5:42325 (size: 350.0 KiB, free: 423.3 MiB)
[2025-11-12T22:26:25.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 62) in 166 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:26:25.683+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool
[2025-11-12T22:26:25.685+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: ShuffleMapStage 63 (showString at NativeMethodAccessorImpl.java:0) finished in 0.190 s
[2025-11-12T22:26:25.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:25.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: running: Set()
[2025-11-12T22:26:25.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:25.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:25.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:25.754+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:26:25.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO CodeGenerator: Code generated in 25.30236 ms
[2025-11-12T22:26:25.816+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:25.817+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Got job 39 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:26:25.817+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Final stage: ResultStage 66 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:25.818+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
[2025-11-12T22:26:25.818+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:25.818+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[171] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:25.824+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 419.1 KiB, free 420.8 MiB)
[2025-11-12T22:26:25.825+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 126.7 KiB, free 420.7 MiB)
[2025-11-12T22:26:25.825+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on eb021f2c8a8b:40023 (size: 126.7 KiB, free: 423.1 MiB)
[2025-11-12T22:26:25.825+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:25.826+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[171] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:25.826+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
[2025-11-12T22:26:25.826+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 63) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:25.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.18.0.5:42325 (size: 126.7 KiB, free: 423.2 MiB)
[2025-11-12T22:26:25.842+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.18.0.5:50960
[2025-11-12T22:26:25.891+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 63) in 65 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:26:25.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool
[2025-11-12T22:26:25.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: ResultStage 66 (showString at NativeMethodAccessorImpl.java:0) finished in 0.074 s
[2025-11-12T22:26:25.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:25.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
[2025-11-12T22:26:25.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO DAGScheduler: Job 39 finished: showString at NativeMethodAccessorImpl.java:0, took 0.076834 s
[2025-11-12T22:26:25.905+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO CodeGenerator: Code generated in 7.423311 ms
[2025-11-12T22:26:25.915+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Removed broadcast_62_piece0 on eb021f2c8a8b:40023 in memory (size: 126.7 KiB, free: 423.3 MiB)
[2025-11-12T22:26:25.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.18.0.5:42325 in memory (size: 126.7 KiB, free: 423.3 MiB)
[2025-11-12T22:26:25.919+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Removed broadcast_61_piece0 on eb021f2c8a8b:40023 in memory (size: 110.8 KiB, free: 423.4 MiB)
[2025-11-12T22:26:25.921+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.18.0.5:42325 in memory (size: 110.8 KiB, free: 423.4 MiB)
[2025-11-12T22:26:25.956+0000] {spark_submit.py:571} INFO - +-------------------+----------+-----------------+-------------------+----------+-----------------+-------------------+----------+----------+-----------------+-----------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+-----------------+-----------------+---------------------+---------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+-----------------------------------+-----------------------------------+
[2025-11-12T22:26:25.957+0000] {spark_submit.py:571} INFO - |id                 |west_yusho|west_makuuchiWins|west_Makuuchi_basho|east_yusho|east_makuuchiWins|east_Makuuchi_basho|west_order|east_order|east_years_active|west_years_active|rolling_winloss_west|rolling_winloss_east|west_winRate      |east_winRate       |west_makuuchiWinRate|east_makuuchiWinRate|height_difference|weight_difference|west_kimarite_entropy|east_kimarite_entropy|west_specialist_oshi|east_specialist_oshi|west_specialist_yotsu|east_specialist_yotsu|west_specialist_other|east_specialist_other|west_winrate_vs_opponent_specialist|east_winrate_vs_opponent_specialist|
[2025-11-12T22:26:25.957+0000] {spark_submit.py:571} INFO - +-------------------+----------+-----------------+-------------------+----------+-----------------+-------------------+----------+----------+-----------------+-----------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+-----------------+-----------------+---------------------+---------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+-----------------------------------+-----------------------------------+
[2025-11-12T22:26:25.958+0000] {spark_submit.py:571} INFO - |202511-2-13-14-8857|2         |19               |2                  |4         |695              |96                 |31        |20        |21               |1                |0.68                |0.51                |0.7368421052631579|0.5063437139561707 |9.5                 |7.239583333333333   |-4.0             |-27.0            |0.7925445602668123   |0.5879402871378228   |0                   |1                   |1                    |0                    |0                    |0                    |0.6833333333333333                 |0.5155555555555555                 |
[2025-11-12T22:26:25.958+0000] {spark_submit.py:571} INFO - |202511-2-1-95-164  |1         |34               |5                  |2         |0                |0                  |47        |67        |5                |4                |0.48                |0.52                |0.5551724137931034|0.6148148148148148 |6.8                 |0.0                 |-6.0             |-27.0            |0.7498673285617448   |0.6175674444063989   |1                   |0                   |0                    |1                    |0                    |0                    |0.48872180451127817                |0.6503067484662577                 |
[2025-11-12T22:26:25.958+0000] {spark_submit.py:571} INFO - |202511-2-0-39-82   |4         |0                |0                  |1         |266              |41                 |76        |69        |16               |4                |0.43                |0.31                |0.6276150627615062|0.5040577096483319 |0.0                 |6.487804878048781   |1.0              |5.0              |0.8598018415412542   |0.9070249177889054   |0                   |0                   |1                    |1                    |0                    |0                    |0.6666666666666666                 |0.4803921568627451                 |
[2025-11-12T22:26:25.963+0000] {spark_submit.py:571} INFO - |202511-2-8-86-21   |0         |223              |31                 |1         |35               |5                  |48        |54        |5                |10               |0.44                |0.45                |0.5217391304347826|0.5808383233532934 |7.193548387096774   |7.0                 |-20.0            |-32.0            |0.7563888604676292   |0.8305056100482502   |1                   |0                   |0                    |1                    |0                    |0                    |0.5366876310272537                 |0.5738636363636364                 |
[2025-11-12T22:26:25.963+0000] {spark_submit.py:571} INFO - |202511-2-14-61-28  |5         |217              |31                 |2         |70               |9                  |34        |33        |4                |10               |0.52                |0.55                |0.5840840840840841|0.5451713395638629 |7.0                 |7.777777777777778   |-15.0            |-25.0            |0.9371476746962436   |0.6311157554173754   |1                   |1                   |0                    |0                    |0                    |0                    |0.6417910447761194                 |0.5480225988700564                 |
[2025-11-12T22:26:25.963+0000] {spark_submit.py:571} INFO - |202511-2-12-8853-33|4         |441              |58                 |0         |56               |7                  |40        |30        |2                |11               |0.38                |0.39                |0.5380549682875264|0.6025641025641025 |7.603448275862069   |8.0                 |-1.0             |9.0              |0.9489018316223805   |0.5713529766817182   |1                   |0                   |0                    |1                    |0                    |0                    |0.5456790123456791                 |0.6263736263736264                 |
[2025-11-12T22:26:25.964+0000] {spark_submit.py:571} INFO - |202511-2-6-102-55  |2         |66               |10                 |3         |58               |9                  |41        |50        |8                |7                |0.26                |0.62                |0.5679611650485437|0.5957446808510638 |6.6                 |6.444444444444445   |1.0              |-11.0            |0.6541641621361      |0.44395124109390044  |0                   |1                   |1                    |0                    |0                    |0                    |0.6263736263736264                 |0.6245059288537549                 |
[2025-11-12T22:26:25.964+0000] {spark_submit.py:571} INFO - |202511-2-7-9-8     |4         |172              |26                 |4         |449              |57                 |28        |38        |13               |7                |0.39                |0.45                |0.5301204819277109|0.5524861878453039 |6.615384615384615   |7.87719298245614    |8.0              |4.0              |0.8176124819683551   |0.39731713197878044  |1                   |1                   |0                    |0                    |0                    |0                    |0.4984984984984985                 |0.5670926517571885                 |
[2025-11-12T22:26:25.964+0000] {spark_submit.py:571} INFO - |202511-2-9-11-34   |1         |170              |24                 |3         |157              |23                 |36        |29        |8                |9                |0.4                 |0.31                |0.5403225806451613|0.5441941074523396 |7.083333333333333   |6.826086956521739   |-14.0            |-38.0            |1.096679130577557    |0.6791248703175683   |1                   |1                   |0                    |0                    |0                    |0                    |0.6007905138339921                 |0.5933609958506224                 |
[2025-11-12T22:26:25.965+0000] {spark_submit.py:571} INFO - |202511-2-5-615-56  |2         |99               |14                 |1         |16               |2                  |25        |37        |2                |4                |0.31                |0.43                |0.5508474576271186|0.643312101910828  |7.071428571428571   |8.0                 |3.0              |51.0             |0.6064741792020734   |0.9829007277151562   |1                   |1                   |0                    |0                    |0                    |0                    |0.54337899543379                   |0.5507246376811594                 |
[2025-11-12T22:26:25.965+0000] {spark_submit.py:571} INFO - |202511-2-10-50-22  |8         |302              |40                 |3         |107              |15                 |21        |35        |4                |12               |0.42                |0.47                |0.5710928319623971|0.559748427672956  |7.55                |7.133333333333334   |-7.0             |-10.0            |0.5214577162888486   |0.7335415199735977   |1                   |1                   |0                    |0                    |0                    |0                    |0.546916890080429                  |0.5314685314685315                 |
[2025-11-12T22:26:25.966+0000] {spark_submit.py:571} INFO - |202511-2-19-8850-3 |1         |54               |7                  |5         |125              |11                 |22        |1         |2                |2                |0.53                |0.85                |0.6487804878048781|0.7607655502392344 |7.714285714285714   |11.363636363636363  |-11.0            |-23.0            |0.8319680104123204   |0.7905144807321831   |0                   |1                   |1                    |0                    |0                    |0                    |0.6982758620689655                 |0.7368421052631579                 |
[2025-11-12T22:26:25.966+0000] {spark_submit.py:571} INFO - |202511-2-2-35-49   |0         |88               |13                 |3         |411              |59                 |49        |46        |22               |11               |0.8                 |0.43                |0.5359477124183006|0.49510763209393344|6.769230769230769   |6.966101694915254   |10.0             |51.80000000000001|0.7950766985998653   |0.7789425866178192   |1                   |0                   |0                    |1                    |0                    |0                    |0.541501976284585                  |0.4800498753117207                 |
[2025-11-12T22:26:25.966+0000] {spark_submit.py:571} INFO - |202511-2-20-37-19  |3         |279              |31                 |0         |281              |37                 |2         |32        |15               |7                |0.72                |0.65                |0.6278260869565218|0.5443548387096774 |9.0                 |7.594594594594595   |4.0              |-21.0            |0.881179631551791    |0.6758574307137932   |0                   |1                   |1                    |0                    |0                    |0                    |0.6327077747989276                 |0.5329768270944741                 |
[2025-11-12T22:26:25.967+0000] {spark_submit.py:571} INFO - |202511-2-4-83-26   |4         |459              |58                 |2         |50               |7                  |43        |45        |6                |10               |0.56                |0.47                |0.5480349344978166|0.568              |7.913793103448276   |7.142857142857143   |0.0              |33.0             |0.8095005650823321   |0.7507797907442465   |1                   |0                   |0                    |1                    |0                    |0                    |0.52                               |0.5833333333333334                 |
[2025-11-12T22:26:25.967+0000] {spark_submit.py:571} INFO - |202511-2-3-15-40   |4         |104              |16                 |7         |252              |37                 |71        |52        |19               |9                |0.31                |0.49                |0.5358361774744027|0.5385996409335727 |6.5                 |6.8108108108108105  |-5.0             |-8.0             |0.8562647409702899   |0.6802857028438637   |1                   |0                   |0                    |1                    |0                    |0                    |0.548                              |0.5640535372848948                 |
[2025-11-12T22:26:25.967+0000] {spark_submit.py:571} INFO - |202511-2-18-20-7   |4         |283              |34                 |2         |279              |32                 |12        |5         |9                |10               |0.56                |0.56                |0.5910364145658263|0.6011644832605532 |8.323529411764707   |8.71875             |-3.0             |-30.0            |0.9323291550562125   |0.8746033103785462   |0                   |1                   |1                    |0                    |0                    |0                    |0.586864406779661                  |0.6243654822335025                 |
[2025-11-12T22:26:25.967+0000] {spark_submit.py:571} INFO - |202511-2-16-8854-13|3         |194              |23                 |2         |44               |4                  |27        |17        |2                |13               |0.49                |0.59                |0.5641646489104116|0.7878787878787878 |8.434782608695652   |11.0                |5.0              |10.0             |0.8561612558041493   |0.9668019211700329   |0                   |0                   |1                    |1                    |0                    |0                    |0.5852941176470589                 |0.803921568627451                  |
[2025-11-12T22:26:25.968+0000] {spark_submit.py:571} INFO - |202511-2-15-24-44  |1         |634              |85                 |0         |146              |19                 |16        |26        |9                |20               |0.52                |0.49                |0.5691756272401434|0.5451388888888888 |7.458823529411765   |7.684210526315789   |10.0             |39.0             |0.8753144276860274   |0.8200490170869682   |1                   |0                   |0                    |1                    |0                    |0                    |0.5933734939759037                 |0.5459610027855153                 |
[2025-11-12T22:26:25.968+0000] {spark_submit.py:571} INFO - |202511-2-11-74-71  |3         |92               |12                 |3         |104              |14                 |39        |24        |4                |9                |0.49                |0.59                |0.5156482861400894|0.5653333333333334 |7.666666666666667   |7.428571428571429   |-8.0             |-43.0            |0.7791407409054228   |0.7730572300070738   |1                   |0                   |0                    |1                    |0                    |0                    |0.525065963060686                  |0.6398305084745762                 |
[2025-11-12T22:26:25.968+0000] {spark_submit.py:571} INFO - |202511-2-17-12-41  |1         |168              |22                 |5         |223              |28                 |23        |11        |8                |7                |0.5                 |0.62                |0.5528756957328386|0.617363344051447  |7.636363636363637   |7.964285714285714   |7.0              |42.0             |0.7205765794596204   |0.8960016071734727   |1                   |1                   |0                    |0                    |0                    |0                    |0.5474683544303798                 |0.6111111111111112                 |
[2025-11-12T22:26:25.969+0000] {spark_submit.py:571} INFO - +-------------------+----------+-----------------+-------------------+----------+-----------------+-------------------+----------+----------+-----------------+-----------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+-----------------+-----------------+---------------------+---------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+-----------------------------------+-----------------------------------+
[2025-11-12T22:26:25.969+0000] {spark_submit.py:571} INFO - 
[2025-11-12T22:26:25.969+0000] {spark_submit.py:571} INFO - Attempting to load PipelineModel on driver from s3a://ryans-sumo-bucket/models/xgboost_model
[2025-11-12T22:26:25.969+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 222.8 KiB, free 421.4 MiB)
[2025-11-12T22:26:25.970+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 421.4 MiB)
[2025-11-12T22:26:25.970+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on eb021f2c8a8b:40023 (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:26:25.971+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:25 INFO SparkContext: Created broadcast 63 from textFile at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:26.341+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:26:26.354+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181
[2025-11-12T22:26:26.354+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Got job 40 (runJob at PythonRDD.scala:181) with 1 output partitions
[2025-11-12T22:26:26.355+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Final stage: ResultStage 67 (runJob at PythonRDD.scala:181)
[2025-11-12T22:26:26.355+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:26.355+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:26.356+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Submitting ResultStage 67 (PythonRDD[174] at RDD at PythonRDD.scala:53), which has no missing parents
[2025-11-12T22:26:26.358+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 8.2 KiB, free 421.4 MiB)
[2025-11-12T22:26:26.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 421.4 MiB)
[2025-11-12T22:26:26.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on eb021f2c8a8b:40023 (size: 5.1 KiB, free: 423.3 MiB)
[2025-11-12T22:26:26.360+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:26.360+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (PythonRDD[174] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:26.360+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
[2025-11-12T22:26:26.367+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 64) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10213 bytes)
[2025-11-12T22:26:26.385+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.18.0.5:43045 (size: 5.1 KiB, free: 423.7 MiB)
[2025-11-12T22:26:26.407+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.18.0.5:43045 (size: 33.3 KiB, free: 423.7 MiB)
[2025-11-12T22:26:26.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 64) in 204 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:26.565+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool
[2025-11-12T22:26:26.565+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: ResultStage 67 (runJob at PythonRDD.scala:181) finished in 0.209 s
[2025-11-12T22:26:26.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:26.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
[2025-11-12T22:26:26.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Job 40 finished: runJob at PythonRDD.scala:181, took 0.211247 s
[2025-11-12T22:26:26.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 222.8 KiB, free 421.2 MiB)
[2025-11-12T22:26:26.572+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 421.1 MiB)
[2025-11-12T22:26:26.573+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on eb021f2c8a8b:40023 (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:26:26.573+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO SparkContext: Created broadcast 65 from textFile at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:26.774+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:26:26.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181
[2025-11-12T22:26:26.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Got job 41 (runJob at PythonRDD.scala:181) with 1 output partitions
[2025-11-12T22:26:26.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Final stage: ResultStage 68 (runJob at PythonRDD.scala:181)
[2025-11-12T22:26:26.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:26.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:26.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Submitting ResultStage 68 (PythonRDD[177] at RDD at PythonRDD.scala:53), which has no missing parents
[2025-11-12T22:26:26.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 8.3 KiB, free 421.1 MiB)
[2025-11-12T22:26:26.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 421.1 MiB)
[2025-11-12T22:26:26.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on eb021f2c8a8b:40023 (size: 5.2 KiB, free: 423.3 MiB)
[2025-11-12T22:26:26.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:26.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (PythonRDD[177] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:26.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
[2025-11-12T22:26:26.787+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 65) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10251 bytes)
[2025-11-12T22:26:26.792+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.18.0.5:43045 (size: 5.2 KiB, free: 423.7 MiB)
[2025-11-12T22:26:26.797+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:26 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.18.0.5:43045 (size: 33.3 KiB, free: 423.6 MiB)
[2025-11-12T22:26:27.021+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 65) in 236 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:27.022+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool
[2025-11-12T22:26:27.023+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: ResultStage 68 (runJob at PythonRDD.scala:181) finished in 0.239 s
[2025-11-12T22:26:27.023+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:27.023+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
[2025-11-12T22:26:27.024+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Job 41 finished: runJob at PythonRDD.scala:181, took 0.239917 s
[2025-11-12T22:26:27.034+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 222.8 KiB, free 420.9 MiB)
[2025-11-12T22:26:27.038+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 420.9 MiB)
[2025-11-12T22:26:27.038+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on eb021f2c8a8b:40023 (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:26:27.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO SparkContext: Created broadcast 67 from textFile at ReadWrite.scala:587
[2025-11-12T22:26:27.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:26:27.327+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO SparkContext: Starting job: first at ReadWrite.scala:587
[2025-11-12T22:26:27.327+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Got job 42 (first at ReadWrite.scala:587) with 1 output partitions
[2025-11-12T22:26:27.328+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Final stage: ResultStage 69 (first at ReadWrite.scala:587)
[2025-11-12T22:26:27.328+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:27.329+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:27.329+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Submitting ResultStage 69 (s3a://ryans-sumo-bucket/models/xgboost_model/stages/0_VectorAssembler_44693654e9ff/metadata MapPartitionsRDD[179] at textFile at ReadWrite.scala:587), which has no missing parents
[2025-11-12T22:26:27.329+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 5.0 KiB, free 420.9 MiB)
[2025-11-12T22:26:27.330+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 420.8 MiB)
[2025-11-12T22:26:27.330+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on eb021f2c8a8b:40023 (size: 2.9 KiB, free: 423.3 MiB)
[2025-11-12T22:26:27.330+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:27.330+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (s3a://ryans-sumo-bucket/models/xgboost_model/stages/0_VectorAssembler_44693654e9ff/metadata MapPartitionsRDD[179] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:27.331+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
[2025-11-12T22:26:27.331+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 66) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10251 bytes)
[2025-11-12T22:26:27.344+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.18.0.5:42325 (size: 2.9 KiB, free: 423.4 MiB)
[2025-11-12T22:26:27.353+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.18.0.5:42325 (size: 33.3 KiB, free: 423.4 MiB)
[2025-11-12T22:26:27.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 66) in 309 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:26:27.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-11-12T22:26:27.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: ResultStage 69 (first at ReadWrite.scala:587) finished in 0.311 s
[2025-11-12T22:26:27.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:27.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
[2025-11-12T22:26:27.642+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Job 42 finished: first at ReadWrite.scala:587, took 0.312831 s
[2025-11-12T22:26:27.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 222.8 KiB, free 420.6 MiB)
[2025-11-12T22:26:27.681+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 420.6 MiB)
[2025-11-12T22:26:27.681+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on eb021f2c8a8b:40023 (size: 33.3 KiB, free: 423.2 MiB)
[2025-11-12T22:26:27.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO SparkContext: Created broadcast 69 from textFile at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:27.936+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:26:27.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181
[2025-11-12T22:26:27.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Got job 43 (runJob at PythonRDD.scala:181) with 1 output partitions
[2025-11-12T22:26:27.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Final stage: ResultStage 70 (runJob at PythonRDD.scala:181)
[2025-11-12T22:26:27.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:27.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:27.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Submitting ResultStage 70 (PythonRDD[182] at RDD at PythonRDD.scala:53), which has no missing parents
[2025-11-12T22:26:27.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 8.3 KiB, free 420.6 MiB)
[2025-11-12T22:26:27.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 420.6 MiB)
[2025-11-12T22:26:27.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on eb021f2c8a8b:40023 (size: 5.2 KiB, free: 423.2 MiB)
[2025-11-12T22:26:27.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:27.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (PythonRDD[182] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:27.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
[2025-11-12T22:26:27.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 67) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10254 bytes)
[2025-11-12T22:26:27.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.18.0.5:42325 (size: 5.2 KiB, free: 423.4 MiB)
[2025-11-12T22:26:27.960+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:27 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.18.0.5:42325 (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:26:28.125+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 67) in 175 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:26:28.125+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-11-12T22:26:28.126+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: ResultStage 70 (runJob at PythonRDD.scala:181) finished in 0.180 s
[2025-11-12T22:26:28.126+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:28.126+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished
[2025-11-12T22:26:28.127+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: Job 43 finished: runJob at PythonRDD.scala:181, took 0.180711 s
[2025-11-12T22:26:28.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 222.8 KiB, free 420.4 MiB)
[2025-11-12T22:26:28.375+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 420.3 MiB)
[2025-11-12T22:26:28.376+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on eb021f2c8a8b:40023 (size: 33.3 KiB, free: 423.2 MiB)
[2025-11-12T22:26:28.376+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO SparkContext: Created broadcast 71 from textFile at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:28.571+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:26:28.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181
[2025-11-12T22:26:28.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: Got job 44 (runJob at PythonRDD.scala:181) with 1 output partitions
[2025-11-12T22:26:28.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: Final stage: ResultStage 71 (runJob at PythonRDD.scala:181)
[2025-11-12T22:26:28.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:28.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:28.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: Submitting ResultStage 71 (PythonRDD[185] at RDD at PythonRDD.scala:53), which has no missing parents
[2025-11-12T22:26:28.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 8.3 KiB, free 420.3 MiB)
[2025-11-12T22:26:28.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 420.3 MiB)
[2025-11-12T22:26:28.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on eb021f2c8a8b:40023 (size: 5.2 KiB, free: 423.2 MiB)
[2025-11-12T22:26:28.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:28.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (PythonRDD[185] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:28.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0
[2025-11-12T22:26:28.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 68) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10254 bytes)
[2025-11-12T22:26:28.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.18.0.5:43045 (size: 5.2 KiB, free: 423.6 MiB)
[2025-11-12T22:26:28.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.18.0.5:43045 (size: 33.3 KiB, free: 423.6 MiB)
[2025-11-12T22:26:28.776+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 68) in 194 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:28.777+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool
[2025-11-12T22:26:28.777+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: ResultStage 71 (runJob at PythonRDD.scala:181) finished in 0.196 s
[2025-11-12T22:26:28.777+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:28.778+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished
[2025-11-12T22:26:28.778+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO DAGScheduler: Job 44 finished: runJob at PythonRDD.scala:181, took 0.197692 s
[2025-11-12T22:26:28.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 222.8 KiB, free 420.1 MiB)
[2025-11-12T22:26:28.787+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 420.1 MiB)
[2025-11-12T22:26:28.787+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on eb021f2c8a8b:40023 (size: 33.3 KiB, free: 423.1 MiB)
[2025-11-12T22:26:28.787+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:28 INFO SparkContext: Created broadcast 73 from textFile at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:29.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:26:29.038+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO SparkContext: Starting job: load at /opt/airflow/jobs/spark_mongoNewMatches.py:763
[2025-11-12T22:26:29.038+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO DAGScheduler: Got job 45 (load at /opt/airflow/jobs/spark_mongoNewMatches.py:763) with 2 output partitions
[2025-11-12T22:26:29.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO DAGScheduler: Final stage: ResultStage 72 (load at /opt/airflow/jobs/spark_mongoNewMatches.py:763)
[2025-11-12T22:26:29.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:29.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:29.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO DAGScheduler: Submitting ResultStage 72 (s3a://ryans-sumo-bucket/models/xgboost_model/stages/1_SparkXGBClassifier_3de5eb1a1dbb/model MapPartitionsRDD[187] at textFile at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:29.040+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 5.0 KiB, free 420.1 MiB)
[2025-11-12T22:26:29.040+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 420.1 MiB)
[2025-11-12T22:26:29.040+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on eb021f2c8a8b:40023 (size: 2.9 KiB, free: 423.1 MiB)
[2025-11-12T22:26:29.041+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:29.041+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 72 (s3a://ryans-sumo-bucket/models/xgboost_model/stages/1_SparkXGBClassifier_3de5eb1a1dbb/model MapPartitionsRDD[187] at textFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:29.041+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO TaskSchedulerImpl: Adding task set 72.0 with 2 tasks resource profile 0
[2025-11-12T22:26:29.041+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 69) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10251 bytes)
[2025-11-12T22:26:29.042+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 70) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10251 bytes)
[2025-11-12T22:26:29.047+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.18.0.5:42325 (size: 2.9 KiB, free: 423.3 MiB)
[2025-11-12T22:26:29.048+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.18.0.5:43045 (size: 2.9 KiB, free: 423.6 MiB)
[2025-11-12T22:26:29.052+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.18.0.5:43045 (size: 33.3 KiB, free: 423.6 MiB)
[2025-11-12T22:26:29.052+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.18.0.5:42325 (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:26:29.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 70) in 528 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:26:29.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO BlockManagerInfo: Added taskresult_69 in memory on 172.18.0.5:43045 (size: 1801.1 KiB, free: 421.8 MiB)
[2025-11-12T22:26:29.699+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 69) in 658 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:26:29.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-11-12T22:26:29.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO DAGScheduler: ResultStage 72 (load at /opt/airflow/jobs/spark_mongoNewMatches.py:763) finished in 0.661 s
[2025-11-12T22:26:29.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:29.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-11-12T22:26:29.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO DAGScheduler: Job 45 finished: load at /opt/airflow/jobs/spark_mongoNewMatches.py:763, took 0.662179 s
[2025-11-12T22:26:29.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:29 INFO BlockManagerInfo: Removed taskresult_69 on 172.18.0.5:43045 in memory (size: 1801.1 KiB, free: 423.6 MiB)
[2025-11-12T22:26:29.742+0000] {spark_submit.py:571} INFO - Loaded PipelineModel on driver
[2025-11-12T22:26:30.042+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_72_piece0 on eb021f2c8a8b:40023 in memory (size: 5.2 KiB, free: 423.1 MiB)
[2025-11-12T22:26:30.044+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.18.0.5:43045 in memory (size: 5.2 KiB, free: 423.6 MiB)
[2025-11-12T22:26:30.048+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_65_piece0 on eb021f2c8a8b:40023 in memory (size: 33.3 KiB, free: 423.2 MiB)
[2025-11-12T22:26:30.049+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.18.0.5:43045 in memory (size: 33.3 KiB, free: 423.6 MiB)
[2025-11-12T22:26:30.052+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_70_piece0 on eb021f2c8a8b:40023 in memory (size: 5.2 KiB, free: 423.2 MiB)
[2025-11-12T22:26:30.052+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.18.0.5:42325 in memory (size: 5.2 KiB, free: 423.3 MiB)
[2025-11-12T22:26:30.054+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_69_piece0 on eb021f2c8a8b:40023 in memory (size: 33.3 KiB, free: 423.2 MiB)
[2025-11-12T22:26:30.055+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.18.0.5:42325 in memory (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:26:30.057+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_67_piece0 on eb021f2c8a8b:40023 in memory (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:26:30.058+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.18.0.5:42325 in memory (size: 33.3 KiB, free: 423.4 MiB)
[2025-11-12T22:26:30.059+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_66_piece0 on eb021f2c8a8b:40023 in memory (size: 5.2 KiB, free: 423.3 MiB)
[2025-11-12T22:26:30.060+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.18.0.5:43045 in memory (size: 5.2 KiB, free: 423.6 MiB)
[2025-11-12T22:26:30.061+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_68_piece0 on eb021f2c8a8b:40023 in memory (size: 2.9 KiB, free: 423.3 MiB)
[2025-11-12T22:26:30.062+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.18.0.5:42325 in memory (size: 2.9 KiB, free: 423.4 MiB)
[2025-11-12T22:26:30.064+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_64_piece0 on eb021f2c8a8b:40023 in memory (size: 5.1 KiB, free: 423.3 MiB)
[2025-11-12T22:26:30.065+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.18.0.5:43045 in memory (size: 5.1 KiB, free: 423.6 MiB)
[2025-11-12T22:26:30.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_63_piece0 on eb021f2c8a8b:40023 in memory (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:26:30.067+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.18.0.5:43045 in memory (size: 33.3 KiB, free: 423.6 MiB)
[2025-11-12T22:26:30.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_74_piece0 on eb021f2c8a8b:40023 in memory (size: 2.9 KiB, free: 423.3 MiB)
[2025-11-12T22:26:30.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.18.0.5:43045 in memory (size: 2.9 KiB, free: 423.6 MiB)
[2025-11-12T22:26:30.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.18.0.5:42325 in memory (size: 2.9 KiB, free: 423.4 MiB)
[2025-11-12T22:26:30.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 208.0 B, free 421.1 MiB)
[2025-11-12T22:26:30.251+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 569.7 KiB, free 420.6 MiB)
[2025-11-12T22:26:30.251+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on eb021f2c8a8b:40023 (size: 569.7 KiB, free: 422.7 MiB)
[2025-11-12T22:26:30.256+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO SparkContext: Created broadcast 75 from broadcast at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:30.311+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_57_piece0 on eb021f2c8a8b:40023 in memory (size: 37.8 KiB, free: 422.8 MiB)
[2025-11-12T22:26:30.316+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.18.0.5:42325 in memory (size: 37.8 KiB, free: 423.4 MiB)
[2025-11-12T22:26:30.317+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.18.0.5:43045 in memory (size: 37.8 KiB, free: 423.7 MiB)
[2025-11-12T22:26:30.317+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_30_piece0 on eb021f2c8a8b:40023 in memory (size: 37.3 KiB, free: 422.8 MiB)
[2025-11-12T22:26:30.318+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.18.0.5:43045 in memory (size: 37.3 KiB, free: 423.7 MiB)
[2025-11-12T22:26:30.321+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_50_piece0 on eb021f2c8a8b:40023 in memory (size: 37.8 KiB, free: 422.9 MiB)
[2025-11-12T22:26:30.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.18.0.5:43045 in memory (size: 37.8 KiB, free: 423.8 MiB)
[2025-11-12T22:26:30.323+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.18.0.5:42325 in memory (size: 37.8 KiB, free: 423.4 MiB)
[2025-11-12T22:26:30.326+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_47_piece0 on eb021f2c8a8b:40023 in memory (size: 37.3 KiB, free: 422.9 MiB)
[2025-11-12T22:26:30.327+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.18.0.5:42325 in memory (size: 37.3 KiB, free: 423.5 MiB)
[2025-11-12T22:26:30.328+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.18.0.5:43045 in memory (size: 37.3 KiB, free: 423.8 MiB)
[2025-11-12T22:26:30.329+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_46_piece0 on eb021f2c8a8b:40023 in memory (size: 90.6 KiB, free: 423.0 MiB)
[2025-11-12T22:26:30.330+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.18.0.5:42325 in memory (size: 90.6 KiB, free: 423.6 MiB)
[2025-11-12T22:26:30.330+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.18.0.5:43045 in memory (size: 90.6 KiB, free: 423.9 MiB)
[2025-11-12T22:26:30.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_56_piece0 on eb021f2c8a8b:40023 in memory (size: 158.7 KiB, free: 423.1 MiB)
[2025-11-12T22:26:30.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.18.0.5:43045 in memory (size: 158.7 KiB, free: 424.0 MiB)
[2025-11-12T22:26:30.333+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.18.0.5:42325 in memory (size: 158.7 KiB, free: 423.7 MiB)
[2025-11-12T22:26:30.334+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_48_piece0 on eb021f2c8a8b:40023 in memory (size: 37.3 KiB, free: 423.2 MiB)
[2025-11-12T22:26:30.335+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.18.0.5:42325 in memory (size: 37.3 KiB, free: 423.8 MiB)
[2025-11-12T22:26:30.336+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.18.0.5:43045 in memory (size: 37.3 KiB, free: 424.1 MiB)
[2025-11-12T22:26:30.337+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_60_piece0 on eb021f2c8a8b:40023 in memory (size: 350.0 KiB, free: 423.5 MiB)
[2025-11-12T22:26:30.338+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.18.0.5:42325 in memory (size: 350.0 KiB, free: 424.1 MiB)
[2025-11-12T22:26:30.340+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_45_piece0 on eb021f2c8a8b:40023 in memory (size: 56.2 KiB, free: 423.6 MiB)
[2025-11-12T22:26:30.342+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.18.0.5:42325 in memory (size: 56.2 KiB, free: 424.2 MiB)
[2025-11-12T22:26:30.342+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.18.0.5:43045 in memory (size: 56.2 KiB, free: 424.1 MiB)
[2025-11-12T22:26:30.344+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_41_piece0 on eb021f2c8a8b:40023 in memory (size: 46.9 KiB, free: 423.6 MiB)
[2025-11-12T22:26:30.345+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.18.0.5:42325 in memory (size: 46.9 KiB, free: 424.2 MiB)
[2025-11-12T22:26:30.345+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.18.0.5:43045 in memory (size: 46.9 KiB, free: 424.2 MiB)
[2025-11-12T22:26:30.348+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_44_piece1 on eb021f2c8a8b:40023 in memory (size: 1049.2 KiB, free: 424.6 MiB)
[2025-11-12T22:26:30.349+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_44_piece1 on 172.18.0.5:42325 in memory (size: 1049.2 KiB, free: 425.2 MiB)
[2025-11-12T22:26:30.350+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_44_piece0 on eb021f2c8a8b:40023 in memory (size: 4.0 MiB, free: 428.6 MiB)
[2025-11-12T22:26:30.350+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_44_piece1 on 172.18.0.5:43045 in memory (size: 1049.2 KiB, free: 425.2 MiB)
[2025-11-12T22:26:30.351+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.18.0.5:42325 in memory (size: 4.0 MiB, free: 429.2 MiB)
[2025-11-12T22:26:30.351+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.18.0.5:43045 in memory (size: 4.0 MiB, free: 429.2 MiB)
[2025-11-12T22:26:30.352+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_34_piece0 on eb021f2c8a8b:40023 in memory (size: 37.3 KiB, free: 428.7 MiB)
[2025-11-12T22:26:30.353+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.5:42325 in memory (size: 37.3 KiB, free: 429.3 MiB)
[2025-11-12T22:26:30.354+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.5:43045 in memory (size: 37.3 KiB, free: 429.2 MiB)
[2025-11-12T22:26:30.356+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_29_piece0 on eb021f2c8a8b:40023 in memory (size: 37.3 KiB, free: 428.7 MiB)
[2025-11-12T22:26:30.357+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.18.0.5:43045 in memory (size: 37.3 KiB, free: 429.3 MiB)
[2025-11-12T22:26:30.357+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.18.0.5:42325 in memory (size: 37.3 KiB, free: 429.3 MiB)
[2025-11-12T22:26:30.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_54_piece1 on eb021f2c8a8b:40023 in memory (size: 1055.1 KiB, free: 429.7 MiB)
[2025-11-12T22:26:30.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_54_piece0 on eb021f2c8a8b:40023 in memory (size: 4.0 MiB, free: 433.7 MiB)
[2025-11-12T22:26:30.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_54_piece1 on 172.18.0.5:43045 in memory (size: 1055.1 KiB, free: 430.3 MiB)
[2025-11-12T22:26:30.360+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_54_piece1 on 172.18.0.5:42325 in memory (size: 1055.1 KiB, free: 430.3 MiB)
[2025-11-12T22:26:30.361+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.18.0.5:43045 in memory (size: 4.0 MiB, free: 434.3 MiB)
[2025-11-12T22:26:30.361+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.18.0.5:42325 in memory (size: 4.0 MiB, free: 434.3 MiB)
[2025-11-12T22:26:30.363+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_32_piece0 on eb021f2c8a8b:40023 in memory (size: 37.3 KiB, free: 433.8 MiB)
[2025-11-12T22:26:30.365+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.5:42325 in memory (size: 37.3 KiB, free: 434.4 MiB)
[2025-11-12T22:26:30.365+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:30 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.5:43045 in memory (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:26:31.746+0000] {spark_submit.py:571} INFO - Model scored rows on driver
[2025-11-12T22:26:32.081+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:32 INFO BlockManagerInfo: Removed broadcast_73_piece0 on eb021f2c8a8b:40023 in memory (size: 33.3 KiB, free: 433.8 MiB)
[2025-11-12T22:26:32.082+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:32 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.18.0.5:42325 in memory (size: 33.3 KiB, free: 434.4 MiB)
[2025-11-12T22:26:32.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:32 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.18.0.5:43045 in memory (size: 33.3 KiB, free: 434.4 MiB)
[2025-11-12T22:26:37.216+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.216+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.217+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.217+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.218+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.218+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.219+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.219+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2244 = ) THEN false ELSE isnull(kimarite#2244) END OR CASE WHEN (kimarite#2244 = ) THEN true ELSE (kimarite#2244 = NA) END) THEN false ELSE CASE WHEN (kimarite#2244 = ) THEN true ELSE isnotnull(kimarite#2244) END END
[2025-11-12T22:26:37.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2698 = ) THEN false ELSE isnull(kimarite#2698) END OR CASE WHEN (kimarite#2698 = ) THEN true ELSE (kimarite#2698 = NA) END) THEN false ELSE CASE WHEN (kimarite#2698 = ) THEN true ELSE isnotnull(kimarite#2698) END END
[2025-11-12T22:26:37.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:37.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4564 = ) THEN false ELSE isnull(kimarite#4564) END OR CASE WHEN (kimarite#4564 = ) THEN true ELSE (kimarite#4564 = NA) END) THEN false ELSE CASE WHEN (kimarite#4564 = ) THEN true ELSE isnotnull(kimarite#4564) END END
[2025-11-12T22:26:37.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4768 = ) THEN false ELSE isnull(kimarite#4768) END OR CASE WHEN (kimarite#4768 = ) THEN true ELSE (kimarite#4768 = NA) END) THEN false ELSE CASE WHEN (kimarite#4768 = ) THEN true ELSE isnotnull(kimarite#4768) END END
[2025-11-12T22:26:37.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:37.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#3879 = ) THEN false ELSE isnull(kimarite#3879) END OR CASE WHEN (kimarite#3879 = ) THEN true ELSE (kimarite#3879 = NA) END) THEN false ELSE CASE WHEN (kimarite#3879 = ) THEN true ELSE isnotnull(kimarite#3879) END END
[2025-11-12T22:26:37.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.229+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4083 = ) THEN false ELSE isnull(kimarite#4083) END OR CASE WHEN (kimarite#4083 = ) THEN true ELSE (kimarite#4083 = NA) END) THEN false ELSE CASE WHEN (kimarite#4083 = ) THEN true ELSE isnotnull(kimarite#4083) END END
[2025-11-12T22:26:37.230+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.232+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.233+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.233+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7603 = ) THEN false ELSE isnull(kimarite#7603) END OR CASE WHEN (kimarite#7603 = ) THEN true ELSE (kimarite#7603 = NA) END) THEN false ELSE CASE WHEN (kimarite#7603 = ) THEN true ELSE isnotnull(kimarite#7603) END END
[2025-11-12T22:26:37.235+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.236+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7807 = ) THEN false ELSE isnull(kimarite#7807) END OR CASE WHEN (kimarite#7807 = ) THEN true ELSE (kimarite#7807 = NA) END) THEN false ELSE CASE WHEN (kimarite#7807 = ) THEN true ELSE isnotnull(kimarite#7807) END END
[2025-11-12T22:26:37.236+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.237+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:37.237+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.238+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#9439 = ) THEN false ELSE isnull(kimarite#9439) END OR CASE WHEN (kimarite#9439 = ) THEN true ELSE (kimarite#9439 = NA) END) THEN false ELSE CASE WHEN (kimarite#9439 = ) THEN true ELSE isnotnull(kimarite#9439) END END
[2025-11-12T22:26:37.240+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.240+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#9643 = ) THEN false ELSE isnull(kimarite#9643) END OR CASE WHEN (kimarite#9643 = ) THEN true ELSE (kimarite#9643 = NA) END) THEN false ELSE CASE WHEN (kimarite#9643 = ) THEN true ELSE isnotnull(kimarite#9643) END END
[2025-11-12T22:26:37.240+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.240+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:37.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#10051 = ) THEN false ELSE isnull(kimarite#10051) END OR CASE WHEN (kimarite#10051 = ) THEN true ELSE (kimarite#10051 = NA) END) THEN false ELSE CASE WHEN (kimarite#10051 = ) THEN true ELSE isnotnull(kimarite#10051) END END
[2025-11-12T22:26:37.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#10255 = ) THEN false ELSE isnull(kimarite#10255) END OR CASE WHEN (kimarite#10255 = ) THEN true ELSE (kimarite#10255 = NA) END) THEN false ELSE CASE WHEN (kimarite#10255 = ) THEN true ELSE isnotnull(kimarite#10255) END END
[2025-11-12T22:26:37.247+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.247+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.247+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.247+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.249+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.250+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11148 = ) THEN false ELSE isnull(kimarite#11148) END OR CASE WHEN (kimarite#11148 = ) THEN true ELSE (kimarite#11148 = NA) END) THEN false ELSE CASE WHEN (kimarite#11148 = ) THEN true ELSE isnotnull(kimarite#11148) END END
[2025-11-12T22:26:37.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11352 = ) THEN false ELSE isnull(kimarite#11352) END OR CASE WHEN (kimarite#11352 = ) THEN true ELSE (kimarite#11352 = NA) END) THEN false ELSE CASE WHEN (kimarite#11352 = ) THEN true ELSE isnotnull(kimarite#11352) END END
[2025-11-12T22:26:37.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.253+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:37.253+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.253+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11760 = ) THEN false ELSE isnull(kimarite#11760) END OR CASE WHEN (kimarite#11760 = ) THEN true ELSE (kimarite#11760 = NA) END) THEN false ELSE CASE WHEN (kimarite#11760 = ) THEN true ELSE isnotnull(kimarite#11760) END END
[2025-11-12T22:26:37.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11964 = ) THEN false ELSE isnull(kimarite#11964) END OR CASE WHEN (kimarite#11964 = ) THEN true ELSE (kimarite#11964 = NA) END) THEN false ELSE CASE WHEN (kimarite#11964 = ) THEN true ELSE isnotnull(kimarite#11964) END END
[2025-11-12T22:26:37.256+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.256+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:37.257+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#12372 = ) THEN false ELSE isnull(kimarite#12372) END OR CASE WHEN (kimarite#12372 = ) THEN true ELSE (kimarite#12372 = NA) END) THEN false ELSE CASE WHEN (kimarite#12372 = ) THEN true ELSE isnotnull(kimarite#12372) END END
[2025-11-12T22:26:37.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#12576 = ) THEN false ELSE isnull(kimarite#12576) END OR CASE WHEN (kimarite#12576 = ) THEN true ELSE (kimarite#12576 = NA) END) THEN false ELSE CASE WHEN (kimarite#12576 = ) THEN true ELSE isnotnull(kimarite#12576) END END
[2025-11-12T22:26:37.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.261+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.261+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.261+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.262+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14208 = ) THEN false ELSE isnull(kimarite#14208) END OR CASE WHEN (kimarite#14208 = ) THEN true ELSE (kimarite#14208 = NA) END) THEN false ELSE CASE WHEN (kimarite#14208 = ) THEN true ELSE isnotnull(kimarite#14208) END END
[2025-11-12T22:26:37.265+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.265+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14412 = ) THEN false ELSE isnull(kimarite#14412) END OR CASE WHEN (kimarite#14412 = ) THEN true ELSE (kimarite#14412 = NA) END) THEN false ELSE CASE WHEN (kimarite#14412 = ) THEN true ELSE isnotnull(kimarite#14412) END END
[2025-11-12T22:26:37.266+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.266+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:37.267+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.267+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16044 = ) THEN false ELSE isnull(kimarite#16044) END OR CASE WHEN (kimarite#16044 = ) THEN true ELSE (kimarite#16044 = NA) END) THEN false ELSE CASE WHEN (kimarite#16044 = ) THEN true ELSE isnotnull(kimarite#16044) END END
[2025-11-12T22:26:37.269+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.269+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16248 = ) THEN false ELSE isnull(kimarite#16248) END OR CASE WHEN (kimarite#16248 = ) THEN true ELSE (kimarite#16248 = NA) END) THEN false ELSE CASE WHEN (kimarite#16248 = ) THEN true ELSE isnotnull(kimarite#16248) END END
[2025-11-12T22:26:37.269+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.270+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:37.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16656 = ) THEN false ELSE isnull(kimarite#16656) END OR CASE WHEN (kimarite#16656 = ) THEN true ELSE (kimarite#16656 = NA) END) THEN false ELSE CASE WHEN (kimarite#16656 = ) THEN true ELSE isnotnull(kimarite#16656) END END
[2025-11-12T22:26:37.272+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.272+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16860 = ) THEN false ELSE isnull(kimarite#16860) END OR CASE WHEN (kimarite#16860 = ) THEN true ELSE (kimarite#16860 = NA) END) THEN false ELSE CASE WHEN (kimarite#16860 = ) THEN true ELSE isnotnull(kimarite#16860) END END
[2025-11-12T22:26:37.279+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.280+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.280+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.280+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.280+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.280+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.282+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.282+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#21884 = ) THEN false ELSE isnull(kimarite#21884) END OR CASE WHEN (kimarite#21884 = ) THEN true ELSE (kimarite#21884 = NA) END) THEN false ELSE CASE WHEN (kimarite#21884 = ) THEN true ELSE isnotnull(kimarite#21884) END END
[2025-11-12T22:26:37.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#22088 = ) THEN false ELSE isnull(kimarite#22088) END OR CASE WHEN (kimarite#22088 = ) THEN true ELSE (kimarite#22088 = NA) END) THEN false ELSE CASE WHEN (kimarite#22088 = ) THEN true ELSE isnotnull(kimarite#22088) END END
[2025-11-12T22:26:37.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:37.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#22496 = ) THEN false ELSE isnull(kimarite#22496) END OR CASE WHEN (kimarite#22496 = ) THEN true ELSE (kimarite#22496 = NA) END) THEN false ELSE CASE WHEN (kimarite#22496 = ) THEN true ELSE isnotnull(kimarite#22496) END END
[2025-11-12T22:26:37.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#22700 = ) THEN false ELSE isnull(kimarite#22700) END OR CASE WHEN (kimarite#22700 = ) THEN true ELSE (kimarite#22700 = NA) END) THEN false ELSE CASE WHEN (kimarite#22700 = ) THEN true ELSE isnotnull(kimarite#22700) END END
[2025-11-12T22:26:37.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:37.290+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.291+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#23108 = ) THEN false ELSE isnull(kimarite#23108) END OR CASE WHEN (kimarite#23108 = ) THEN true ELSE (kimarite#23108 = NA) END) THEN false ELSE CASE WHEN (kimarite#23108 = ) THEN true ELSE isnotnull(kimarite#23108) END END
[2025-11-12T22:26:37.291+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.291+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#23312 = ) THEN false ELSE isnull(kimarite#23312) END OR CASE WHEN (kimarite#23312 = ) THEN true ELSE (kimarite#23312 = NA) END) THEN false ELSE CASE WHEN (kimarite#23312 = ) THEN true ELSE isnotnull(kimarite#23312) END END
[2025-11-12T22:26:37.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.294+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.294+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.295+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.295+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#24944 = ) THEN false ELSE isnull(kimarite#24944) END OR CASE WHEN (kimarite#24944 = ) THEN true ELSE (kimarite#24944 = NA) END) THEN false ELSE CASE WHEN (kimarite#24944 = ) THEN true ELSE isnotnull(kimarite#24944) END END
[2025-11-12T22:26:37.297+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.297+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#25148 = ) THEN false ELSE isnull(kimarite#25148) END OR CASE WHEN (kimarite#25148 = ) THEN true ELSE (kimarite#25148 = NA) END) THEN false ELSE CASE WHEN (kimarite#25148 = ) THEN true ELSE isnotnull(kimarite#25148) END END
[2025-11-12T22:26:37.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:37.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.299+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#26780 = ) THEN false ELSE isnull(kimarite#26780) END OR CASE WHEN (kimarite#26780 = ) THEN true ELSE (kimarite#26780 = NA) END) THEN false ELSE CASE WHEN (kimarite#26780 = ) THEN true ELSE isnotnull(kimarite#26780) END END
[2025-11-12T22:26:37.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#26984 = ) THEN false ELSE isnull(kimarite#26984) END OR CASE WHEN (kimarite#26984 = ) THEN true ELSE (kimarite#26984 = NA) END) THEN false ELSE CASE WHEN (kimarite#26984 = ) THEN true ELSE isnotnull(kimarite#26984) END END
[2025-11-12T22:26:37.301+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.301+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:37.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#27392 = ) THEN false ELSE isnull(kimarite#27392) END OR CASE WHEN (kimarite#27392 = ) THEN true ELSE (kimarite#27392 = NA) END) THEN false ELSE CASE WHEN (kimarite#27392 = ) THEN true ELSE isnotnull(kimarite#27392) END END
[2025-11-12T22:26:37.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#27596 = ) THEN false ELSE isnull(kimarite#27596) END OR CASE WHEN (kimarite#27596 = ) THEN true ELSE (kimarite#27596 = NA) END) THEN false ELSE CASE WHEN (kimarite#27596 = ) THEN true ELSE isnotnull(kimarite#27596) END END
[2025-11-12T22:26:37.305+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.308+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.308+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#28004 = ) THEN false ELSE isnull(kimarite#28004) END OR CASE WHEN (kimarite#28004 = ) THEN true ELSE (kimarite#28004 = NA) END) THEN false ELSE CASE WHEN (kimarite#28004 = ) THEN true ELSE isnotnull(kimarite#28004) END END
[2025-11-12T22:26:37.310+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.310+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#28208 = ) THEN false ELSE isnull(kimarite#28208) END OR CASE WHEN (kimarite#28208 = ) THEN true ELSE (kimarite#28208 = NA) END) THEN false ELSE CASE WHEN (kimarite#28208 = ) THEN true ELSE isnotnull(kimarite#28208) END END
[2025-11-12T22:26:37.310+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.311+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:37.311+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.311+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#28616 = ) THEN false ELSE isnull(kimarite#28616) END OR CASE WHEN (kimarite#28616 = ) THEN true ELSE (kimarite#28616 = NA) END) THEN false ELSE CASE WHEN (kimarite#28616 = ) THEN true ELSE isnotnull(kimarite#28616) END END
[2025-11-12T22:26:37.313+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.313+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#28820 = ) THEN false ELSE isnull(kimarite#28820) END OR CASE WHEN (kimarite#28820 = ) THEN true ELSE (kimarite#28820 = NA) END) THEN false ELSE CASE WHEN (kimarite#28820 = ) THEN true ELSE isnotnull(kimarite#28820) END END
[2025-11-12T22:26:37.313+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.314+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:37.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#29228 = ) THEN false ELSE isnull(kimarite#29228) END OR CASE WHEN (kimarite#29228 = ) THEN true ELSE (kimarite#29228 = NA) END) THEN false ELSE CASE WHEN (kimarite#29228 = ) THEN true ELSE isnotnull(kimarite#29228) END END
[2025-11-12T22:26:37.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.316+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#29432 = ) THEN false ELSE isnull(kimarite#29432) END OR CASE WHEN (kimarite#29432 = ) THEN true ELSE (kimarite#29432 = NA) END) THEN false ELSE CASE WHEN (kimarite#29432 = ) THEN true ELSE isnotnull(kimarite#29432) END END
[2025-11-12T22:26:37.317+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.317+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.317+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.317+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.318+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.318+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.319+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.319+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#31064 = ) THEN false ELSE isnull(kimarite#31064) END OR CASE WHEN (kimarite#31064 = ) THEN true ELSE (kimarite#31064 = NA) END) THEN false ELSE CASE WHEN (kimarite#31064 = ) THEN true ELSE isnotnull(kimarite#31064) END END
[2025-11-12T22:26:37.321+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.321+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#31268 = ) THEN false ELSE isnull(kimarite#31268) END OR CASE WHEN (kimarite#31268 = ) THEN true ELSE (kimarite#31268 = NA) END) THEN false ELSE CASE WHEN (kimarite#31268 = ) THEN true ELSE isnotnull(kimarite#31268) END END
[2025-11-12T22:26:37.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:37.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#32900 = ) THEN false ELSE isnull(kimarite#32900) END OR CASE WHEN (kimarite#32900 = ) THEN true ELSE (kimarite#32900 = NA) END) THEN false ELSE CASE WHEN (kimarite#32900 = ) THEN true ELSE isnotnull(kimarite#32900) END END
[2025-11-12T22:26:37.324+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.324+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#33104 = ) THEN false ELSE isnull(kimarite#33104) END OR CASE WHEN (kimarite#33104 = ) THEN true ELSE (kimarite#33104 = NA) END) THEN false ELSE CASE WHEN (kimarite#33104 = ) THEN true ELSE isnotnull(kimarite#33104) END END
[2025-11-12T22:26:37.324+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.325+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:37.326+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.326+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#33512 = ) THEN false ELSE isnull(kimarite#33512) END OR CASE WHEN (kimarite#33512 = ) THEN true ELSE (kimarite#33512 = NA) END) THEN false ELSE CASE WHEN (kimarite#33512 = ) THEN true ELSE isnotnull(kimarite#33512) END END
[2025-11-12T22:26:37.327+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.327+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#33716 = ) THEN false ELSE isnull(kimarite#33716) END OR CASE WHEN (kimarite#33716 = ) THEN true ELSE (kimarite#33716 = NA) END) THEN false ELSE CASE WHEN (kimarite#33716 = ) THEN true ELSE isnotnull(kimarite#33716) END END
[2025-11-12T22:26:37.534+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO CodeGenerator: Code generated in 5.691947 ms
[2025-11-12T22:26:37.537+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Registering RDD 189 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 19
[2025-11-12T22:26:37.537+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Got map stage job 46 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:37.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Final stage: ShuffleMapStage 73 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:37.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:37.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:37.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[189] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:37.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 20.5 KiB, free 433.6 MiB)
[2025-11-12T22:26:37.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 9.6 KiB, free 433.6 MiB)
[2025-11-12T22:26:37.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on eb021f2c8a8b:40023 (size: 9.6 KiB, free: 433.8 MiB)
[2025-11-12T22:26:37.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:37.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[189] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:37.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSchedulerImpl: Adding task set 73.0 with 2 tasks resource profile 0
[2025-11-12T22:26:37.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 221.4 KiB, free 433.3 MiB)
[2025-11-12T22:26:37.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 71) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 11355 bytes)
[2025-11-12T22:26:37.542+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSetManager: Starting task 1.0 in stage 73.0 (TID 72) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 11479 bytes)
[2025-11-12T22:26:37.549+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.3 MiB)
[2025-11-12T22:26:37.549+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 433.8 MiB)
[2025-11-12T22:26:37.550+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO SparkContext: Created broadcast 77 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:37.550+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.18.0.5:42325 (size: 9.6 KiB, free: 434.4 MiB)
[2025-11-12T22:26:37.551+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:37.554+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.18.0.5:43045 (size: 9.6 KiB, free: 434.4 MiB)
[2025-11-12T22:26:37.559+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 221.4 KiB, free 433.1 MiB)
[2025-11-12T22:26:37.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.1 MiB)
[2025-11-12T22:26:37.572+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 433.7 MiB)
[2025-11-12T22:26:37.573+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO SparkContext: Created broadcast 78 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:37.573+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:37.576+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Registering RDD 197 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 20
[2025-11-12T22:26:37.577+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Got map stage job 47 (javaToPython at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:26:37.577+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Final stage: ShuffleMapStage 74 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:37.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:37.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:37.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[197] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:37.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 26.9 KiB, free 433.0 MiB)
[2025-11-12T22:26:37.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 433.0 MiB)
[2025-11-12T22:26:37.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on eb021f2c8a8b:40023 (size: 9.5 KiB, free: 433.7 MiB)
[2025-11-12T22:26:37.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:37.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[197] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:26:37.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSchedulerImpl: Adding task set 74.0 with 4 tasks resource profile 0
[2025-11-12T22:26:37.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 221.4 KiB, free 432.8 MiB)
[2025-11-12T22:26:37.596+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 432.8 MiB)
[2025-11-12T22:26:37.596+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 433.7 MiB)
[2025-11-12T22:26:37.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO SparkContext: Created broadcast 80 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:37.598+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:37.602+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Registering RDD 201 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 21
[2025-11-12T22:26:37.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Got map stage job 48 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:37.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Final stage: ShuffleMapStage 75 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:37.604+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:37.604+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:37.608+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[201] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:37.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 51.7 KiB, free 432.7 MiB)
[2025-11-12T22:26:37.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 432.7 MiB)
[2025-11-12T22:26:37.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on eb021f2c8a8b:40023 (size: 21.8 KiB, free: 433.7 MiB)
[2025-11-12T22:26:37.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:37.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[201] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:37.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSchedulerImpl: Adding task set 75.0 with 2 tasks resource profile 0
[2025-11-12T22:26:37.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 221.4 KiB, free 432.5 MiB)
[2025-11-12T22:26:37.617+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 73) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:26:37.618+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSetManager: Finished task 1.0 in stage 73.0 (TID 72) in 76 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:26:37.619+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 432.4 MiB)
[2025-11-12T22:26:37.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 433.6 MiB)
[2025-11-12T22:26:37.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO SparkContext: Created broadcast 82 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:37.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:37.622+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 74) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:26:37.623+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 71) in 82 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:26:37.623+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool
[2025-11-12T22:26:37.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: ShuffleMapStage 73 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 0.086 s
[2025-11-12T22:26:37.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:37.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: running: Set(ShuffleMapStage 74, ShuffleMapStage 75)
[2025-11-12T22:26:37.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:37.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:37.627+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Registering RDD 205 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 22
[2025-11-12T22:26:37.627+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Got map stage job 49 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:37.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Final stage: ShuffleMapStage 76 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:37.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:37.630+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.18.0.5:42325 (size: 9.5 KiB, free: 434.4 MiB)
[2025-11-12T22:26:37.630+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:37.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[205] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:37.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 43.2 KiB, free 432.4 MiB)
[2025-11-12T22:26:37.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 432.4 MiB)
[2025-11-12T22:26:37.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on eb021f2c8a8b:40023 (size: 18.6 KiB, free: 433.6 MiB)
[2025-11-12T22:26:37.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:37.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[205] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:37.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.18.0.5:43045 (size: 9.5 KiB, free: 434.3 MiB)
[2025-11-12T22:26:37.634+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSchedulerImpl: Adding task set 76.0 with 2 tasks resource profile 0
[2025-11-12T22:26:37.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO CodeGenerator: Code generated in 5.494039 ms
[2025-11-12T22:26:37.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Registering RDD 207 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 23
[2025-11-12T22:26:37.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Got map stage job 50 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:37.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Final stage: ShuffleMapStage 77 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:37.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:37.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:37.642+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[207] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:37.642+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:26:37.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 16.7 KiB, free 432.4 MiB)
[2025-11-12T22:26:37.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 8.8 KiB, free 432.4 MiB)
[2025-11-12T22:26:37.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on eb021f2c8a8b:40023 (size: 8.8 KiB, free: 433.6 MiB)
[2025-11-12T22:26:37.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:37.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[207] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:37.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO TaskSchedulerImpl: Adding task set 77.0 with 2 tasks resource profile 0
[2025-11-12T22:26:37.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:26:37.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.693+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.694+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:37.695+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.695+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:37.697+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.698+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:37.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:37.707+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.711+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.711+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:37.712+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.712+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:37.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.719+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.720+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:37.721+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:37.727+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.727+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.731+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.732+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:37.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:37.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.739+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.740+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:37.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:37.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:37.750+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.750+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:37.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:37.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:37.755+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:37.755+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:37.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:37.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:37.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Removed broadcast_76_piece0 on eb021f2c8a8b:40023 in memory (size: 9.6 KiB, free: 433.6 MiB)
[2025-11-12T22:26:37.791+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.18.0.5:42325 in memory (size: 9.6 KiB, free: 434.4 MiB)
[2025-11-12T22:26:37.792+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:37 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.18.0.5:43045 in memory (size: 9.6 KiB, free: 434.3 MiB)
[2025-11-12T22:26:40.310+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:40 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 75) (172.18.0.5, executor 1, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:26:40.311+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:40 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 74) in 2688 ms on 172.18.0.5 (executor 1) (1/4)
[2025-11-12T22:26:40.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:40 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:26:40.415+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:40 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 76) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:26:40.416+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:40 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 73) in 2800 ms on 172.18.0.5 (executor 0) (2/4)
[2025-11-12T22:26:40.439+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:40 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:26:42.520+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 77) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:26:42.520+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO TaskSetManager: Finished task 2.0 in stage 74.0 (TID 75) in 2210 ms on 172.18.0.5 (executor 1) (3/4)
[2025-11-12T22:26:42.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.18.0.5:43045 (size: 21.8 KiB, free: 434.3 MiB)
[2025-11-12T22:26:42.545+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:26:42.897+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 78) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:26:42.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO TaskSetManager: Finished task 3.0 in stage 74.0 (TID 76) in 2483 ms on 172.18.0.5 (executor 0) (4/4)
[2025-11-12T22:26:42.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool
[2025-11-12T22:26:42.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO DAGScheduler: ShuffleMapStage 74 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 5.321 s
[2025-11-12T22:26:42.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:42.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO DAGScheduler: running: Set(ShuffleMapStage 75, ShuffleMapStage 76, ShuffleMapStage 77)
[2025-11-12T22:26:42.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:42.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:42.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.18.0.5:42325 (size: 21.8 KiB, free: 434.3 MiB)
[2025-11-12T22:26:42.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:26:42.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:42.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:42.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:42.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:42.943+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:42.943+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:42.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:42.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:42.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:42.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:42.951+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:42.951+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:42.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:42.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:42.959+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:42.960+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:42.961+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:42.961+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:42.964+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:42.964+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:42.967+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:42.967+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:42.968+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:42.968+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:42.973+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:42.973+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:42.976+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:42.976+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:42.978+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:42.978+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:42.980+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:42.980+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:42.983+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:42.983+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:42.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:42.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:42.987+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:42.987+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:42.989+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:42.990+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:42.991+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:42.991+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:42.992+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:42.993+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:42.997+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:42.997+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:42.998+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:42.999+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:42 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:43.034+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:26:43.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:26:43.037+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:26:43.038+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:26:43.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:26:43.040+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:26:43.041+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:26:43.055+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO CodeGenerator: Code generated in 9.140302 ms
[2025-11-12T22:26:43.059+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO CodeGenerator: Code generated in 3.094736 ms
[2025-11-12T22:26:43.063+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Registering RDD 212 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 24
[2025-11-12T22:26:43.064+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Got map stage job 51 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:43.064+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Final stage: ShuffleMapStage 79 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:43.067+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
[2025-11-12T22:26:43.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:43.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[212] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:43.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 63.1 KiB, free 432.3 MiB)
[2025-11-12T22:26:43.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 432.3 MiB)
[2025-11-12T22:26:43.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on eb021f2c8a8b:40023 (size: 27.5 KiB, free: 433.6 MiB)
[2025-11-12T22:26:43.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:43.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[212] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:43.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO TaskSchedulerImpl: Adding task set 79.0 with 2 tasks resource profile 0
[2025-11-12T22:26:43.077+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO CodeGenerator: Code generated in 10.638868 ms
[2025-11-12T22:26:43.082+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO CodeGenerator: Code generated in 3.502154 ms
[2025-11-12T22:26:43.088+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Registering RDD 217 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 25
[2025-11-12T22:26:43.088+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Got map stage job 52 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:43.089+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Final stage: ShuffleMapStage 80 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:43.089+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
[2025-11-12T22:26:43.089+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:43.090+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[217] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:43.091+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 64.3 KiB, free 432.2 MiB)
[2025-11-12T22:26:43.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.2 MiB)
[2025-11-12T22:26:43.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on eb021f2c8a8b:40023 (size: 28.0 KiB, free: 433.6 MiB)
[2025-11-12T22:26:43.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:43.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[217] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:43.093+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO TaskSchedulerImpl: Adding task set 80.0 with 2 tasks resource profile 0
[2025-11-12T22:26:43.125+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:43.126+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:43.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:43.133+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:43.134+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:43.134+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:43.136+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:43.137+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:43.139+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:43.139+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:43.140+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:43.140+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:43.144+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:43.145+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:43.146+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:43.147+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:43.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:43.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:43.150+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:43.150+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:43.153+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:43.153+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:43.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:43.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:43.158+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:43.159+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:43.161+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:43.161+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:43.162+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:43.163+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:43.165+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:43.167+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:43.169+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:43.170+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:43.171+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:43.171+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:43.174+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:43.175+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:43.177+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:43.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:43.179+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:43.179+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:43.181+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:43.182+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:43.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:43.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:43.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:43.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:43 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:45.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 79) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:26:45.029+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 77) in 2510 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:26:45.036+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.18.0.5:43045 (size: 18.6 KiB, free: 434.2 MiB)
[2025-11-12T22:26:45.046+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:26:45.320+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO TaskSetManager: Starting task 1.0 in stage 76.0 (TID 80) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:26:45.321+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 78) in 2424 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:26:45.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool
[2025-11-12T22:26:45.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: ShuffleMapStage 75 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 7.717 s
[2025-11-12T22:26:45.323+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:45.323+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: running: Set(ShuffleMapStage 79, ShuffleMapStage 76, ShuffleMapStage 80, ShuffleMapStage 77)
[2025-11-12T22:26:45.323+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:45.323+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:45.326+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.18.0.5:42325 (size: 18.6 KiB, free: 434.2 MiB)
[2025-11-12T22:26:45.336+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:26:45.356+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.356+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.358+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.358+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:45.360+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.360+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:45.362+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.363+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.365+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.365+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:45.366+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.366+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:45.370+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.373+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.373+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:45.374+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.374+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:45.377+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.377+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.379+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.379+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:45.380+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.381+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:45.385+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.385+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.387+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.388+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:45.389+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.389+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:45.390+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.391+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.393+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.393+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:45.394+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.394+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:45.397+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.397+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.399+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.399+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:45.400+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.401+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:45.402+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.403+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.405+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.405+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:45.406+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.406+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:45.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.437+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.438+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.439+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.442+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.444+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.445+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.446+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.447+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.448+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.449+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.450+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.451+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.452+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.453+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.454+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.455+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.456+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.458+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:45.460+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:26:45.478+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO CodeGenerator: Code generated in 15.803095 ms
[2025-11-12T22:26:45.483+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: Registering RDD 221 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 26
[2025-11-12T22:26:45.484+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: Got map stage job 53 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:26:45.487+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: Final stage: ShuffleMapStage 82 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:45.487+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 81)
[2025-11-12T22:26:45.489+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:45.489+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[221] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:45.489+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 70.1 KiB, free 432.1 MiB)
[2025-11-12T22:26:45.491+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 432.1 MiB)
[2025-11-12T22:26:45.491+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on eb021f2c8a8b:40023 (size: 27.6 KiB, free: 433.5 MiB)
[2025-11-12T22:26:45.491+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:45.492+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[221] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:45.492+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
[2025-11-12T22:26:45.523+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.528+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.529+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:45.529+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.529+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:45.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.534+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:45.536+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.537+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:45.543+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.547+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.548+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:45.549+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.549+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:45.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.554+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.556+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.556+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:45.557+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.557+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:45.562+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.562+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.565+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:45.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:45.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.572+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.572+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:45.574+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.574+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:45.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:45.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:45.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:45.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:45.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:45.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:45.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Removed broadcast_79_piece0 on eb021f2c8a8b:40023 in memory (size: 9.5 KiB, free: 433.5 MiB)
[2025-11-12T22:26:45.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:45.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:45.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.18.0.5:42325 in memory (size: 9.5 KiB, free: 434.2 MiB)
[2025-11-12T22:26:45.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.18.0.5:43045 in memory (size: 9.5 KiB, free: 434.2 MiB)
[2025-11-12T22:26:45.596+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Removed broadcast_81_piece0 on eb021f2c8a8b:40023 in memory (size: 21.8 KiB, free: 433.6 MiB)
[2025-11-12T22:26:45.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.18.0.5:43045 in memory (size: 21.8 KiB, free: 434.2 MiB)
[2025-11-12T22:26:45.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:45 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.18.0.5:42325 in memory (size: 21.8 KiB, free: 434.2 MiB)
[2025-11-12T22:26:47.253+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 81) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 11355 bytes)
[2025-11-12T22:26:47.254+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 79) in 2226 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:26:47.259+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.18.0.5:43045 (size: 8.8 KiB, free: 434.2 MiB)
[2025-11-12T22:26:47.313+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 82) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11479 bytes)
[2025-11-12T22:26:47.314+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 81) in 60 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:26:47.369+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 83) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:26:47.370+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 82) in 56 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:26:47.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool
[2025-11-12T22:26:47.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: ShuffleMapStage 77 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 9.729 s
[2025-11-12T22:26:47.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:47.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: running: Set(ShuffleMapStage 82, ShuffleMapStage 79, ShuffleMapStage 76, ShuffleMapStage 80)
[2025-11-12T22:26:47.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:47.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:47.375+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.18.0.5:43045 (size: 27.5 KiB, free: 434.2 MiB)
[2025-11-12T22:26:47.379+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.18.0.5:50962
[2025-11-12T22:26:47.433+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.434+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.439+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.439+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:47.442+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:47.447+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.448+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.453+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.454+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:47.456+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.456+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:47.463+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.464+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.467+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.468+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:47.470+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.470+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:47.474+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.474+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.478+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.478+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:47.480+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.480+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:47.486+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.487+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.489+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.489+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:47.490+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.490+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:47.493+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.493+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.497+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.498+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:47.500+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.500+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:47.503+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.503+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.507+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.507+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:47.509+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.509+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:47.511+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.511+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.513+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.514+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:47.514+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:47.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSetManager: Starting task 1.0 in stage 79.0 (TID 84) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:26:47.567+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSetManager: Finished task 1.0 in stage 76.0 (TID 80) in 2246 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:26:47.567+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-11-12T22:26:47.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: ShuffleMapStage 76 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 9.937 s
[2025-11-12T22:26:47.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:47.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: running: Set(ShuffleMapStage 82, ShuffleMapStage 79, ShuffleMapStage 80)
[2025-11-12T22:26:47.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:47.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:47.576+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.18.0.5:42325 (size: 27.5 KiB, free: 434.2 MiB)
[2025-11-12T22:26:47.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.18.0.5:50960
[2025-11-12T22:26:47.608+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.609+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:47.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.613+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:47.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.619+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:47.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:47.627+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:47.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:47.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:47.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:47.645+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.648+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:47.649+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.649+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:47.650+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.651+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:47.654+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.654+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:47.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:47.661+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.661+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:47.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:47.667+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.667+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:47.694+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:47.695+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:47.696+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:47.697+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:47.698+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:47.699+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:47.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:47.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:47.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:47.715+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO CodeGenerator: Code generated in 10.581765 ms
[2025-11-12T22:26:47.721+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:47.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: Got job 54 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:26:47.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: Final stage: ResultStage 84 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:47.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
[2025-11-12T22:26:47.723+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:47.723+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[224] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:47.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 44.9 KiB, free 432.2 MiB)
[2025-11-12T22:26:47.726+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 20.0 KiB, free 432.2 MiB)
[2025-11-12T22:26:47.726+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on eb021f2c8a8b:40023 (size: 20.0 KiB, free: 433.5 MiB)
[2025-11-12T22:26:47.727+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:47.727+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[224] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:47.727+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
[2025-11-12T22:26:47.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.736+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:47.739+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.739+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:47.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.744+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.744+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:47.745+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:47.750+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.750+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:47.753+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.753+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:47.755+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:47.759+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.759+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:47.763+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.764+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.766+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.766+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:47.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:47.769+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.769+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.771+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.772+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:47.772+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.773+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:47.775+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.776+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.778+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.778+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:47.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.780+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:47.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:47.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:47.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:47.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:47.787+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:47.788+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:47 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:49.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 85) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:26:49.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 83) in 1820 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:26:49.197+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.18.0.5:43045 (size: 28.0 KiB, free: 434.1 MiB)
[2025-11-12T22:26:49.469+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 86) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:26:49.470+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO TaskSetManager: Finished task 1.0 in stage 79.0 (TID 84) in 1904 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:26:49.471+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-11-12T22:26:49.471+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: ShuffleMapStage 79 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 6.405 s
[2025-11-12T22:26:49.472+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:49.472+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: running: Set(ResultStage 84, ShuffleMapStage 82, ShuffleMapStage 80)
[2025-11-12T22:26:49.472+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:49.472+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:49.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.18.0.5:42325 (size: 28.0 KiB, free: 434.2 MiB)
[2025-11-12T22:26:49.514+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:49.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:49.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:49.518+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:49.519+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:49.519+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:49.521+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:49.522+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:49.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:49.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:49.525+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:49.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:49.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:49.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:49.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:49.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:49.537+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:49.537+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:49.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:49.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:49.543+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:49.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:49.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:49.545+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:49.552+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:49.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:49.557+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:49.557+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:49.559+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:49.559+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:49.562+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:49.563+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:49.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:49.567+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:49.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:49.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:49.573+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:49.574+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:49.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:49.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:49.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:49.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:49.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:49.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:49.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:49.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:49.590+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:49.591+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:49.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:26:49.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:26:49.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:26:49.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:26:49.645+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:26:49.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO CodeGenerator: Code generated in 5.796951 ms
[2025-11-12T22:26:49.661+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:49.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: Got job 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-11-12T22:26:49.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: Final stage: ResultStage 86 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:49.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
[2025-11-12T22:26:49.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:49.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[227] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:49.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 60.2 KiB, free 432.1 MiB)
[2025-11-12T22:26:49.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 26.0 KiB, free 432.1 MiB)
[2025-11-12T22:26:49.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on eb021f2c8a8b:40023 (size: 26.0 KiB, free: 433.5 MiB)
[2025-11-12T22:26:49.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:49.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 86 (MapPartitionsRDD[227] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:49.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO TaskSchedulerImpl: Adding task set 86.0 with 2 tasks resource profile 0
[2025-11-12T22:26:49.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Removed broadcast_84_piece0 on eb021f2c8a8b:40023 in memory (size: 8.8 KiB, free: 433.5 MiB)
[2025-11-12T22:26:49.799+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 172.18.0.5:43045 in memory (size: 8.8 KiB, free: 434.1 MiB)
[2025-11-12T22:26:49.811+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Removed broadcast_83_piece0 on eb021f2c8a8b:40023 in memory (size: 18.6 KiB, free: 433.5 MiB)
[2025-11-12T22:26:49.814+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.18.0.5:43045 in memory (size: 18.6 KiB, free: 434.2 MiB)
[2025-11-12T22:26:49.815+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.18.0.5:42325 in memory (size: 18.6 KiB, free: 434.2 MiB)
[2025-11-12T22:26:49.819+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Removed broadcast_85_piece0 on eb021f2c8a8b:40023 in memory (size: 27.5 KiB, free: 433.6 MiB)
[2025-11-12T22:26:49.820+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.18.0.5:42325 in memory (size: 27.5 KiB, free: 434.2 MiB)
[2025-11-12T22:26:49.821+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:49 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.18.0.5:43045 in memory (size: 27.5 KiB, free: 434.2 MiB)
[2025-11-12T22:26:51.062+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 87) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:26:51.063+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 85) in 1875 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:26:51.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.18.0.5:43045 (size: 27.6 KiB, free: 434.2 MiB)
[2025-11-12T22:26:51.076+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.18.0.5:50962
[2025-11-12T22:26:51.232+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 88) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:51.233+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 87) in 171 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:51.233+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool
[2025-11-12T22:26:51.234+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: ShuffleMapStage 82 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 5.748 s
[2025-11-12T22:26:51.234+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:51.234+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: running: Set(ResultStage 84, ResultStage 86, ShuffleMapStage 80)
[2025-11-12T22:26:51.235+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:51.235+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:51.241+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.18.0.5:43045 (size: 20.0 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.246+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.18.0.5:50962
[2025-11-12T22:26:51.277+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.278+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.279+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 89) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:51.279+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 88) in 48 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:51.279+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool
[2025-11-12T22:26:51.280+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: ResultStage 84 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 3.556 s
[2025-11-12T22:26:51.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:51.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished
[2025-11-12T22:26:51.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Job 54 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 3.559072 s
[2025-11-12T22:26:51.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:51.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:51.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 432.2 MiB)
[2025-11-12T22:26:51.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on eb021f2c8a8b:40023 (size: 47.0 KiB, free: 433.5 MiB)
[2025-11-12T22:26:51.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Created broadcast 90 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:51.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.288+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.288+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.18.0.5:43045 (size: 26.0 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.289+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.290+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:51.291+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.292+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:51.292+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.18.0.5:50962
[2025-11-12T22:26:51.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.301+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.302+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:51.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:51.307+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.308+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.312+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.313+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:51.314+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:51.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.323+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.326+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.326+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:51.328+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.328+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:51.331+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.331+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.335+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.337+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:51.338+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.338+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:51.343+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.344+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.348+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.350+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:51.350+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.351+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:51.352+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.353+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.356+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.356+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:51.357+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.358+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:51.407+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.409+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.411+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.413+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.414+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.416+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.420+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.422+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.423+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.424+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 90) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:51.428+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 86) in 1955 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:26:51.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool
[2025-11-12T22:26:51.431+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: ShuffleMapStage 80 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 8.335 s
[2025-11-12T22:26:51.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:51.433+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.434+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: running: Set(ResultStage 86)
[2025-11-12T22:26:51.434+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:51.434+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:51.435+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.438+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.442+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.18.0.5:42325 (size: 26.0 KiB, free: 434.2 MiB)
[2025-11-12T22:26:51.442+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.444+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.445+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.18.0.5:50960
[2025-11-12T22:26:51.446+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.447+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.448+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.450+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.452+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.459+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.464+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.466+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.467+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.468+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.469+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:51.470+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added taskresult_89 in memory on 172.18.0.5:43045 (size: 1232.3 KiB, free: 432.9 MiB)
[2025-11-12T22:26:51.480+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 89) in 202 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:26:51.484+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed taskresult_89 on 172.18.0.5:43045 in memory (size: 1232.3 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.493+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO CodeGenerator: Code generated in 15.024451 ms
[2025-11-12T22:26:51.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO CodeGenerator: Code generated in 14.401325 ms
[2025-11-12T22:26:51.505+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:51.506+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:51.507+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Got job 56 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:26:51.507+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Final stage: ResultStage 89 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:51.508+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
[2025-11-12T22:26:51.509+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:51.509+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[234] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:51.511+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 66.8 KiB, free 432.1 MiB)
[2025-11-12T22:26:51.512+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 26.9 KiB, free 432.1 MiB)
[2025-11-12T22:26:51.513+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on eb021f2c8a8b:40023 (size: 26.9 KiB, free: 433.5 MiB)
[2025-11-12T22:26:51.513+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:51.514+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[234] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:51.514+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
[2025-11-12T22:26:51.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Got job 57 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:26:51.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Final stage: ResultStage 90 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:51.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
[2025-11-12T22:26:51.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 91) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:51.518+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:51.519+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[235] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:51.522+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 69.7 KiB, free 432.0 MiB)
[2025-11-12T22:26:51.523+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 432.0 MiB)
[2025-11-12T22:26:51.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on eb021f2c8a8b:40023 (size: 27.5 KiB, free: 433.5 MiB)
[2025-11-12T22:26:51.525+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:51.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[235] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:51.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
[2025-11-12T22:26:51.528+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.18.0.5:43045 (size: 26.9 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.529+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.531+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.531+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:51.531+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.532+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:51.536+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:51.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.18.0.5:50962
[2025-11-12T22:26:51.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:51.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.547+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.547+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.548+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:51.548+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.549+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:51.552+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.555+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.556+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.556+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:51.556+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.557+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:51.562+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.563+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.563+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:51.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.565+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:51.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.568+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.570+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:51.571+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.572+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:51.576+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.577+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:51.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:51.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:51.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:51.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 92) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:51.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 91) in 71 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:51.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool
[2025-11-12T22:26:51.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: ResultStage 89 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.077 s
[2025-11-12T22:26:51.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:51.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
[2025-11-12T22:26:51.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Job 56 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.081110 s
[2025-11-12T22:26:51.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 56.1 KiB, free 432.0 MiB)
[2025-11-12T22:26:51.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on eb021f2c8a8b:40023 (size: 56.1 KiB, free: 433.4 MiB)
[2025-11-12T22:26:51.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Created broadcast 93 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:51.596+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.18.0.5:43045 (size: 27.5 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.650+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(25), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:26:51.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(25), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:26:51.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(25), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:26:51.654+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO ShufflePartitionsUtil: For shuffle(25), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:26:51.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:26:51.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 92) in 73 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:26:51.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-11-12T22:26:51.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: ResultStage 90 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.139 s
[2025-11-12T22:26:51.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:51.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished
[2025-11-12T22:26:51.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Job 57 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.152561 s
[2025-11-12T22:26:51.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 431.9 MiB)
[2025-11-12T22:26:51.667+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on eb021f2c8a8b:40023 (size: 90.5 KiB, free: 433.3 MiB)
[2025-11-12T22:26:51.668+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Created broadcast 94 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:51.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO CodeGenerator: Code generated in 9.133996 ms
[2025-11-12T22:26:51.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added taskresult_90 in memory on 172.18.0.5:42325 (size: 1257.7 KiB, free: 433.0 MiB)
[2025-11-12T22:26:51.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 90) in 258 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:26:51.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool
[2025-11-12T22:26:51.685+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:51.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: ResultStage 86 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 2.019 s
[2025-11-12T22:26:51.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:51.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished
[2025-11-12T22:26:51.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Job 55 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 2.021986 s
[2025-11-12T22:26:51.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Got job 58 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-11-12T22:26:51.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Final stage: ResultStage 93 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:26:51.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)
[2025-11-12T22:26:51.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:51.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[238] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:26:51.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed taskresult_90 on 172.18.0.5:42325 in memory (size: 1257.7 KiB, free: 434.2 MiB)
[2025-11-12T22:26:51.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 61.5 KiB, free 431.8 MiB)
[2025-11-12T22:26:51.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 26.4 KiB, free 431.8 MiB)
[2025-11-12T22:26:51.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on eb021f2c8a8b:40023 (size: 26.4 KiB, free: 433.3 MiB)
[2025-11-12T22:26:51.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:51.693+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 93 (MapPartitionsRDD[238] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:51.693+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Adding task set 93.0 with 2 tasks resource profile 0
[2025-11-12T22:26:51.694+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 93) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:51.694+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 94) (172.18.0.5, executor 1, partition 1, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:26:51.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed broadcast_92_piece0 on eb021f2c8a8b:40023 in memory (size: 27.5 KiB, free: 433.3 MiB)
[2025-11-12T22:26:51.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 172.18.0.5:43045 in memory (size: 27.5 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.18.0.5:43045 (size: 26.4 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.18.0.5:42325 (size: 26.4 KiB, free: 434.2 MiB)
[2025-11-12T22:26:51.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed broadcast_89_piece0 on eb021f2c8a8b:40023 in memory (size: 26.0 KiB, free: 433.3 MiB)
[2025-11-12T22:26:51.717+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.18.0.5:42325 in memory (size: 26.0 KiB, free: 434.2 MiB)
[2025-11-12T22:26:51.718+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.18.0.5:43045 in memory (size: 26.0 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.718+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.718+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.719+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.18.0.5:50960
[2025-11-12T22:26:51.719+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.18.0.5:50962
[2025-11-12T22:26:51.719+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.721+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4362L)
[2025-11-12T22:26:51.721+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3672L)
[2025-11-12T22:26:51.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed broadcast_88_piece0 on eb021f2c8a8b:40023 in memory (size: 20.0 KiB, free: 433.4 MiB)
[2025-11-12T22:26:51.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.723+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.723+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9237L)
[2025-11-12T22:26:51.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 172.18.0.5:43045 in memory (size: 20.0 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.726+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#9844L)
[2025-11-12T22:26:51.731+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed broadcast_91_piece0 on eb021f2c8a8b:40023 in memory (size: 26.9 KiB, free: 433.4 MiB)
[2025-11-12T22:26:51.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11558L)
[2025-11-12T22:26:51.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12165L)
[2025-11-12T22:26:51.736+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.18.0.5:43045 in memory (size: 26.9 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.736+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.737+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#15842L)
[2025-11-12T22:26:51.739+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.739+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16449L)
[2025-11-12T22:26:51.751+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.753+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.754+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.754+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#22294L)
[2025-11-12T22:26:51.754+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.755+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#22901L)
[2025-11-12T22:26:51.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.757+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.759+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#26578L)
[2025-11-12T22:26:51.759+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.760+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#27185L)
[2025-11-12T22:26:51.761+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.762+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.763+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.763+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#28414L)
[2025-11-12T22:26:51.763+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.764+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#29021L)
[2025-11-12T22:26:51.765+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.765+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.766+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:26:51.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#32698L)
[2025-11-12T22:26:51.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:26:51.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#33305L)
[2025-11-12T22:26:51.801+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 428.1 MiB)
[2025-11-12T22:26:51.804+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on eb021f2c8a8b:40023 (size: 4.0 MiB, free: 429.4 MiB)
[2025-11-12T22:26:51.805+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_96_piece1 stored as bytes in memory (estimated size 1049.4 KiB, free 427.1 MiB)
[2025-11-12T22:26:51.805+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_96_piece1 in memory on eb021f2c8a8b:40023 (size: 1049.4 KiB, free: 428.4 MiB)
[2025-11-12T22:26:51.806+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Created broadcast 96 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:51.836+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO CodeGenerator: Code generated in 13.124369 ms
[2025-11-12T22:26:51.839+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TorrentBroadcast: Started reading broadcast variable 90 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:51.840+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TorrentBroadcast: Reading broadcast variable 90 took 0 ms
[2025-11-12T22:26:51.842+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TorrentBroadcast: Started reading broadcast variable 93 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:51.842+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TorrentBroadcast: Reading broadcast variable 93 took 0 ms
[2025-11-12T22:26:51.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO CodeGenerator: Code generated in 6.892299 ms
[2025-11-12T22:26:51.855+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 221.3 KiB, free 426.9 MiB)
[2025-11-12T22:26:51.861+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 426.8 MiB)
[2025-11-12T22:26:51.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 428.3 MiB)
[2025-11-12T22:26:51.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Created broadcast 97 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:51.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:51.878+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO CodeGenerator: Code generated in 6.780594 ms
[2025-11-12T22:26:51.881+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 221.3 KiB, free 426.6 MiB)
[2025-11-12T22:26:51.884+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added taskresult_94 in memory on 172.18.0.5:43045 (size: 1248.0 KiB, free: 432.9 MiB)
[2025-11-12T22:26:51.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 426.6 MiB)
[2025-11-12T22:26:51.890+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on eb021f2c8a8b:40023 (size: 37.3 KiB, free: 428.3 MiB)
[2025-11-12T22:26:51.891+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Created broadcast 98 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:51.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added taskresult_93 in memory on 172.18.0.5:42325 (size: 1247.7 KiB, free: 433.0 MiB)
[2025-11-12T22:26:51.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:51.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 94) in 202 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:26:51.896+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed taskresult_94 on 172.18.0.5:43045 in memory (size: 1248.0 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.897+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 93) in 207 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:26:51.897+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool
[2025-11-12T22:26:51.898+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: ResultStage 93 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.212 s
[2025-11-12T22:26:51.898+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:26:51.898+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
[2025-11-12T22:26:51.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Job 58 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.215937 s
[2025-11-12T22:26:51.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Registering RDD 247 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 27
[2025-11-12T22:26:51.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Got map stage job 59 (javaToPython at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:26:51.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Final stage: ShuffleMapStage 94 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:51.901+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:51.901+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:51.901+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[247] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:51.902+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Removed taskresult_93 on 172.18.0.5:42325 in memory (size: 1247.7 KiB, free: 434.2 MiB)
[2025-11-12T22:26:51.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 119.2 KiB, free 426.5 MiB)
[2025-11-12T22:26:51.904+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 43.1 KiB, free 426.4 MiB)
[2025-11-12T22:26:51.904+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on eb021f2c8a8b:40023 (size: 43.1 KiB, free: 428.3 MiB)
[2025-11-12T22:26:51.905+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:51.905+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[247] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:26:51.905+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSchedulerImpl: Adding task set 94.0 with 4 tasks resource profile 0
[2025-11-12T22:26:51.906+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 95) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:26:51.906+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 96) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:26:51.915+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.18.0.5:42325 (size: 43.1 KiB, free: 434.2 MiB)
[2025-11-12T22:26:51.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.18.0.5:43045 (size: 43.1 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.934+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.935+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.940+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.18.0.5:42325 (size: 47.0 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.18.0.5:43045 (size: 47.0 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.950+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.18.0.5:42325 (size: 56.1 KiB, free: 434.1 MiB)
[2025-11-12T22:26:51.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.956+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.958+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.958+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.18.0.5:43045 (size: 56.1 KiB, free: 434.0 MiB)
[2025-11-12T22:26:51.962+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.963+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.964+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:51.965+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:51.988+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:51 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.0 MiB)
[2025-11-12T22:26:52.005+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.0 MiB)
[2025-11-12T22:26:52.013+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 422.4 MiB)
[2025-11-12T22:26:52.014+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on eb021f2c8a8b:40023 (size: 4.0 MiB, free: 424.3 MiB)
[2025-11-12T22:26:52.015+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_100_piece1 stored as bytes in memory (estimated size 1054.7 KiB, free 421.4 MiB)
[2025-11-12T22:26:52.017+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_100_piece1 in memory on eb021f2c8a8b:40023 (size: 1054.7 KiB, free: 423.2 MiB)
[2025-11-12T22:26:52.018+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO SparkContext: Created broadcast 100 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:26:52.030+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TorrentBroadcast: Started reading broadcast variable 94 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:52.031+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TorrentBroadcast: Reading broadcast variable 94 took 0 ms
[2025-11-12T22:26:52.064+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO CodeGenerator: Code generated in 23.184805 ms
[2025-11-12T22:26:52.067+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 225.0 KiB, free 421.2 MiB)
[2025-11-12T22:26:52.074+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 421.1 MiB)
[2025-11-12T22:26:52.075+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on eb021f2c8a8b:40023 (size: 38.3 KiB, free: 423.2 MiB)
[2025-11-12T22:26:52.076+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO SparkContext: Created broadcast 101 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:52.077+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:52.081+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Registering RDD 251 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 28
[2025-11-12T22:26:52.082+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Got map stage job 60 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:52.083+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Final stage: ShuffleMapStage 95 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:52.083+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:52.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:52.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[251] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:52.085+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 51.5 KiB, free 421.1 MiB)
[2025-11-12T22:26:52.085+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 421.1 MiB)
[2025-11-12T22:26:52.086+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on eb021f2c8a8b:40023 (size: 16.3 KiB, free: 423.2 MiB)
[2025-11-12T22:26:52.086+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:52.087+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[251] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:52.087+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks resource profile 0
[2025-11-12T22:26:52.109+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO CodeGenerator: Code generated in 15.284063 ms
[2025-11-12T22:26:52.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 222.7 KiB, free 420.9 MiB)
[2025-11-12T22:26:52.117+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 420.8 MiB)
[2025-11-12T22:26:52.118+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on eb021f2c8a8b:40023 (size: 37.8 KiB, free: 423.1 MiB)
[2025-11-12T22:26:52.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO SparkContext: Created broadcast 103 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:52.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:52.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Registering RDD 255 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 29
[2025-11-12T22:26:52.126+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Got map stage job 61 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:52.128+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Final stage: ShuffleMapStage 96 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:52.129+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:52.130+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:52.130+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[255] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:52.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 37.7 KiB, free 420.8 MiB)
[2025-11-12T22:26:52.135+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 420.8 MiB)
[2025-11-12T22:26:52.136+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on eb021f2c8a8b:40023 (size: 13.5 KiB, free: 423.1 MiB)
[2025-11-12T22:26:52.136+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:52.138+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[255] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:52.138+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TaskSchedulerImpl: Adding task set 96.0 with 2 tasks resource profile 0
[2025-11-12T22:26:52.168+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:52.168+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:52.175+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:52.176+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:52.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:52.185+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:52.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:26:52.191+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:26:52.230+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TorrentBroadcast: Started reading broadcast variable 100 with 2 pieces (estimated total size 8.0 MiB)
[2025-11-12T22:26:52.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TorrentBroadcast: Reading broadcast variable 100 took 0 ms
[2025-11-12T22:26:52.254+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TorrentBroadcast: Started reading broadcast variable 93 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:52.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TorrentBroadcast: Reading broadcast variable 93 took 0 ms
[2025-11-12T22:26:52.257+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TorrentBroadcast: Started reading broadcast variable 94 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:26:52.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TorrentBroadcast: Reading broadcast variable 94 took 0 ms
[2025-11-12T22:26:52.289+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO CodeGenerator: Code generated in 23.705028 ms
[2025-11-12T22:26:52.291+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 225.0 KiB, free 420.6 MiB)
[2025-11-12T22:26:52.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 420.5 MiB)
[2025-11-12T22:26:52.299+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on eb021f2c8a8b:40023 (size: 38.3 KiB, free: 423.1 MiB)
[2025-11-12T22:26:52.299+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO SparkContext: Created broadcast 105 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:52.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:52.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Registering RDD 259 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 30
[2025-11-12T22:26:52.304+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Got map stage job 62 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:52.304+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Final stage: ShuffleMapStage 97 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:52.305+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:52.305+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:52.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[259] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:52.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 51.5 KiB, free 420.5 MiB)
[2025-11-12T22:26:52.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 420.5 MiB)
[2025-11-12T22:26:52.307+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on eb021f2c8a8b:40023 (size: 16.3 KiB, free: 423.1 MiB)
[2025-11-12T22:26:52.307+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:52.307+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[259] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:52.308+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TaskSchedulerImpl: Adding task set 97.0 with 2 tasks resource profile 0
[2025-11-12T22:26:52.328+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO CodeGenerator: Code generated in 16.108798 ms
[2025-11-12T22:26:52.330+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 222.7 KiB, free 420.2 MiB)
[2025-11-12T22:26:52.338+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 420.2 MiB)
[2025-11-12T22:26:52.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on eb021f2c8a8b:40023 (size: 37.8 KiB, free: 423.0 MiB)
[2025-11-12T22:26:52.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO SparkContext: Created broadcast 107 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:26:52.340+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:26:52.343+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Registering RDD 263 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 31
[2025-11-12T22:26:52.345+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Got map stage job 63 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:26:52.346+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Final stage: ShuffleMapStage 98 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:52.347+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:26:52.347+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:52.348+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[263] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:52.348+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 37.7 KiB, free 420.2 MiB)
[2025-11-12T22:26:52.348+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 420.1 MiB)
[2025-11-12T22:26:52.348+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on eb021f2c8a8b:40023 (size: 13.5 KiB, free: 423.0 MiB)
[2025-11-12T22:26:52.349+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:52.349+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[263] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:26:52.349+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO TaskSchedulerImpl: Adding task set 98.0 with 2 tasks resource profile 0
[2025-11-12T22:26:52.366+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Removed broadcast_86_piece0 on eb021f2c8a8b:40023 in memory (size: 28.0 KiB, free: 423.0 MiB)
[2025-11-12T22:26:52.367+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.18.0.5:43045 in memory (size: 28.0 KiB, free: 434.0 MiB)
[2025-11-12T22:26:52.368+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.18.0.5:42325 in memory (size: 28.0 KiB, free: 434.0 MiB)
[2025-11-12T22:26:52.370+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Removed broadcast_95_piece0 on eb021f2c8a8b:40023 in memory (size: 26.4 KiB, free: 423.1 MiB)
[2025-11-12T22:26:52.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.18.0.5:42325 in memory (size: 26.4 KiB, free: 434.1 MiB)
[2025-11-12T22:26:52.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.18.0.5:43045 in memory (size: 26.4 KiB, free: 434.0 MiB)
[2025-11-12T22:26:52.375+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Removed broadcast_87_piece0 on eb021f2c8a8b:40023 in memory (size: 27.6 KiB, free: 423.1 MiB)
[2025-11-12T22:26:52.376+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:52 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 172.18.0.5:43045 in memory (size: 27.6 KiB, free: 434.0 MiB)
[2025-11-12T22:26:53.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:53 INFO TaskSetManager: Starting task 2.0 in stage 94.0 (TID 97) (172.18.0.5, executor 1, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:26:53.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:53 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 95) in 1610 ms on 172.18.0.5 (executor 1) (1/4)
[2025-11-12T22:26:53.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:53 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.18.0.5:43045 (size: 37.3 KiB, free: 434.0 MiB)
[2025-11-12T22:26:53.560+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:53 INFO TaskSetManager: Starting task 3.0 in stage 94.0 (TID 98) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:26:53.560+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:53 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 96) in 1654 ms on 172.18.0.5 (executor 0) (2/4)
[2025-11-12T22:26:53.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:53 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.18.0.5:42325 (size: 37.3 KiB, free: 434.0 MiB)
[2025-11-12T22:26:54.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 99) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:26:54.678+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO TaskSetManager: Finished task 2.0 in stage 94.0 (TID 97) in 1162 ms on 172.18.0.5 (executor 1) (3/4)
[2025-11-12T22:26:54.683+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.18.0.5:43045 (size: 16.3 KiB, free: 434.0 MiB)
[2025-11-12T22:26:54.707+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO BlockManagerInfo: Added broadcast_96_piece1 in memory on 172.18.0.5:43045 (size: 1049.4 KiB, free: 433.0 MiB)
[2025-11-12T22:26:54.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.18.0.5:43045 (size: 4.0 MiB, free: 429.0 MiB)
[2025-11-12T22:26:54.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.18.0.5:43045 (size: 90.5 KiB, free: 428.9 MiB)
[2025-11-12T22:26:54.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.18.0.5:43045 (size: 38.3 KiB, free: 428.8 MiB)
[2025-11-12T22:26:54.927+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 100) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:26:54.928+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO TaskSetManager: Finished task 3.0 in stage 94.0 (TID 98) in 1368 ms on 172.18.0.5 (executor 0) (4/4)
[2025-11-12T22:26:54.929+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool
[2025-11-12T22:26:54.929+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO DAGScheduler: ShuffleMapStage 94 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 3.028 s
[2025-11-12T22:26:54.929+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:26:54.929+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO DAGScheduler: running: Set(ShuffleMapStage 96, ShuffleMapStage 97, ShuffleMapStage 98, ShuffleMapStage 95)
[2025-11-12T22:26:54.930+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:26:54.930+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO DAGScheduler: failed: Set()
[2025-11-12T22:26:54.933+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.18.0.5:42325 (size: 16.3 KiB, free: 434.0 MiB)
[2025-11-12T22:26:54.960+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.18.0.5:42325 (size: 4.0 MiB, free: 430.0 MiB)
[2025-11-12T22:26:54.965+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO BlockManagerInfo: Added broadcast_96_piece1 in memory on 172.18.0.5:42325 (size: 1049.4 KiB, free: 429.0 MiB)
[2025-11-12T22:26:54.982+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.18.0.5:42325 (size: 90.5 KiB, free: 428.9 MiB)
[2025-11-12T22:26:54.988+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:54 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.18.0.5:42325 (size: 38.3 KiB, free: 428.9 MiB)
[2025-11-12T22:26:55.024+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:55.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:55.027+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:55.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:55.029+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:55.030+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:55.032+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:55.033+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:26:55.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:26:55.036+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:26:55.061+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO CodeGenerator: Code generated in 18.66881 ms
[2025-11-12T22:26:55.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO DAGScheduler: Registering RDD 267 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 32
[2025-11-12T22:26:55.075+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO DAGScheduler: Got map stage job 64 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:26:55.076+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO DAGScheduler: Final stage: ShuffleMapStage 100 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:26:55.076+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)
[2025-11-12T22:26:55.077+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:26:55.077+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[267] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:26:55.077+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 132.1 KiB, free 420.3 MiB)
[2025-11-12T22:26:55.078+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 420.2 MiB)
[2025-11-12T22:26:55.078+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on eb021f2c8a8b:40023 (size: 47.9 KiB, free: 423.1 MiB)
[2025-11-12T22:26:55.078+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:26:55.078+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[267] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:26:55.079+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:55 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
[2025-11-12T22:26:59.801+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:59 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 101) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:26:59.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:59 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 100) in 4874 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:26:59.807+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:59 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.18.0.5:42325 (size: 13.5 KiB, free: 428.9 MiB)
[2025-11-12T22:26:59.837+0000] {spark_submit.py:571} INFO - 25/11/12 22:26:59 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.18.0.5:42325 (size: 37.8 KiB, free: 428.8 MiB)
[2025-11-12T22:27:02.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:02 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 102) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:27:02.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:02 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 99) in 7391 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:27:02.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:02 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool
[2025-11-12T22:27:02.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:02 INFO DAGScheduler: ShuffleMapStage 95 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 9.987 s
[2025-11-12T22:27:02.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:02 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:27:02.071+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:02 INFO DAGScheduler: running: Set(ShuffleMapStage 96, ShuffleMapStage 100, ShuffleMapStage 97, ShuffleMapStage 98)
[2025-11-12T22:27:02.071+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:02 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:27:02.072+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:02 INFO DAGScheduler: failed: Set()
[2025-11-12T22:27:02.076+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:02 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.18.0.5:43045 (size: 13.5 KiB, free: 428.8 MiB)
[2025-11-12T22:27:02.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:02 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.18.0.5:43045 (size: 37.8 KiB, free: 428.8 MiB)
[2025-11-12T22:27:05.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:05 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 103) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:27:05.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:05 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 101) in 5838 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:27:05.645+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:05 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.18.0.5:42325 (size: 16.3 KiB, free: 428.8 MiB)
[2025-11-12T22:27:05.668+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:05 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.18.0.5:42325 (size: 4.0 MiB, free: 424.8 MiB)
[2025-11-12T22:27:05.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:05 INFO BlockManagerInfo: Added broadcast_100_piece1 in memory on 172.18.0.5:42325 (size: 1054.7 KiB, free: 423.8 MiB)
[2025-11-12T22:27:05.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:05 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.18.0.5:42325 (size: 38.3 KiB, free: 423.7 MiB)
[2025-11-12T22:27:06.777+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO TaskSetManager: Starting task 1.0 in stage 97.0 (TID 104) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:27:06.777+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 102) in 4709 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:27:06.778+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool
[2025-11-12T22:27:06.778+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO DAGScheduler: ShuffleMapStage 96 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 14.653 s
[2025-11-12T22:27:06.778+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:27:06.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO DAGScheduler: running: Set(ShuffleMapStage 100, ShuffleMapStage 97, ShuffleMapStage 98)
[2025-11-12T22:27:06.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:27:06.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO DAGScheduler: failed: Set()
[2025-11-12T22:27:06.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.18.0.5:43045 (size: 16.3 KiB, free: 428.8 MiB)
[2025-11-12T22:27:06.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO BlockManagerInfo: Added broadcast_100_piece1 in memory on 172.18.0.5:43045 (size: 1054.7 KiB, free: 427.7 MiB)
[2025-11-12T22:27:06.809+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.18.0.5:43045 (size: 4.0 MiB, free: 423.7 MiB)
[2025-11-12T22:27:06.828+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:06 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.18.0.5:43045 (size: 38.3 KiB, free: 423.7 MiB)
[2025-11-12T22:27:11.557+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:11 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 105) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:27:11.558+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:11 INFO TaskSetManager: Finished task 1.0 in stage 97.0 (TID 104) in 4782 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:27:11.563+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:11 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.18.0.5:43045 (size: 13.5 KiB, free: 423.7 MiB)
[2025-11-12T22:27:11.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:11 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.18.0.5:43045 (size: 37.8 KiB, free: 423.7 MiB)
[2025-11-12T22:27:12.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 106) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:27:12.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 103) in 7062 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:27:12.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool
[2025-11-12T22:27:12.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO DAGScheduler: ShuffleMapStage 97 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 20.398 s
[2025-11-12T22:27:12.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:27:12.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO DAGScheduler: running: Set(ShuffleMapStage 100, ShuffleMapStage 98)
[2025-11-12T22:27:12.704+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:27:12.704+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO DAGScheduler: failed: Set()
[2025-11-12T22:27:12.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.18.0.5:42325 (size: 13.5 KiB, free: 423.7 MiB)
[2025-11-12T22:27:12.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_104_piece0 on eb021f2c8a8b:40023 in memory (size: 13.5 KiB, free: 423.1 MiB)
[2025-11-12T22:27:12.717+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.18.0.5:43045 in memory (size: 13.5 KiB, free: 423.7 MiB)
[2025-11-12T22:27:12.717+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.18.0.5:42325 in memory (size: 13.5 KiB, free: 423.7 MiB)
[2025-11-12T22:27:12.721+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_106_piece0 on eb021f2c8a8b:40023 in memory (size: 16.3 KiB, free: 423.1 MiB)
[2025-11-12T22:27:12.721+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.18.0.5:43045 in memory (size: 16.3 KiB, free: 423.7 MiB)
[2025-11-12T22:27:12.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.18.0.5:42325 in memory (size: 16.3 KiB, free: 423.8 MiB)
[2025-11-12T22:27:12.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_102_piece0 on eb021f2c8a8b:40023 in memory (size: 16.3 KiB, free: 423.1 MiB)
[2025-11-12T22:27:12.726+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.18.0.5:43045 in memory (size: 16.3 KiB, free: 423.7 MiB)
[2025-11-12T22:27:12.727+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.18.0.5:42325 in memory (size: 16.3 KiB, free: 423.8 MiB)
[2025-11-12T22:27:12.728+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_99_piece0 on eb021f2c8a8b:40023 in memory (size: 43.1 KiB, free: 423.1 MiB)
[2025-11-12T22:27:12.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.18.0.5:43045 in memory (size: 43.1 KiB, free: 423.7 MiB)
[2025-11-12T22:27:12.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.18.0.5:42325 in memory (size: 43.1 KiB, free: 423.8 MiB)
[2025-11-12T22:27:12.737+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:12 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.18.0.5:42325 (size: 37.8 KiB, free: 423.8 MiB)
[2025-11-12T22:27:18.327+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 107) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:27:18.327+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 106) in 5626 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:27:18.333+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.18.0.5:42325 (size: 47.9 KiB, free: 423.7 MiB)
[2025-11-12T22:27:18.338+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.18.0.5:50960
[2025-11-12T22:27:18.506+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 107) in 180 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:27:18.507+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-11-12T22:27:18.507+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: ShuffleMapStage 100 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 23.435 s
[2025-11-12T22:27:18.508+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:27:18.508+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: running: Set(ShuffleMapStage 98)
[2025-11-12T22:27:18.508+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:27:18.509+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: failed: Set()
[2025-11-12T22:27:18.550+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(32), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:18.551+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(32), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:18.552+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(32), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:18.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(32), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:18.554+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(32), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:18.563+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO CodeGenerator: Code generated in 5.130123 ms
[2025-11-12T22:27:18.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:27:18.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Got job 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:27:18.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Final stage: ResultStage 103 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:27:18.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
[2025-11-12T22:27:18.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:27:18.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[271] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:27:18.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 117.6 KiB, free 420.5 MiB)
[2025-11-12T22:27:18.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 105) in 7028 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:27:18.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool
[2025-11-12T22:27:18.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 43.1 KiB, free 420.4 MiB)
[2025-11-12T22:27:18.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on eb021f2c8a8b:40023 (size: 43.1 KiB, free: 423.1 MiB)
[2025-11-12T22:27:18.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:27:18.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[271] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:27:18.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
[2025-11-12T22:27:18.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 108) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:27:18.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: ShuffleMapStage 98 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 26.244 s
[2025-11-12T22:27:18.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:27:18.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: running: Set(ResultStage 103)
[2025-11-12T22:27:18.590+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:27:18.590+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: failed: Set()
[2025-11-12T22:27:18.596+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.18.0.5:43045 (size: 43.1 KiB, free: 423.7 MiB)
[2025-11-12T22:27:18.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.18.0.5:50962
[2025-11-12T22:27:18.678+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 108) in 90 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:27:18.679+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-11-12T22:27:18.683+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: ResultStage 103 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.097 s
[2025-11-12T22:27:18.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:27:18.685+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
[2025-11-12T22:27:18.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Job 65 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.100724 s
[2025-11-12T22:27:18.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 158.7 KiB, free 420.3 MiB)
[2025-11-12T22:27:18.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on eb021f2c8a8b:40023 (size: 158.7 KiB, free: 422.9 MiB)
[2025-11-12T22:27:18.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO SparkContext: Created broadcast 111 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:27:18.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 49230999, minimum partition size: 1048576
[2025-11-12T22:27:18.736+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 57307945, minimum partition size: 1048576
[2025-11-12T22:27:18.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 49230999, minimum partition size: 1048576
[2025-11-12T22:27:18.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 57307945, minimum partition size: 1048576
[2025-11-12T22:27:18.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(29), advisory target size: 67108864, actual target size 20897623, minimum partition size: 1048576
[2025-11-12T22:27:18.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 22743821, minimum partition size: 1048576
[2025-11-12T22:27:18.744+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(29), advisory target size: 67108864, actual target size 20897623, minimum partition size: 1048576
[2025-11-12T22:27:18.745+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 22743821, minimum partition size: 1048576
[2025-11-12T22:27:18.757+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO CodeGenerator: Code generated in 7.315719 ms
[2025-11-12T22:27:18.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO CodeGenerator: Code generated in 12.823159 ms
[2025-11-12T22:27:18.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO CodeGenerator: Code generated in 8.851285 ms
[2025-11-12T22:27:18.807+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Registering RDD 279 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 33
[2025-11-12T22:27:18.808+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Got map stage job 66 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:27:18.808+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Final stage: ShuffleMapStage 106 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:27:18.808+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104, ShuffleMapStage 105)
[2025-11-12T22:27:18.808+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:27:18.809+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[279] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:27:18.811+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO CodeGenerator: Code generated in 3.580855 ms
[2025-11-12T22:27:18.812+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 309.3 KiB, free 420.0 MiB)
[2025-11-12T22:27:18.813+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 97.9 KiB, free 419.9 MiB)
[2025-11-12T22:27:18.814+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on eb021f2c8a8b:40023 (size: 97.9 KiB, free: 422.8 MiB)
[2025-11-12T22:27:18.814+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:27:18.814+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[279] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:27:18.815+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSchedulerImpl: Adding task set 106.0 with 2 tasks resource profile 0
[2025-11-12T22:27:18.815+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 109) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10247 bytes)
[2025-11-12T22:27:18.815+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSetManager: Starting task 1.0 in stage 106.0 (TID 110) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10247 bytes)
[2025-11-12T22:27:18.822+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.18.0.5:42325 (size: 97.9 KiB, free: 423.6 MiB)
[2025-11-12T22:27:18.823+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.18.0.5:43045 (size: 97.9 KiB, free: 423.6 MiB)
[2025-11-12T22:27:18.826+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO CodeGenerator: Code generated in 10.085139 ms
[2025-11-12T22:27:18.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.18.0.5:50960
[2025-11-12T22:27:18.836+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.18.0.5:50962
[2025-11-12T22:27:18.844+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO CodeGenerator: Code generated in 9.892131 ms
[2025-11-12T22:27:18.855+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Registering RDD 287 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 34
[2025-11-12T22:27:18.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Got map stage job 67 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:27:18.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Final stage: ShuffleMapStage 109 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:27:18.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107, ShuffleMapStage 108)
[2025-11-12T22:27:18.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:27:18.859+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Submitting ShuffleMapStage 109 (MapPartitionsRDD[287] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:27:18.859+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.18.0.5:42325 (size: 158.7 KiB, free: 423.5 MiB)
[2025-11-12T22:27:18.861+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.18.0.5:43045 (size: 158.7 KiB, free: 423.5 MiB)
[2025-11-12T22:27:18.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 258.0 KiB, free 419.6 MiB)
[2025-11-12T22:27:18.863+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 85.6 KiB, free 419.5 MiB)
[2025-11-12T22:27:18.863+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on eb021f2c8a8b:40023 (size: 85.6 KiB, free: 422.8 MiB)
[2025-11-12T22:27:18.863+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:27:18.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 109 (MapPartitionsRDD[287] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:27:18.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:18 INFO TaskSchedulerImpl: Adding task set 109.0 with 2 tasks resource profile 0
[2025-11-12T22:27:20.520+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 111) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10247 bytes)
[2025-11-12T22:27:20.521+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 109) in 1706 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:27:20.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.18.0.5:43045 (size: 85.6 KiB, free: 423.4 MiB)
[2025-11-12T22:27:20.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.18.0.5:50962
[2025-11-12T22:27:20.542+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO TaskSetManager: Starting task 1.0 in stage 109.0 (TID 112) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10247 bytes)
[2025-11-12T22:27:20.543+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO TaskSetManager: Finished task 1.0 in stage 106.0 (TID 110) in 1726 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:27:20.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool
[2025-11-12T22:27:20.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: ShuffleMapStage 106 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 1.734 s
[2025-11-12T22:27:20.548+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:27:20.549+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: running: Set(ShuffleMapStage 109)
[2025-11-12T22:27:20.550+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:27:20.550+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: failed: Set()
[2025-11-12T22:27:20.556+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.18.0.5:42325 (size: 85.6 KiB, free: 423.4 MiB)
[2025-11-12T22:27:20.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.18.0.5:50960
[2025-11-12T22:27:20.590+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1273341, minimum partition size: 1048576
[2025-11-12T22:27:20.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1273341, minimum partition size: 1048576
[2025-11-12T22:27:20.618+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO CodeGenerator: Code generated in 7.497727 ms
[2025-11-12T22:27:20.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO CodeGenerator: Code generated in 8.437867 ms
[2025-11-12T22:27:20.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:27:20.673+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: Got job 68 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-11-12T22:27:20.673+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: Final stage: ResultStage 113 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:27:20.674+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 112)
[2025-11-12T22:27:20.674+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:27:20.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[293] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:27:20.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 281.0 KiB, free 419.3 MiB)
[2025-11-12T22:27:20.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 87.9 KiB, free 419.2 MiB)
[2025-11-12T22:27:20.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on eb021f2c8a8b:40023 (size: 87.9 KiB, free: 422.7 MiB)
[2025-11-12T22:27:20.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:27:20.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 113 (MapPartitionsRDD[293] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:27:20.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:20 INFO TaskSchedulerImpl: Adding task set 113.0 with 2 tasks resource profile 0
[2025-11-12T22:27:21.392+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 113) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:27:21.393+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Finished task 1.0 in stage 109.0 (TID 112) in 851 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:27:21.394+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Starting task 1.0 in stage 113.0 (TID 114) (172.18.0.5, executor 1, partition 1, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:27:21.395+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 111) in 874 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:27:21.395+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool
[2025-11-12T22:27:21.395+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: ShuffleMapStage 109 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 2.538 s
[2025-11-12T22:27:21.396+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:27:21.396+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: running: Set(ResultStage 113)
[2025-11-12T22:27:21.398+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:27:21.398+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: failed: Set()
[2025-11-12T22:27:21.399+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.18.0.5:42325 (size: 87.9 KiB, free: 423.3 MiB)
[2025-11-12T22:27:21.400+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.18.0.5:43045 (size: 87.9 KiB, free: 423.3 MiB)
[2025-11-12T22:27:21.413+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.18.0.5:50962
[2025-11-12T22:27:21.415+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.18.0.5:50960
[2025-11-12T22:27:21.416+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:21.417+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:21.425+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO CodeGenerator: Code generated in 3.349146 ms
[2025-11-12T22:27:21.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO CodeGenerator: Code generated in 3.558055 ms
[2025-11-12T22:27:21.454+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:27:21.455+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Got job 69 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:27:21.456+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Final stage: ResultStage 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:27:21.456+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
[2025-11-12T22:27:21.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:27:21.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[299] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:27:21.463+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 241.0 KiB, free 418.9 MiB)
[2025-11-12T22:27:21.464+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 80.5 KiB, free 418.9 MiB)
[2025-11-12T22:27:21.465+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on eb021f2c8a8b:40023 (size: 80.5 KiB, free: 422.6 MiB)
[2025-11-12T22:27:21.465+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:27:21.465+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[299] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:27:21.466+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0
[2025-11-12T22:27:21.498+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 115) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:27:21.499+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 113) in 106 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:27:21.502+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Finished task 1.0 in stage 113.0 (TID 114) in 109 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:27:21.503+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool
[2025-11-12T22:27:21.504+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: ResultStage 113 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.827 s
[2025-11-12T22:27:21.504+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:27:21.505+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished
[2025-11-12T22:27:21.505+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Job 68 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.831655 s
[2025-11-12T22:27:21.507+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.18.0.5:42325 (size: 80.5 KiB, free: 423.2 MiB)
[2025-11-12T22:27:21.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 1029.2 KiB, free 417.9 MiB)
[2025-11-12T22:27:21.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on eb021f2c8a8b:40023 (size: 1029.2 KiB, free: 421.6 MiB)
[2025-11-12T22:27:21.518+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO SparkContext: Created broadcast 116 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:27:21.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.18.0.5:50960
[2025-11-12T22:27:21.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:21.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO CodeGenerator: Code generated in 18.720161 ms
[2025-11-12T22:27:21.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Registering RDD 303 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 35
[2025-11-12T22:27:21.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Got map stage job 70 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:27:21.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Final stage: ShuffleMapStage 119 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:27:21.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)
[2025-11-12T22:27:21.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:27:21.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[303] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:27:21.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 115) in 99 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:27:21.598+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool
[2025-11-12T22:27:21.598+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 378.5 KiB, free 417.5 MiB)
[2025-11-12T22:27:21.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_114_piece0 on eb021f2c8a8b:40023 in memory (size: 87.9 KiB, free: 421.7 MiB)
[2025-11-12T22:27:21.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.18.0.5:42325 in memory (size: 87.9 KiB, free: 423.3 MiB)
[2025-11-12T22:27:21.609+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.18.0.5:43045 in memory (size: 87.9 KiB, free: 423.4 MiB)
[2025-11-12T22:27:21.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 115.3 KiB, free 417.7 MiB)
[2025-11-12T22:27:21.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on eb021f2c8a8b:40023 (size: 115.3 KiB, free: 421.6 MiB)
[2025-11-12T22:27:21.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:27:21.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[303] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:27:21.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks resource profile 0
[2025-11-12T22:27:21.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: ResultStage 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.149 s
[2025-11-12T22:27:21.613+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:27:21.614+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished
[2025-11-12T22:27:21.614+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Job 69 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.152333 s
[2025-11-12T22:27:21.614+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 116) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10138 bytes)
[2025-11-12T22:27:21.615+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_112_piece0 on eb021f2c8a8b:40023 in memory (size: 97.9 KiB, free: 421.7 MiB)
[2025-11-12T22:27:21.615+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 172.18.0.5:42325 in memory (size: 97.9 KiB, free: 423.4 MiB)
[2025-11-12T22:27:21.615+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 172.18.0.5:43045 in memory (size: 97.9 KiB, free: 423.5 MiB)
[2025-11-12T22:27:21.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 350.1 KiB, free 417.8 MiB)
[2025-11-12T22:27:21.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on eb021f2c8a8b:40023 (size: 350.1 KiB, free: 421.3 MiB)
[2025-11-12T22:27:21.618+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO SparkContext: Created broadcast 118 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:27:21.619+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_110_piece0 on eb021f2c8a8b:40023 in memory (size: 43.1 KiB, free: 421.4 MiB)
[2025-11-12T22:27:21.619+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 172.18.0.5:43045 in memory (size: 43.1 KiB, free: 423.5 MiB)
[2025-11-12T22:27:21.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.18.0.5:43045 (size: 115.3 KiB, free: 423.4 MiB)
[2025-11-12T22:27:21.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_113_piece0 on eb021f2c8a8b:40023 in memory (size: 85.6 KiB, free: 421.4 MiB)
[2025-11-12T22:27:21.623+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.18.0.5:42325 in memory (size: 85.6 KiB, free: 423.5 MiB)
[2025-11-12T22:27:21.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 172.18.0.5:43045 in memory (size: 85.6 KiB, free: 423.5 MiB)
[2025-11-12T22:27:21.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:21.649+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.18.0.5:50962
[2025-11-12T22:27:21.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO CodeGenerator: Code generated in 38.985986 ms
[2025-11-12T22:27:21.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Registering RDD 306 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 36
[2025-11-12T22:27:21.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Got map stage job 71 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:27:21.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Final stage: ShuffleMapStage 121 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:27:21.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)
[2025-11-12T22:27:21.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:27:21.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[306] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:27:21.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.18.0.5:43045 (size: 1029.2 KiB, free: 422.5 MiB)
[2025-11-12T22:27:21.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 349.5 KiB, free 417.9 MiB)
[2025-11-12T22:27:21.712+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 110.6 KiB, free 417.8 MiB)
[2025-11-12T22:27:21.712+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on eb021f2c8a8b:40023 (size: 110.6 KiB, free: 421.3 MiB)
[2025-11-12T22:27:21.713+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:27:21.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[306] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:27:21.715+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks resource profile 0
[2025-11-12T22:27:21.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 117) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10138 bytes)
[2025-11-12T22:27:21.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.18.0.5:42325 (size: 110.6 KiB, free: 423.4 MiB)
[2025-11-12T22:27:21.757+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.18.0.5:50960
[2025-11-12T22:27:21.759+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_108_piece0 on eb021f2c8a8b:40023 in memory (size: 13.5 KiB, free: 421.4 MiB)
[2025-11-12T22:27:21.760+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 172.18.0.5:43045 in memory (size: 13.5 KiB, free: 422.5 MiB)
[2025-11-12T22:27:21.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 172.18.0.5:42325 in memory (size: 13.5 KiB, free: 423.4 MiB)
[2025-11-12T22:27:21.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_109_piece0 on eb021f2c8a8b:40023 in memory (size: 47.9 KiB, free: 421.4 MiB)
[2025-11-12T22:27:21.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 172.18.0.5:42325 in memory (size: 47.9 KiB, free: 423.4 MiB)
[2025-11-12T22:27:21.836+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.18.0.5:42325 (size: 350.1 KiB, free: 423.1 MiB)
[2025-11-12T22:27:21.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 117) in 178 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:27:21.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool
[2025-11-12T22:27:21.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: ShuffleMapStage 121 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 0.193 s
[2025-11-12T22:27:21.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:27:21.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: running: Set(ShuffleMapStage 119)
[2025-11-12T22:27:21.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:27:21.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: failed: Set()
[2025-11-12T22:27:21.904+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO ShufflePartitionsUtil: For shuffle(36), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:21.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO CodeGenerator: Code generated in 3.820955 ms
[2025-11-12T22:27:21.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:27:21.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 116) in 335 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:27:21.943+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool
[2025-11-12T22:27:21.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: ShuffleMapStage 119 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 0.362 s
[2025-11-12T22:27:21.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:27:21.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: running: Set()
[2025-11-12T22:27:21.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:27:21.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO DAGScheduler: failed: Set()
[2025-11-12T22:27:21.983+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:21 INFO CodeGenerator: Code generated in 37.992245 ms
[2025-11-12T22:27:22.042+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:27:22.043+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO DAGScheduler: Got job 72 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:27:22.043+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO DAGScheduler: Final stage: ResultStage 124 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:27:22.043+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 123)
[2025-11-12T22:27:22.044+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:27:22.044+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[312] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:27:22.052+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 471.2 KiB, free 417.6 MiB)
[2025-11-12T22:27:22.053+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 145.2 KiB, free 417.5 MiB)
[2025-11-12T22:27:22.054+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on eb021f2c8a8b:40023 (size: 145.2 KiB, free: 421.3 MiB)
[2025-11-12T22:27:22.054+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:27:22.055+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 124 (MapPartitionsRDD[312] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:27:22.055+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks resource profile 0
[2025-11-12T22:27:22.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 118) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:27:22.062+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.18.0.5:42325 (size: 145.2 KiB, free: 423.0 MiB)
[2025-11-12T22:27:22.483+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.18.0.5:50960
[2025-11-12T22:27:22.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.18.0.5:42325 (size: 569.7 KiB, free: 422.4 MiB)
[2025-11-12T22:27:22.999+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:22 INFO BlockManagerInfo: Added broadcast_75_python on disk on 172.18.0.5:42325 (size: 1071.5 KiB)
[2025-11-12T22:27:23.900+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 118) in 1845 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:27:23.901+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool
[2025-11-12T22:27:23.901+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO DAGScheduler: ResultStage 124 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.858 s
[2025-11-12T22:27:23.902+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:27:23.902+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 124: Stage finished
[2025-11-12T22:27:23.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO DAGScheduler: Job 72 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.860507 s
[2025-11-12T22:27:23.909+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO CodeGenerator: Code generated in 3.640148 ms
[2025-11-12T22:27:23.914+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 780.0 B, free 417.5 MiB)
[2025-11-12T22:27:23.915+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on eb021f2c8a8b:40023 (size: 780.0 B, free: 421.3 MiB)
[2025-11-12T22:27:23.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO SparkContext: Created broadcast 121 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:27:23.932+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO ShufflePartitionsUtil: For shuffle(35), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:23.982+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO CodeGenerator: Code generated in 28.486059 ms
[2025-11-12T22:27:23.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO DAGScheduler: Registering RDD 317 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 37
[2025-11-12T22:27:23.986+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO DAGScheduler: Got map stage job 73 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:27:23.987+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO DAGScheduler: Final stage: ShuffleMapStage 127 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:27:23.987+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 126)
[2025-11-12T22:27:23.987+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:27:23.988+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO DAGScheduler: Submitting ShuffleMapStage 127 (MapPartitionsRDD[317] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:27:23.996+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 486.9 KiB, free 417.0 MiB)
[2025-11-12T22:27:23.997+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 138.4 KiB, free 416.8 MiB)
[2025-11-12T22:27:23.997+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on eb021f2c8a8b:40023 (size: 138.4 KiB, free: 421.1 MiB)
[2025-11-12T22:27:23.998+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:27:23.998+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 127 (MapPartitionsRDD[317] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:27:23.999+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks resource profile 0
[2025-11-12T22:27:24.000+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:23 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 119) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:27:24.005+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.18.0.5:43045 (size: 138.4 KiB, free: 422.3 MiB)
[2025-11-12T22:27:24.023+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.18.0.5:50962
[2025-11-12T22:27:24.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.18.0.5:43045 (size: 780.0 B, free: 422.3 MiB)
[2025-11-12T22:27:24.283+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 119) in 284 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:27:24.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool
[2025-11-12T22:27:24.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: ShuffleMapStage 127 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 0.298 s
[2025-11-12T22:27:24.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:27:24.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: running: Set()
[2025-11-12T22:27:24.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:27:24.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: failed: Set()
[2025-11-12T22:27:24.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:27:24.310+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO SparkContext: Starting job: foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883
[2025-11-12T22:27:24.311+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: Got job 74 (foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883) with 1 output partitions
[2025-11-12T22:27:24.312+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: Final stage: ResultStage 131 (foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883)
[2025-11-12T22:27:24.312+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 130)
[2025-11-12T22:27:24.313+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:27:24.313+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: Submitting ResultStage 131 (PythonRDD[322] at foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883), which has no missing parents
[2025-11-12T22:27:24.313+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 27.4 KiB, free 416.8 MiB)
[2025-11-12T22:27:24.314+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 12.5 KiB, free 416.8 MiB)
[2025-11-12T22:27:24.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on eb021f2c8a8b:40023 (size: 12.5 KiB, free: 421.1 MiB)
[2025-11-12T22:27:24.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:27:24.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (PythonRDD[322] at foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:27:24.316+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks resource profile 0
[2025-11-12T22:27:24.316+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 120) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:27:24.323+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.18.0.5:42325 (size: 12.5 KiB, free: 422.4 MiB)
[2025-11-12T22:27:24.325+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.18.0.5:50960
[2025-11-12T22:27:24.704+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 120) in 388 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:27:24.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool
[2025-11-12T22:27:24.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: ResultStage 131 (foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883) finished in 0.392 s
[2025-11-12T22:27:24.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:27:24.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 131: Stage finished
[2025-11-12T22:27:24.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO DAGScheduler: Job 74 finished: foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883, took 0.394655 s
[2025-11-12T22:27:24.708+0000] {spark_submit.py:571} INFO - Executor-side pymongo: scheduled partitioned updates for basho_pages.id=202511
[2025-11-12T22:27:24.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-11-12T22:27:24.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO SparkUI: Stopped Spark web UI at http://eb021f2c8a8b:4040
[2025-11-12T22:27:24.718+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-11-12T22:27:24.719+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
[2025-11-12T22:27:24.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-11-12T22:27:24.755+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO MemoryStore: MemoryStore cleared
[2025-11-12T22:27:24.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO BlockManager: BlockManager stopped
[2025-11-12T22:27:24.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-11-12T22:27:24.760+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-11-12T22:27:24.807+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:24 INFO SparkContext: Successfully stopped SparkContext
[2025-11-12T22:27:26.159+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:26 INFO ShutdownHookManager: Shutdown hook called
[2025-11-12T22:27:26.160+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-48be39f9-d8f5-4664-835c-5ec646c6eba7/pyspark-f92ad184-8b4a-4ef2-8553-b566397071a2
[2025-11-12T22:27:26.165+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-48be39f9-d8f5-4664-835c-5ec646c6eba7
[2025-11-12T22:27:26.169+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-2493b960-65ff-4241-9e63-d25e20b83311
[2025-11-12T22:27:26.176+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:26 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2025-11-12T22:27:26.176+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:26 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2025-11-12T22:27:26.177+0000] {spark_submit.py:571} INFO - 25/11/12 22:27:26 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2025-11-12T22:27:26.408+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=sumo_data_pipeline, task_id=run_new_matches_mongo, execution_date=20251107T085511, start_date=20251112T222443, end_date=20251112T222726
[2025-11-12T22:27:26.448+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-11-12T22:27:26.470+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
