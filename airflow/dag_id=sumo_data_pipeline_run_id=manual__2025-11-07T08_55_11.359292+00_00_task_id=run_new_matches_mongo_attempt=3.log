eb021f2c8a8b
*** Found local files:
***   * /opt/airflow/logs/dag_id=sumo_data_pipeline/run_id=manual__2025-11-07T08:55:11.359292+00:00/task_id=run_new_matches_mongo/attempt=3.log
[2025-11-12T22:18:13.091+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: sumo_data_pipeline.run_new_matches_mongo manual__2025-11-07T08:55:11.359292+00:00 [queued]>
[2025-11-12T22:18:13.100+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: sumo_data_pipeline.run_new_matches_mongo manual__2025-11-07T08:55:11.359292+00:00 [queued]>
[2025-11-12T22:18:13.100+0000] {taskinstance.py:2170} INFO - Starting attempt 3 of 3
[2025-11-12T22:18:13.110+0000] {taskinstance.py:2191} INFO - Executing <Task(SparkSubmitOperator): run_new_matches_mongo> on 2025-11-07 08:55:11.359292+00:00
[2025-11-12T22:18:13.115+0000] {standard_task_runner.py:60} INFO - Started process 3108 to run task
[2025-11-12T22:18:13.118+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'sumo_data_pipeline', 'run_new_matches_mongo', 'manual__2025-11-07T08:55:11.359292+00:00', '--job-id', '132', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpbgmosleg']
[2025-11-12T22:18:13.121+0000] {standard_task_runner.py:88} INFO - Job 132: Subtask run_new_matches_mongo
[2025-11-12T22:18:13.179+0000] {task_command.py:423} INFO - Running <TaskInstance: sumo_data_pipeline.run_new_matches_mongo manual__2025-11-07T08:55:11.359292+00:00 [running]> on host eb021f2c8a8b
[2025-11-12T22:18:13.351+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='sumo_data_pipeline' AIRFLOW_CTX_TASK_ID='run_new_matches_mongo' AIRFLOW_CTX_EXECUTION_DATE='2025-11-07T08:55:11.359292+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-11-07T08:55:11.359292+00:00'
[2025-11-12T22:18:13.360+0000] {base.py:83} INFO - Using connection ID 'spark_default' for task execution.
[2025-11-12T22:18:13.364+0000] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master spark://spark-master:7077 --conf spark.pyspark.python=python3 --conf spark.executorEnv.PYSPARK_PYTHON=python3 --conf spark.pyspark.driver.python=python3 --conf spark.executorEnv.MONGO_URI=mongodb+srv://sumo-***:ILoveFumi%21@sumo.jrywipx.mongodb.net/sumo --conf spark.executorEnv.MONGO_DB_NAME=sumo --conf spark.executorEnv.MONGO_COLL_NAME=homepage --conf spark.driverEnv.MONGO_URI=mongodb+srv://sumo-***:ILoveFumi%21@sumo.jrywipx.mongodb.net/sumo --conf spark.driverEnv.MONGO_DB_NAME=sumo --conf spark.driverEnv.MONGO_COLL_NAME=homepage --conf spark.executor.instances=1 --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.DefaultAWSCredentialsProviderChain --conf spark.executorEnv.AWS_REGION=us-west-2 --conf spark.executorEnv.AWS_ACCESS_KEY_ID=AKIAQXPZDDBLZGNPBDZR --conf spark.executorEnv.AWS_SECRET_ACCESS_KEY=****** --jars /opt/spark/jars/hadoop-aws-3.3.4.jar,/opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 --executor-cores 1 --executor-memory 1g --driver-memory 1g --name arrow-spark /opt/airflow/jobs/spark_mongoNewMatches.py "{\"payload\": [{\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 39, \"eastRank\": \"Maegashira 17 East\", \"eastShikona\": \"Chiyoshoma\", \"id\": \"202511-2-0-39-82\", \"kimarite\": \"\", \"matchNo\": 1, \"westId\": 82, \"westRank\": \"Juryo 1 West\", \"westShikona\": \"Fujiseiun\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 95, \"eastRank\": \"Maegashira 16 East\", \"eastShikona\": \"Oshoumi\", \"id\": \"202511-2-1-95-164\", \"kimarite\": \"\", \"matchNo\": 2, \"westId\": 164, \"westRank\": \"Maegashira 17 West\", \"westShikona\": \"Asakoryu\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 35, \"eastRank\": \"Maegashira 16 West\", \"eastShikona\": \"Sadanoumi\", \"id\": \"202511-2-2-35-49\", \"kimarite\": \"\", \"matchNo\": 3, \"westId\": 49, \"westRank\": \"Maegashira 15 West\", \"westShikona\": \"Shonannoumi\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 15, \"eastRank\": \"Maegashira 14 East\", \"eastShikona\": \"Ryuden\", \"id\": \"202511-2-3-15-40\", \"kimarite\": \"\", \"matchNo\": 4, \"westId\": 40, \"westRank\": \"Maegashira 15 East\", \"westShikona\": \"Nishikifuji\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 83, \"eastRank\": \"Maegashira 14 West\", \"eastShikona\": \"Tokihayate\", \"id\": \"202511-2-4-83-26\", \"kimarite\": \"\", \"matchNo\": 5, \"westId\": 26, \"westRank\": \"Maegashira 13 West\", \"westShikona\": \"Mitakeumi\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 615, \"eastRank\": \"Maegashira 12 East\", \"eastShikona\": \"Fujinokawa\", \"id\": \"202511-2-5-615-56\", \"kimarite\": \"\", \"matchNo\": 6, \"westId\": 56, \"westRank\": \"Maegashira 13 East\", \"westShikona\": \"Gonoyama\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 102, \"eastRank\": \"Maegashira 12 West\", \"eastShikona\": \"Tomokaze\", \"id\": \"202511-2-6-102-55\", \"kimarite\": \"\", \"matchNo\": 7, \"westId\": 55, \"westRank\": \"Maegashira 11 West\", \"westShikona\": \"Roga\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 9, \"eastRank\": \"Maegashira 10 East\", \"eastShikona\": \"Daieisho\", \"id\": \"202511-2-7-9-8\", \"kimarite\": \"\", \"matchNo\": 8, \"westId\": 8, \"westRank\": \"Maegashira 10 West\", \"westShikona\": \"Kotoshoho\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 86, \"eastRank\": \"Maegashira 11 East\", \"eastShikona\": \"Shishi\", \"id\": \"202511-2-8-86-21\", \"kimarite\": \"\", \"matchNo\": 9, \"westId\": 21, \"westRank\": \"Maegashira 9 West\", \"westShikona\": \"Tobizaru\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 11, \"eastRank\": \"Maegashira 8 East\", \"eastShikona\": \"Ichiyamamoto\", \"id\": \"202511-2-9-11-34\", \"kimarite\": \"\", \"matchNo\": 10, \"westId\": 34, \"westRank\": \"Maegashira 9 East\", \"westShikona\": \"Midorifuji\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 50, \"eastRank\": \"Maegashira 8 West\", \"eastShikona\": \"Kinbozan\", \"id\": \"202511-2-10-50-22\", \"kimarite\": \"\", \"matchNo\": 11, \"westId\": 22, \"westRank\": \"Maegashira 7 West\", \"westShikona\": \"Abi\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 74, \"eastRank\": \"Maegashira 6 East\", \"eastShikona\": \"Atamifuji\", \"id\": \"202511-2-11-74-71\", \"kimarite\": \"\", \"matchNo\": 12, \"westId\": 71, \"westRank\": \"Maegashira 7 East\", \"westShikona\": \"Churanoumi\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 8853, \"eastRank\": \"Maegashira 6 West\", \"eastShikona\": \"Onokatsu\", \"id\": \"202511-2-12-8853-33\", \"kimarite\": \"\", \"matchNo\": 13, \"westId\": 33, \"westRank\": \"Maegashira 5 West\", \"westShikona\": \"Shodai\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 14, \"eastRank\": \"Maegashira 4 East\", \"eastShikona\": \"Tamawashi\", \"id\": \"202511-2-13-14-8857\", \"kimarite\": \"\", \"matchNo\": 14, \"westId\": 8857, \"westRank\": \"Maegashira 5 East\", \"westShikona\": \"Yoshinofuji\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 61, \"eastRank\": \"Maegashira 4 West\", \"eastShikona\": \"Oshoma\", \"id\": \"202511-2-14-61-28\", \"kimarite\": \"\", \"matchNo\": 15, \"westId\": 28, \"westRank\": \"Maegashira 3 West\", \"westShikona\": \"Ura\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 24, \"eastRank\": \"Maegashira 3 East\", \"eastShikona\": \"Hiradoumi\", \"id\": \"202511-2-15-24-44\", \"kimarite\": \"\", \"matchNo\": 16, \"westId\": 44, \"westRank\": \"Komusubi 1 West\", \"westShikona\": \"Takayasu\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 8854, \"eastRank\": \"Sekiwake 1 East\", \"eastShikona\": \"Aonishiki\", \"id\": \"202511-2-16-8854-13\", \"kimarite\": \"\", \"matchNo\": 17, \"westId\": 13, \"westRank\": \"Maegashira 2 West\", \"westShikona\": \"Wakamotoharu\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 12, \"eastRank\": \"Maegashira 1 West\", \"eastShikona\": \"Wakatakakage\", \"id\": \"202511-2-17-12-41\", \"kimarite\": \"\", \"matchNo\": 18, \"westId\": 41, \"westRank\": \"Sekiwake 1 West\", \"westShikona\": \"Oho\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 20, \"eastRank\": \"Ozeki 1 East\", \"eastShikona\": \"Kotozakura\", \"id\": \"202511-2-18-20-7\", \"kimarite\": \"\", \"matchNo\": 19, \"westId\": 7, \"westRank\": \"Maegashira 2 East\", \"westShikona\": \"Kirishima\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 8850, \"eastRank\": \"Yokozuna 1 East\", \"eastShikona\": \"Onosato\", \"id\": \"202511-2-19-8850-3\", \"kimarite\": \"\", \"matchNo\": 20, \"westId\": 3, \"westRank\": \"Maegashira 1 East\", \"westShikona\": \"Hakuoho\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}, {\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 37, \"eastRank\": \"Komusubi 1 East\", \"eastShikona\": \"Takanosho\", \"id\": \"202511-2-20-37-19\", \"kimarite\": \"\", \"matchNo\": 21, \"westId\": 19, \"westRank\": \"Yokozuna 1 West\", \"westShikona\": \"Hoshoryu\", \"winnerEn\": \"\", \"winnerId\": 0, \"winnerJp\": \"\"}], \"type\": \"newMatches\"}"
[2025-11-12T22:18:15.098+0000] {spark_submit.py:571} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-11-12T22:18:15.170+0000] {spark_submit.py:571} INFO - Ivy Default Cache set to: /home/airflow/.ivy2/cache
[2025-11-12T22:18:15.171+0000] {spark_submit.py:571} INFO - The jars for the packages stored in: /home/airflow/.ivy2/jars
[2025-11-12T22:18:15.173+0000] {spark_submit.py:571} INFO - org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency
[2025-11-12T22:18:15.174+0000] {spark_submit.py:571} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-f48de45b-5667-4d8e-8ad0-961ce73753e3;1.0
[2025-11-12T22:18:15.174+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-11-12T22:18:15.276+0000] {spark_submit.py:571} INFO - found org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central
[2025-11-12T22:18:15.296+0000] {spark_submit.py:571} INFO - found org.mongodb#mongodb-driver-sync;4.0.5 in central
[2025-11-12T22:18:15.311+0000] {spark_submit.py:571} INFO - found org.mongodb#bson;4.0.5 in central
[2025-11-12T22:18:15.327+0000] {spark_submit.py:571} INFO - found org.mongodb#mongodb-driver-core;4.0.5 in central
[2025-11-12T22:18:15.346+0000] {spark_submit.py:571} INFO - :: resolution report :: resolve 166ms :: artifacts dl 6ms
[2025-11-12T22:18:15.347+0000] {spark_submit.py:571} INFO - :: modules in use:
[2025-11-12T22:18:15.347+0000] {spark_submit.py:571} INFO - org.mongodb#bson;4.0.5 from central in [default]
[2025-11-12T22:18:15.348+0000] {spark_submit.py:571} INFO - org.mongodb#mongodb-driver-core;4.0.5 from central in [default]
[2025-11-12T22:18:15.348+0000] {spark_submit.py:571} INFO - org.mongodb#mongodb-driver-sync;4.0.5 from central in [default]
[2025-11-12T22:18:15.348+0000] {spark_submit.py:571} INFO - org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]
[2025-11-12T22:18:15.349+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-11-12T22:18:15.349+0000] {spark_submit.py:571} INFO - |                  |            modules            ||   artifacts   |
[2025-11-12T22:18:15.349+0000] {spark_submit.py:571} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-11-12T22:18:15.350+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-11-12T22:18:15.350+0000] {spark_submit.py:571} INFO - |      default     |   4   |   0   |   0   |   0   ||   4   |   0   |
[2025-11-12T22:18:15.350+0000] {spark_submit.py:571} INFO - ---------------------------------------------------------------------
[2025-11-12T22:18:15.351+0000] {spark_submit.py:571} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-f48de45b-5667-4d8e-8ad0-961ce73753e3
[2025-11-12T22:18:15.352+0000] {spark_submit.py:571} INFO - confs: [default]
[2025-11-12T22:18:15.356+0000] {spark_submit.py:571} INFO - 0 artifacts copied, 4 already retrieved (0kB/5ms)
[2025-11-12T22:18:15.547+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-11-12T22:18:16.389+0000] {spark_submit.py:571} INFO - [spark_mongoNewMatches] raw arg: "{\"payload\": [{\"bashoId\": \"202511\", \"day\": 2, \"division\": \"Makuuchi\", \"eastId\": 39, \"eastRank\": \"Maegashira 17 East\", \"eastShikona\": \"Chiyoshoma\", \"id\": \"202511-2-0-39-82\", \"kimarite\": \"\", \"matchNo\": 1, \"westId\": 82, \"westRank\": \"Juryo 1 West\", \"westShikona\":  ...
[2025-11-12T22:18:16.460+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SparkContext: Running Spark version 3.5.2
[2025-11-12T22:18:16.461+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
[2025-11-12T22:18:16.461+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SparkContext: Java version 17.0.17
[2025-11-12T22:18:16.478+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO ResourceUtils: ==============================================================
[2025-11-12T22:18:16.479+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-11-12T22:18:16.479+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO ResourceUtils: ==============================================================
[2025-11-12T22:18:16.479+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SparkContext: Submitted application: spark_mongoNewMatches
[2025-11-12T22:18:16.497+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-11-12T22:18:16.503+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2025-11-12T22:18:16.505+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-11-12T22:18:16.557+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SecurityManager: Changing view acls to: airflow
[2025-11-12T22:18:16.558+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SecurityManager: Changing modify acls to: airflow
[2025-11-12T22:18:16.559+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SecurityManager: Changing view acls groups to:
[2025-11-12T22:18:16.559+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SecurityManager: Changing modify acls groups to:
[2025-11-12T22:18:16.559+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: airflow; groups with view permissions: EMPTY; users with modify permissions: airflow; groups with modify permissions: EMPTY
[2025-11-12T22:18:16.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO Utils: Successfully started service 'sparkDriver' on port 37757.
[2025-11-12T22:18:16.766+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SparkEnv: Registering MapOutputTracker
[2025-11-12T22:18:16.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SparkEnv: Registering BlockManagerMaster
[2025-11-12T22:18:16.817+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-11-12T22:18:16.818+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-11-12T22:18:16.820+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-11-12T22:18:16.841+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1656abdb-a143-4a69-b35c-3e83a0b12204
[2025-11-12T22:18:16.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-11-12T22:18:16.863+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-11-12T22:18:16.959+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-11-12T22:18:17.002+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-11-12T22:18:17.029+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO SparkContext: Added JAR file:///opt/spark/jars/hadoop-aws-3.3.4.jar at spark://eb021f2c8a8b:37757/jars/hadoop-aws-3.3.4.jar with timestamp 1762985896455
[2025-11-12T22:18:17.030+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO SparkContext: Added JAR file:///opt/spark/jars/aws-java-sdk-bundle-1.12.262.jar at spark://eb021f2c8a8b:37757/jars/aws-java-sdk-bundle-1.12.262.jar with timestamp 1762985896455
[2025-11-12T22:18:17.030+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar at spark://eb021f2c8a8b:37757/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1762985896455
[2025-11-12T22:18:17.031+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar at spark://eb021f2c8a8b:37757/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1762985896455
[2025-11-12T22:18:17.031+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.mongodb_bson-4.0.5.jar at spark://eb021f2c8a8b:37757/jars/org.mongodb_bson-4.0.5.jar with timestamp 1762985896455
[2025-11-12T22:18:17.031+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO SparkContext: Added JAR file:///home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar at spark://eb021f2c8a8b:37757/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1762985896455
[2025-11-12T22:18:17.033+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar at spark://eb021f2c8a8b:37757/files/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1762985896455
[2025-11-12T22:18:17.034+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO Utils: Copying /home/airflow/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar to /tmp/spark-4e867b47-00f6-4c3b-b4d3-328d9247193b/userFiles-6ac30907-4e1c-41c6-9fe8-0b385d18804b/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar
[2025-11-12T22:18:17.048+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar at spark://eb021f2c8a8b:37757/files/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1762985896455
[2025-11-12T22:18:17.049+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO Utils: Copying /home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar to /tmp/spark-4e867b47-00f6-4c3b-b4d3-328d9247193b/userFiles-6ac30907-4e1c-41c6-9fe8-0b385d18804b/org.mongodb_mongodb-driver-sync-4.0.5.jar
[2025-11-12T22:18:17.054+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.mongodb_bson-4.0.5.jar at spark://eb021f2c8a8b:37757/files/org.mongodb_bson-4.0.5.jar with timestamp 1762985896455
[2025-11-12T22:18:17.055+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO Utils: Copying /home/airflow/.ivy2/jars/org.mongodb_bson-4.0.5.jar to /tmp/spark-4e867b47-00f6-4c3b-b4d3-328d9247193b/userFiles-6ac30907-4e1c-41c6-9fe8-0b385d18804b/org.mongodb_bson-4.0.5.jar
[2025-11-12T22:18:17.062+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO SparkContext: Added file file:///home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar at spark://eb021f2c8a8b:37757/files/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1762985896455
[2025-11-12T22:18:17.062+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO Utils: Copying /home/airflow/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar to /tmp/spark-4e867b47-00f6-4c3b-b4d3-328d9247193b/userFiles-6ac30907-4e1c-41c6-9fe8-0b385d18804b/org.mongodb_mongodb-driver-core-4.0.5.jar
[2025-11-12T22:18:17.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
[2025-11-12T22:18:17.167+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.3:7077 after 19 ms (0 ms spent in bootstraps)
[2025-11-12T22:18:17.238+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20251112221817-0007
[2025-11-12T22:18:17.241+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251112221817-0007/0 on worker-20251112212940-172.18.0.5-43185 (172.18.0.5:43185) with 1 core(s)
[2025-11-12T22:18:17.242+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20251112221817-0007/0 on hostPort 172.18.0.5:43185 with 1 core(s), 1024.0 MiB RAM
[2025-11-12T22:18:17.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20251112221817-0007/1 on worker-20251112212940-172.18.0.5-43185 (172.18.0.5:43185) with 1 core(s)
[2025-11-12T22:18:17.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20251112221817-0007/1 on hostPort 172.18.0.5:43185 with 1 core(s), 1024.0 MiB RAM
[2025-11-12T22:18:17.247+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35921.
[2025-11-12T22:18:17.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO NettyBlockTransferService: Server created on eb021f2c8a8b:35921
[2025-11-12T22:18:17.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-11-12T22:18:17.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, eb021f2c8a8b, 35921, None)
[2025-11-12T22:18:17.266+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO BlockManagerMasterEndpoint: Registering block manager eb021f2c8a8b:35921 with 434.4 MiB RAM, BlockManagerId(driver, eb021f2c8a8b, 35921, None)
[2025-11-12T22:18:17.268+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, eb021f2c8a8b, 35921, None)
[2025-11-12T22:18:17.270+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, eb021f2c8a8b, 35921, None)
[2025-11-12T22:18:17.277+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251112221817-0007/1 is now RUNNING
[2025-11-12T22:18:17.278+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20251112221817-0007/0 is now RUNNING
[2025-11-12T22:18:17.445+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:17 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2025-11-12T22:18:18.134+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:18 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-11-12T22:18:18.137+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:18 INFO SharedState: Warehouse path is 'file:/opt/airflow/spark-warehouse'.
[2025-11-12T22:18:19.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:19 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:34294) with ID 0,  ResourceProfileId 0
[2025-11-12T22:18:19.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:19 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.5:34292) with ID 1,  ResourceProfileId 0
[2025-11-12T22:18:19.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:19 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:40603 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.5, 40603, None)
[2025-11-12T22:18:19.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:19 INFO BlockManagerMasterEndpoint: Registering block manager 172.18.0.5:45133 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.5, 45133, None)
[2025-11-12T22:18:21.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO CodeGenerator: Code generated in 206.917267 ms
[2025-11-12T22:18:21.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO DAGScheduler: Registering RDD 6 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-11-12T22:18:21.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:18:21.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:18:21.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:21.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:21.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:18:21.398+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 16.7 KiB, free 434.4 MiB)
[2025-11-12T22:18:21.429+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.4 MiB)
[2025-11-12T22:18:21.431+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on eb021f2c8a8b:35921 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:21.433+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:21.446+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:18:21.447+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
[2025-11-12T22:18:21.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 11355 bytes)
[2025-11-12T22:18:21.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11479 bytes)
[2025-11-12T22:18:21.881+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:45133 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:21.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.18.0.5:40603 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1416 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:18:23.057+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1392 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:18:23.057+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-11-12T22:18:23.061+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 52191
[2025-11-12T22:18:23.065+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 1.954 s
[2025-11-12T22:18:23.065+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:18:23.065+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: running: Set()
[2025-11-12T22:18:23.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:18:23.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: failed: Set()
[2025-11-12T22:18:23.094+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO CodeGenerator: Code generated in 9.198798 ms
[2025-11-12T22:18:23.111+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-12T22:18:23.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:18:23.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:18:23.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2025-11-12T22:18:23.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:23.115+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[9] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:18:23.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.5 KiB, free 434.4 MiB)
[2025-11-12T22:18:23.128+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.4 MiB)
[2025-11-12T22:18:23.129+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on eb021f2c8a8b:35921 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.129+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:23.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:23.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-11-12T22:18:23.135+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:18:23.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.18.0.5:45133 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.198+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 172.18.0.5:34294
[2025-11-12T22:18:23.220+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on eb021f2c8a8b:35921 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.5:45133 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.18.0.5:40603 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 167 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:18:23.301+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-11-12T22:18:23.302+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.181 s
[2025-11-12T22:18:23.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:23.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-11-12T22:18:23.304+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.194588 s
[2025-11-12T22:18:23.311+0000] {spark_submit.py:571} INFO - Loaded 21 matches from webhook payload.
[2025-11-12T22:18:23.422+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO CodeGenerator: Code generated in 10.639961 ms
[2025-11-12T22:18:23.428+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO SparkContext: Starting job: collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102
[2025-11-12T22:18:23.429+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Got job 2 (collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102) with 1 output partitions
[2025-11-12T22:18:23.429+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Final stage: ResultStage 3 (collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102)
[2025-11-12T22:18:23.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:23.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:23.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102), which has no missing parents
[2025-11-12T22:18:23.433+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.5 KiB, free 434.4 MiB)
[2025-11-12T22:18:23.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 434.4 MiB)
[2025-11-12T22:18:23.437+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on eb021f2c8a8b:35921 (size: 7.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.438+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:23.438+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:23.439+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-11-12T22:18:23.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 11366 bytes)
[2025-11-12T22:18:23.461+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.18.0.5:40603 (size: 7.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.552+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 110 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:18:23.552+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-11-12T22:18:23.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: ResultStage 3 (collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102) finished in 0.121 s
[2025-11-12T22:18:23.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:23.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-11-12T22:18:23.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO DAGScheduler: Job 2 finished: collect at /opt/airflow/jobs/spark_mongoNewMatches.py:102, took 0.125004 s
[2025-11-12T22:18:23.570+0000] {spark_submit.py:571} INFO - passing basho id for join: 202511
[2025-11-12T22:18:23.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Removed broadcast_2_piece0 on eb021f2c8a8b:35921 in memory (size: 7.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.18.0.5:40603 in memory (size: 7.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.608+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on eb021f2c8a8b:35921 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.18.0.5:45133 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-12T22:18:23.762+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 264.0 B, free 434.4 MiB)
[2025-11-12T22:18:23.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 467.0 B, free 434.4 MiB)
[2025-11-12T22:18:23.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on eb021f2c8a8b:35921 (size: 467.0 B, free: 434.4 MiB)
[2025-11-12T22:18:23.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO SparkContext: Created broadcast 3 from broadcast at MongoSpark.scala:530
[2025-11-12T22:18:23.805+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO cluster: Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=sumo.jrywipx.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='atlas-efvaxv-shard-0'}
[2025-11-12T22:18:23.812+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO MongoClientCache: Creating MongoClient: []
[2025-11-12T22:18:23.816+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO cluster: Cluster description not yet available. Waiting for 30000 ms before timing out
[2025-11-12T22:18:23.837+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:18:23.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:18:23.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:18:23.855+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:23 INFO cluster: No server chosen by com.mongodb.client.internal.MongoClientDelegate$1@7c959db7 from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 30000 ms before timing out
[2025-11-12T22:18:24.493+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO connection: Opened connection [connectionId{localValue:1, serverValue:108189}] to ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017
[2025-11-12T22:18:24.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO connection: Opened connection [connectionId{localValue:3, serverValue:98739}] to ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017
[2025-11-12T22:18:24.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO connection: Opened connection [connectionId{localValue:2, serverValue:101720}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:18:24.545+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=49977566, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:18:24 UTC 2025, lastUpdateTimeNanos=6825950774224}
[2025-11-12T22:18:24.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=49823659, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az3'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff0000000000000045, setVersion=7, lastWriteDate=Wed Nov 12 22:18:24 UTC 2025, lastUpdateTimeNanos=6825950789125}
[2025-11-12T22:18:24.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=49771857, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az1'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:18:24 UTC 2025, lastUpdateTimeNanos=6825950774224}
[2025-11-12T22:18:24.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO cluster: Setting max election id to 7fffffff0000000000000045 from replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:18:24.547+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO cluster: Setting max set version to 7 from replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:18:24.547+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO cluster: Discovered replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:18:24.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO connection: Opened connection [connectionId{localValue:4, serverValue:101720}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:18:24.951+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO SparkContext: Starting job: treeAggregate at MongoInferSchema.scala:88
[2025-11-12T22:18:24.952+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO DAGScheduler: Got job 3 (treeAggregate at MongoInferSchema.scala:88) with 1 output partitions
[2025-11-12T22:18:24.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO DAGScheduler: Final stage: ResultStage 4 (treeAggregate at MongoInferSchema.scala:88)
[2025-11-12T22:18:24.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:24.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:24.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at treeAggregate at MongoInferSchema.scala:88), which has no missing parents
[2025-11-12T22:18:24.956+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.2 KiB, free 434.4 MiB)
[2025-11-12T22:18:24.962+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.4 MiB)
[2025-11-12T22:18:24.963+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on eb021f2c8a8b:35921 (size: 4.2 KiB, free: 434.4 MiB)
[2025-11-12T22:18:24.963+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:24.964+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at treeAggregate at MongoInferSchema.scala:88) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:24.964+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-11-12T22:18:24.967+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.18.0.5, executor 0, partition 0, ANY, 10290 bytes)
[2025-11-12T22:18:24.996+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.18.0.5:45133 (size: 4.2 KiB, free: 434.4 MiB)
[2025-11-12T22:18:25.037+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:25 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:45133 (size: 467.0 B, free: 434.4 MiB)
[2025-11-12T22:18:26.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 1146 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:18:26.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-11-12T22:18:26.115+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO DAGScheduler: ResultStage 4 (treeAggregate at MongoInferSchema.scala:88) finished in 1.159 s
[2025-11-12T22:18:26.116+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:26.116+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2025-11-12T22:18:26.153+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO DAGScheduler: Job 3 finished: treeAggregate at MongoInferSchema.scala:88, took 1.201279 s
[2025-11-12T22:18:26.182+0000] {spark_submit.py:571} INFO - successfully loaded basho_pages for join
[2025-11-12T22:18:26.249+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO MongoRelation: requiredColumns: _id, basho, days, id, filters:
[2025-11-12T22:18:26.451+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO CodeGenerator: Code generated in 89.107559 ms
[2025-11-12T22:18:26.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:18:26.693+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:18:26.693+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:18:26.694+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:26.695+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:26.695+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:18:26.697+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 82.0 KiB, free 434.3 MiB)
[2025-11-12T22:18:26.704+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 434.3 MiB)
[2025-11-12T22:18:26.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO BlockManagerInfo: Removed broadcast_4_piece0 on eb021f2c8a8b:35921 in memory (size: 4.2 KiB, free: 434.4 MiB)
[2025-11-12T22:18:26.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on eb021f2c8a8b:35921 (size: 22.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:26.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:26.707+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:26.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-11-12T22:18:26.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.18.0.5:45133 in memory (size: 4.2 KiB, free: 434.4 MiB)
[2025-11-12T22:18:26.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.18.0.5, executor 1, partition 0, ANY, 10290 bytes)
[2025-11-12T22:18:26.743+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.18.0.5:40603 (size: 22.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:26.875+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.18.0.5:40603 (size: 467.0 B, free: 434.4 MiB)
[2025-11-12T22:18:28.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:28 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 2229 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:18:28.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:28 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-11-12T22:18:28.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:28 INFO DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0) finished in 2.244 s
[2025-11-12T22:18:28.940+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:28 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:28.940+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-11-12T22:18:28.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:28 INFO DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 2.247208 s
[2025-11-12T22:18:29.591+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO CodeGenerator: Code generated in 10.094638 ms
[2025-11-12T22:18:29.596+0000] {spark_submit.py:571} INFO - +--------------------+--------------------+--------------------+------+
[2025-11-12T22:18:29.596+0000] {spark_submit.py:571} INFO - |                 _id|               basho|                days|    id|
[2025-11-12T22:18:29.597+0000] {spark_submit.py:571} INFO - +--------------------+--------------------+--------------------+------+
[2025-11-12T22:18:29.597+0000] {spark_submit.py:571} INFO - |{6915033f5e86fd38...|{202511, Basho 20...|{{{{[{202511, 2, ...|202511|
[2025-11-12T22:18:29.597+0000] {spark_submit.py:571} INFO - +--------------------+--------------------+--------------------+------+
[2025-11-12T22:18:29.598+0000] {spark_submit.py:571} INFO - 
[2025-11-12T22:18:29.598+0000] {spark_submit.py:571} INFO - None
[2025-11-12T22:18:29.600+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO MongoRelation: requiredColumns: _id, basho, days, id, filters:
[2025-11-12T22:18:29.638+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO CodeGenerator: Code generated in 16.914932 ms
[2025-11-12T22:18:29.859+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO BlockManagerInfo: Removed broadcast_5_piece0 on eb021f2c8a8b:35921 in memory (size: 22.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:29.860+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181
[2025-11-12T22:18:29.861+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.18.0.5:40603 in memory (size: 22.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:29.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO DAGScheduler: Got job 5 (runJob at PythonRDD.scala:181) with 1 output partitions
[2025-11-12T22:18:29.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO DAGScheduler: Final stage: ResultStage 6 (runJob at PythonRDD.scala:181)
[2025-11-12T22:18:29.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:29.863+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:29.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO DAGScheduler: Submitting ResultStage 6 (PythonRDD[29] at RDD at PythonRDD.scala:53), which has no missing parents
[2025-11-12T22:18:29.866+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 81.3 KiB, free 434.3 MiB)
[2025-11-12T22:18:29.874+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 24.1 KiB, free 434.3 MiB)
[2025-11-12T22:18:29.874+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on eb021f2c8a8b:35921 (size: 24.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:29.875+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:29.876+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (PythonRDD[29] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:29.876+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-11-12T22:18:29.877+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (172.18.0.5, executor 1, partition 0, ANY, 10290 bytes)
[2025-11-12T22:18:29.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.18.0.5:40603 (size: 24.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:30.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 246 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:18:30.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:30 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-11-12T22:18:30.129+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:30 INFO DAGScheduler: ResultStage 6 (runJob at PythonRDD.scala:181) finished in 0.260 s
[2025-11-12T22:18:30.130+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:30 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:30.130+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
[2025-11-12T22:18:30.130+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:30 INFO DAGScheduler: Job 5 finished: runJob at PythonRDD.scala:181, took 0.264064 s
[2025-11-12T22:18:31.035+0000] {spark_submit.py:571} INFO - Reading cleaned snapshots from s3a://ryans-sumo-bucket/gold/cleaned_data/
[2025-11-12T22:18:31.125+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:31 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2025-11-12T22:18:31.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:31 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
[2025-11-12T22:18:31.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:31 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2025-11-12T22:18:31.341+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on eb021f2c8a8b:35921 in memory (size: 24.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:31.343+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.18.0.5:40603 in memory (size: 24.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:32.349+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO InMemoryFileIndex: It took 88 ms to list leaf files for 1 paths.
[2025-11-12T22:18:32.398+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2025-11-12T22:18:32.399+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO DAGScheduler: Got job 6 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:18:32.400+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO DAGScheduler: Final stage: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:18:32.400+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:32.401+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:32.401+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[31] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:18:32.406+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 108.5 KiB, free 434.3 MiB)
[2025-11-12T22:18:32.411+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 39.7 KiB, free 434.3 MiB)
[2025-11-12T22:18:32.412+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on eb021f2c8a8b:35921 (size: 39.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:32.413+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:32.414+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[31] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:32.414+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
[2025-11-12T22:18:32.415+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10300 bytes)
[2025-11-12T22:18:32.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.18.0.5:40603 (size: 39.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:33.822+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:33 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 1407 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:18:33.823+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:33 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-11-12T22:18:33.823+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:33 INFO DAGScheduler: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.422 s
[2025-11-12T22:18:33.824+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:33 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:33.824+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
[2025-11-12T22:18:33.824+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:33 INFO DAGScheduler: Job 6 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.424631 s
[2025-11-12T22:18:33.837+0000] {spark_submit.py:571} INFO - Preview of cleaned_data (main_all):
[2025-11-12T22:18:33.898+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:33 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:33.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:33 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:33.913+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:33 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2025-11-12T22:18:34.019+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO CodeGenerator: Code generated in 57.18348 ms
[2025-11-12T22:18:34.037+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 230.1 KiB, free 434.0 MiB)
[2025-11-12T22:18:34.045+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 38.7 KiB, free 434.0 MiB)
[2025-11-12T22:18:34.046+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on eb021f2c8a8b:35921 (size: 38.7 KiB, free: 434.3 MiB)
[2025-11-12T22:18:34.047+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO SparkContext: Created broadcast 8 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:18:34.057+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:18:34.079+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:18:34.080+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:18:34.081+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO DAGScheduler: Final stage: ResultStage 8 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:18:34.081+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:34.081+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:34.085+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:18:34.087+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO BlockManagerInfo: Removed broadcast_7_piece0 on eb021f2c8a8b:35921 in memory (size: 39.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:34.090+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.18.0.5:40603 in memory (size: 39.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:34.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 61.5 KiB, free 434.1 MiB)
[2025-11-12T22:18:34.099+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 434.1 MiB)
[2025-11-12T22:18:34.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on eb021f2c8a8b:35921 (size: 14.1 KiB, free: 434.3 MiB)
[2025-11-12T22:18:34.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:34.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:34.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-11-12T22:18:34.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10805 bytes)
[2025-11-12T22:18:34.128+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.18.0.5:45133 (size: 14.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:34.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.18.0.5:45133 (size: 38.7 KiB, free: 434.3 MiB)
[2025-11-12T22:18:34.854+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO MongoClientCache: Closing MongoClient: [ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017,ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017,ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017]
[2025-11-12T22:18:34.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:34 INFO connection: Closed connection [connectionId{localValue:4, serverValue:101720}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017 because the pool has been closed.
[2025-11-12T22:18:37.977+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:37 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 3874 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:18:37.978+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:37 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-11-12T22:18:37.979+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:37 INFO DAGScheduler: ResultStage 8 (showString at NativeMethodAccessorImpl.java:0) finished in 3.890 s
[2025-11-12T22:18:37.980+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:37 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:37.980+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-11-12T22:18:37.980+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:37 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 3.898958 s
[2025-11-12T22:18:38.012+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO CodeGenerator: Code generated in 21.66254 ms
[2025-11-12T22:18:38.090+0000] {spark_submit.py:571} INFO - +---+---------+------+-----------------+------------+-----------+-------+------+-----------------+-----------+-----------+--------+--------+----------+-------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+-----------------+--------------+----------+-----------------+--------------+----------+---------------------+---------------------+----------+--------+--------+----------------+----------------+-----------------+-----------------+-----------------+-----------------+
[2025-11-12T22:18:38.090+0000] {spark_submit.py:571} INFO - |day|division |eastId|eastRank         |eastShikona |kimarite   |matchNo|westId|westRank         |westShikona|winnerEn   |winnerId|winnerJp|match_id  |westWin|west_currentRank|west_debut|west_height|west_id|west_intai          |west_weight|west_rikishi_id|west_yusho|west_makuuchi_yusho|west_totalWins|west_totalLosses|west_totalMatches|west_makuuchiWins|west_basho|west_Makuuchi_basho|west_Gino_sho|west_Kanto_sho|west_Shukun_sho|east_currentRank|east_debut|east_height|east_id|east_intai          |east_weight|east_rikishi_id|east_yusho|east_makuuchi_yusho|east_totalWins|east_totalLosses|east_totalMatches|east_makuuchiWins|east_basho|east_Makuuchi_basho|east_Gino_sho|east_Kanto_sho|east_Shukun_sho|west_rank        |west_rankValue|west_order|east_rank        |east_rankValue|east_order|east_birthdate_parsed|west_birthdate_parsed|match_date|east_age|west_age|east_debut_clean|west_debut_clean|east_debut_parsed|west_debut_parsed|east_years_active|west_years_active|
[2025-11-12T22:18:38.091+0000] {spark_submit.py:571} INFO - +---+---------+------+-----------------+------------+-----------+-------+------+-----------------+-----------+-----------+--------+--------+----------+-------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+-----------------+--------------+----------+-----------------+--------------+----------+---------------------+---------------------+----------+--------+--------+----------------+----------------+-----------------+-----------------+-----------------+-----------------+
[2025-11-12T22:18:38.091+0000] {spark_submit.py:571} INFO - |1  |Makushita|5394  |Makushita 40 East|Tokuoyama   |oshitaoshi |11     |5409  |Makushita 40 West|Masakaze   |Tokuoyama  |5394    |        |1992050111|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198503    |180.0      |5394   |1997-07-01T00:00:00Z|161.5      |5394           |0         |NULL               |256           |262             |518              |NULL             |74        |NULL               |NULL         |NULL          |NULL           |Makushita 40 West|740           |207       |Makushita 40 East|740           |206       |1970-03-11           |1970-12-15           |1992-05-01|22      |21      |1985-03-01      |1987-09-01      |1985-03-01       |1987-09-01       |7                |4                |
[2025-11-12T22:18:38.091+0000] {spark_submit.py:571} INFO - |15 |Makushita|5609  |Makushita 43 West|Daikaizan   |uwatenage  |6      |5409  |Makushita 40 West|Masakaze   |Daikaizan  |5609    |        |199205156 |0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198305    |185.0      |5609   |1996-09-01T00:00:00Z|155.0      |5609           |1         |NULL               |285           |263             |548              |NULL             |80        |NULL               |NULL         |NULL          |NULL           |Makushita 40 West|740           |207       |Makushita 43 West|743           |213       |1967-04-12           |1970-12-15           |1992-05-15|25      |21      |1983-05-01      |1987-09-01      |1983-05-01       |1987-09-01       |9                |4                |
[2025-11-12T22:18:38.091+0000] {spark_submit.py:571} INFO - |5  |Makushita|5894  |Makushita 41 East|Kotodaiei   |oshidashi  |9      |5409  |Makushita 40 West|Masakaze   |Masakaze   |5409    |        |199205059 |1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198101    |178.4      |5894   |1993-01-01T00:00:00Z|112.6      |5894           |0         |NULL               |256           |241             |497              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |Makushita 40 West|740           |207       |Makushita 41 East|741           |208       |1963-02-16           |1970-12-15           |1992-05-05|29      |21      |1981-01-01      |1987-09-01      |1981-01-01       |1987-09-01       |11               |4                |
[2025-11-12T22:18:38.092+0000] {spark_submit.py:571} INFO - |5  |Sandanme |5820  |Sandanme 52 East |Hokudozan   |kotenage   |26     |4894  |Sandanme 48 West |Kantoryu   |Kantoryu   |4894    |        |1992050526|1      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198705    |180.0      |5820   |1994-03-01T00:00:00Z|88.0       |5820           |0         |NULL               |129           |127             |256              |NULL             |41        |NULL               |NULL         |NULL          |NULL           |Sandanme 48 West |848           |435       |Sandanme 52 East |852           |442       |1971-04-17           |1970-11-18           |1992-05-05|21      |21      |1987-05-01      |1989-01-01      |1987-05-01       |1989-01-01       |5                |3                |
[2025-11-12T22:18:38.092+0000] {spark_submit.py:571} INFO - |13 |Sandanme |3844  |Sandanme 13 East |Takaozaki   |yorikiri   |28     |5409  |Sandanme 21 East |Masakaze   |Takaozaki  |3844    |        |1995091328|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |199203    |190.0      |3844   |2007-09-01T00:00:00Z|147.5      |3844           |2         |NULL               |505           |470             |975              |229              |93        |34                 |NULL         |3             |NULL           |Sandanme 21 East |821           |378       |Sandanme 13 East |813           |360       |1976-04-02           |1970-12-15           |1995-09-13|19      |24      |1992-03-01      |1987-09-01      |1992-03-01       |1987-09-01       |3                |8                |
[2025-11-12T22:18:38.092+0000] {spark_submit.py:571} INFO - |11 |Jonidan  |3922  |Jonidan 121 East |Minami      |hikiotoshi |31     |4823  |Jonidan 123 West |Hirohata   |Minami     |3922    |        |1995091131|0      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199503    |181.0      |3922   |2013-11-01T00:00:00Z|134.0      |3922           |1         |NULL               |409           |354             |763              |NULL             |111       |NULL               |NULL         |NULL          |NULL           |Jonidan 123 West |1023          |873       |Jonidan 121 East |1021          |863       |1979-05-23           |1975-12-10           |1995-09-11|16      |19      |1995-03-01      |1994-01-01      |1995-03-01       |1994-01-01       |0                |1                |
[2025-11-12T22:18:38.093+0000] {spark_submit.py:571} INFO - |6  |Sandanme |3657  |Sandanme 32 East |Takanosho   |yorikiri   |33     |4894  |Sandanme 40 East |Kantoryu   |Takanosho  |3657    |        |1995090633|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198703    |188.1      |3657   |2005-03-01T00:00:00Z|181.0      |3657           |1         |NULL               |368           |388             |756              |NULL             |108       |NULL               |NULL         |NULL          |NULL           |Sandanme 40 East |840           |418       |Sandanme 32 East |832           |402       |1971-08-05           |1970-11-18           |1995-09-06|24      |24      |1987-03-01      |1989-01-01      |1987-03-01       |1989-01-01       |8                |6                |
[2025-11-12T22:18:38.093+0000] {spark_submit.py:571} INFO - |13 |Jonidan  |3571  |Jonidan 127 West |Dewanoyu    |oshidashi  |20     |4823  |Jonidan 123 West |Hirohata   |Hirohata   |4823    |        |1995091320|1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199209    |171.5      |3571   |2005-03-01T00:00:00Z|135.0      |3571           |0         |NULL               |242           |241             |483              |NULL             |75        |NULL               |NULL         |NULL          |NULL           |Jonidan 123 West |1023          |873       |Jonidan 127 West |1027          |889       |1976-04-16           |1975-12-10           |1995-09-13|19      |19      |1992-09-01      |1994-01-01      |1992-09-01       |1994-01-01       |3                |1                |
[2025-11-12T22:18:38.093+0000] {spark_submit.py:571} INFO - |9  |Sandanme |5835  |Sandanme 39 East |Kuroiwa     |kimedashi  |30     |4894  |Sandanme 40 East |Kantoryu   |Kantoryu   |4894    |        |1995090930|1      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198303    |187.5      |5835   |1996-03-01T00:00:00Z|93.5       |5835           |0         |NULL               |265           |274             |539              |NULL             |78        |NULL               |NULL         |NULL          |NULL           |Sandanme 40 East |840           |418       |Sandanme 39 East |839           |416       |1967-06-02           |1970-11-18           |1995-09-09|28      |24      |1983-03-01      |1989-01-01      |1983-03-01       |1989-01-01       |12               |6                |
[2025-11-12T22:18:38.094+0000] {spark_submit.py:571} INFO - |4  |Jonidan  |4018  |Jonidan 89 West  |Raiho       |hatakikomi |47     |5385  |Jonidan 87 West  |Fujiwaka   |Raiho      |4018    |        |1995090447|0      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199203    |179.0      |4018   |2003-01-01T00:00:00Z|145.5      |4018           |1         |NULL               |221           |224             |445              |NULL             |65        |NULL               |NULL         |NULL          |NULL           |Jonidan 87 West  |987           |754       |Jonidan 89 West  |989           |758       |1976-07-22           |1976-02-17           |1995-09-04|19      |19      |1992-03-01      |1992-09-01      |1992-03-01       |1992-09-01       |3                |3                |
[2025-11-12T22:18:38.094+0000] {spark_submit.py:571} INFO - |3  |Jonidan  |3585  |Jonidan 124 East |Ogiryu      |tsukiotoshi|31     |4823  |Jonidan 123 West |Hirohata   |Hirohata   |4823    |        |1995090331|1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199011    |171.0      |3585   |2009-01-01T00:00:00Z|82.0       |3585           |0         |NULL               |356           |407             |763              |NULL             |109       |NULL               |NULL         |NULL          |NULL           |Jonidan 123 West |1023          |873       |Jonidan 124 East |1024          |875       |1972-10-15           |1975-12-10           |1995-09-03|22      |19      |1990-11-01      |1994-01-01      |1990-11-01       |1994-01-01       |4                |1                |
[2025-11-12T22:18:38.095+0000] {spark_submit.py:571} INFO - |10 |Jonidan  |4822  |Jonidan 126 West |Oazuma      |uwatenage  |30     |4823  |Jonidan 123 West |Hirohata   |Hirohata   |4823    |        |1995091030|1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199201    |182.0      |4822   |2001-07-01T00:00:00Z|97.5       |4822           |0         |NULL               |179           |185             |364              |NULL             |56        |NULL               |NULL         |NULL          |NULL           |Jonidan 123 West |1023          |873       |Jonidan 126 West |1026          |886       |1973-12-30           |1975-12-10           |1995-09-10|21      |19      |1992-01-01      |1994-01-01      |1992-01-01       |1994-01-01       |3                |1                |
[2025-11-12T22:18:38.095+0000] {spark_submit.py:571} INFO - |6  |Jonidan  |5312  |Jonidan 124 West |Hideyoshi   |yorikiri   |30     |4823  |Jonidan 123 West |Hirohata   |Hirohata   |4823    |        |1995090630|1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199405    |170.0      |5312   |1998-03-01T00:00:00Z|85.0       |5312           |0         |NULL               |77            |78              |155              |NULL             |23        |NULL               |NULL         |NULL          |NULL           |Jonidan 123 West |1023          |873       |Jonidan 124 West |1024          |878       |1978-07-23           |1975-12-10           |1995-09-06|17      |19      |1994-05-01      |1994-01-01      |1994-05-01       |1994-01-01       |1                |1                |
[2025-11-12T22:18:38.095+0000] {spark_submit.py:571} INFO - |11 |Jonidan  |4976  |Jonidan 86 East  |Hirosawa    |tsukiotoshi|47     |5385  |Jonidan 87 West  |Fujiwaka   |Fujiwaka   |5385    |        |1995091147|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199403    |180.0      |4976   |2000-07-01T00:00:00Z|143.0      |4976           |0         |NULL               |135           |117             |252              |NULL             |38        |NULL               |NULL         |NULL          |NULL           |Jonidan 87 West  |987           |754       |Jonidan 86 East  |986           |751       |1975-07-22           |1976-02-17           |1995-09-11|20      |19      |1994-03-01      |1992-09-01      |1994-03-01       |1992-09-01       |1                |3                |
[2025-11-12T22:18:38.095+0000] {spark_submit.py:571} INFO - |10 |Jonidan  |5069  |Jonidan 83 East  |Fujishiro   |uwatenage  |48     |5385  |Jonidan 87 West  |Fujiwaka   |Fujishiro  |5069    |        |1995091048|0      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199409    |187.5      |5069   |2000-01-01T00:00:00Z|133.0      |5069           |0         |NULL               |102           |94              |196              |NULL             |32        |NULL               |NULL         |NULL          |NULL           |Jonidan 87 West  |987           |754       |Jonidan 83 East  |983           |745       |1977-05-26           |1976-02-17           |1995-09-10|18      |19      |1994-09-01      |1992-09-01      |1994-09-01       |1992-09-01       |1                |3                |
[2025-11-12T22:18:38.096+0000] {spark_submit.py:571} INFO - |6  |Sandanme |3290  |Sandanme 20 East |Akinohana   |sukuinage  |39     |5409  |Sandanme 21 East |Masakaze   |Masakaze   |5409    |        |1995090639|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |181.0      |3290   |2019-01-01T00:00:00Z|147.5      |3290           |0         |NULL               |535           |524             |1059             |NULL             |154       |NULL               |NULL         |NULL          |NULL           |Sandanme 21 East |821           |378       |Sandanme 20 East |820           |376       |1975-01-03           |1970-12-15           |1995-09-06|20      |24      |1993-03-01      |1987-09-01      |1993-03-01       |1987-09-01       |2                |8                |
[2025-11-12T22:18:38.096+0000] {spark_submit.py:571} INFO - |6  |Jonidan  |4003  |Jonidan 88 West  |Hokutenzan  |oshidashi  |47     |5385  |Jonidan 87 West  |Fujiwaka   |Fujiwaka   |5385    |        |1995090647|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199403    |177.0      |4003   |2003-09-01T00:00:00Z|116.5      |4003           |0         |NULL               |185           |190             |375              |NULL             |57        |NULL               |NULL         |NULL          |NULL           |Jonidan 87 West  |987           |754       |Jonidan 88 West  |988           |756       |1979-03-30           |1976-02-17           |1995-09-06|16      |19      |1994-03-01      |1992-09-01      |1994-03-01       |1992-09-01       |1                |3                |
[2025-11-12T22:18:38.096+0000] {spark_submit.py:571} INFO - |9  |Sandanme |5137  |Sandanme 68 East |Ryutenzan   |yorikiri   |16     |4894  |Sandanme 71 East |Kantoryu   |Kantoryu   |4894    |        |1997070916|1      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |199509    |187.0      |5137   |1999-05-01T00:00:00Z|134.0      |5137           |0         |NULL               |81            |65              |146              |NULL             |22        |NULL               |NULL         |NULL          |NULL           |Sandanme 71 East |871           |480       |Sandanme 68 East |868           |474       |1976-06-11           |1970-11-18           |1997-07-09|21      |26      |1995-09-01      |1989-01-01      |1995-09-01       |1989-01-01       |1                |8                |
[2025-11-12T22:18:38.097+0000] {spark_submit.py:571} INFO - |7  |Jonidan  |4915  |Jonidan 173 West |Neya        |yorikiri   |2      |3506  |Jonidan 171 West |Kokubushu  |Neya       |4915    |        |199805072 |0      |NULL            |199505    |176.0      |3506   |2003-01-01T00:00:00Z|126.0      |3506           |0         |NULL               |119           |168             |287              |NULL             |43        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |175.0      |4915   |2001-01-01T00:00:00Z|107.5      |4915           |0         |NULL               |142           |178             |320              |NULL             |47        |NULL               |NULL         |NULL          |NULL           |Jonidan 171 West |1071          |1065      |Jonidan 173 West |1073          |1073      |1977-06-23           |1973-07-30           |1998-05-07|20      |24      |1993-03-01      |1995-05-01      |1993-03-01       |1995-05-01       |5                |3                |
[2025-11-12T22:18:38.097+0000] {spark_submit.py:571} INFO - |15 |Jonidan  |3595  |Jonidan 172 West |Imanishi    |oshitaoshi |1      |3506  |Jonidan 171 West |Kokubushu  |Kokubushu  |3506    |        |199805151 |1      |NULL            |199505    |176.0      |3506   |2003-01-01T00:00:00Z|126.0      |3506           |0         |NULL               |119           |168             |287              |NULL             |43        |NULL               |NULL         |NULL          |NULL           |NULL            |199603    |177.0      |3595   |2002-01-01T00:00:00Z|100.5      |3595           |0         |NULL               |110           |120             |230              |NULL             |35        |NULL               |NULL         |NULL          |NULL           |Jonidan 171 West |1071          |1065      |Jonidan 172 West |1072          |1069      |1980-09-05           |1973-07-30           |1998-05-15|17      |24      |1996-03-01      |1995-05-01      |1996-03-01       |1995-05-01       |2                |3                |
[2025-11-12T22:18:38.097+0000] {spark_submit.py:571} INFO - |5  |Sandanme |3726  |Sandanme 38 East |Torafusuyama|yorikiri   |30     |5409  |Sandanme 42 East |Masakaze   |Masakaze   |5409    |        |1994030530|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198703    |188.0      |3726   |2004-01-01T00:00:00Z|133.5      |3726           |0         |NULL               |360           |340             |700              |NULL             |101       |NULL               |NULL         |NULL          |NULL           |Sandanme 42 East |842           |422       |Sandanme 38 East |838           |414       |1971-06-06           |1970-12-15           |1994-03-05|22      |23      |1987-03-01      |1987-09-01      |1987-03-01       |1987-09-01       |7                |6                |
[2025-11-12T22:18:38.098+0000] {spark_submit.py:571} INFO - |8  |Sandanme |5437  |Sandanme 31 East |Amagifuji   |oshidashi  |34     |4894  |Sandanme 33 West |Kantoryu   |Amagifuji  |5437    |        |1994030834|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198703    |180.0      |5437   |1997-05-01T00:00:00Z|132.0      |5437           |0         |NULL               |217           |203             |420              |NULL             |61        |NULL               |NULL         |NULL          |NULL           |Sandanme 33 West |833           |405       |Sandanme 31 East |831           |400       |1972-01-23           |1970-11-18           |1994-03-08|22      |23      |1987-03-01      |1989-01-01      |1987-03-01       |1989-01-01       |7                |5                |
[2025-11-12T22:18:38.098+0000] {spark_submit.py:571} INFO - |4  |Sandanme |5754  |Sandanme 40 East |Tsugarufuji |uwatenage  |30     |5409  |Sandanme 42 East |Masakaze   |Tsugarufuji|5754    |        |1994030430|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198803    |186.5      |5754   |1995-09-01T00:00:00Z|124.0      |5754           |0         |NULL               |150           |158             |308              |NULL             |45        |NULL               |NULL         |NULL          |NULL           |Sandanme 42 East |842           |422       |Sandanme 40 East |840           |418       |1972-12-17           |1970-12-15           |1994-03-04|21      |23      |1988-03-01      |1987-09-01      |1988-03-01       |1987-09-01       |6                |6                |
[2025-11-12T22:18:38.098+0000] {spark_submit.py:571} INFO - |3  |Jonokuchi|5033  |Jonokuchi 49 East|Dewasakai   |yorikiri   |5      |4823  |Jonokuchi 50 West|Hirohata   |Dewasakai  |5033    |        |199403035 |0      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199401    |179.5      |5033   |2000-03-01T00:00:00Z|99.0       |5033           |0         |NULL               |132           |127             |259              |NULL             |37        |NULL               |NULL         |NULL          |NULL           |Jonokuchi 50 West|1050          |981       |Jonokuchi 49 East|1049          |975       |1975-07-19           |1975-12-10           |1994-03-03|18      |18      |1994-01-01      |1994-01-01      |1994-01-01       |1994-01-01       |0                |0                |
[2025-11-12T22:18:38.099+0000] {spark_submit.py:571} INFO - |14 |Jonokuchi|5424  |Jonokuchi 44 East|Chida       |oshidashi  |3      |4823  |Jonokuchi 50 West|Hirohata   |Hirohata   |4823    |        |199403143 |1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |174.0      |5424   |1997-05-01T00:00:00Z|109.0      |5424           |0         |NULL               |57            |104             |161              |NULL             |24        |NULL               |NULL         |NULL          |NULL           |Jonokuchi 50 West|1050          |981       |Jonokuchi 44 East|1044          |956       |1977-05-07           |1975-12-10           |1994-03-14|16      |18      |1993-03-01      |1994-01-01      |1993-03-01       |1994-01-01       |1                |0                |
[2025-11-12T22:18:38.099+0000] {spark_submit.py:571} INFO - |5  |Jonokuchi|5991  |Jonokuchi 47 East|Ishiyama    |oshitaoshi |6      |4823  |Jonokuchi 50 West|Hirohata   |Ishiyama   |5991    |        |199403056 |0      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199401    |183.0      |5991   |1996-03-01T00:00:00Z|106.0      |5991           |0         |NULL               |28            |14              |42               |NULL             |11        |NULL               |NULL         |NULL          |NULL           |Jonokuchi 50 West|1050          |981       |Jonokuchi 47 East|1047          |967       |1975-05-19           |1975-12-10           |1994-03-05|18      |18      |1994-01-01      |1994-01-01      |1994-01-01       |1994-01-01       |0                |0                |
[2025-11-12T22:18:38.099+0000] {spark_submit.py:571} INFO - |10 |Sandanme |3858  |Sandanme 40 East |Chiyotaikai |yoritaoshi |29     |4894  |Sandanme 47 East |Kantoryu   |Kantoryu   |4894    |        |1993111029|1      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |199211    |181.5      |3858   |2010-01-01T00:00:00Z|158.0      |3858           |7         |3                  |771           |528             |1299             |597              |103       |75                 |3            |1             |1              |Sandanme 47 East |847           |432       |Sandanme 40 East |840           |418       |1976-04-29           |1970-11-18           |1993-11-10|17      |22      |1992-11-01      |1989-01-01      |1992-11-01       |1989-01-01       |1                |4                |
[2025-11-12T22:18:38.100+0000] {spark_submit.py:571} INFO - |3  |Jonokuchi|4042  |Jonokuchi 6 East |Ken         |tsukiotoshi|24     |5385  |Jonokuchi 7 East |Fujiwaka   |Ken        |4042    |        |1993110324|0      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |180.0      |4042   |2011-05-01T00:00:00Z|137.7      |4042           |1         |NULL               |512           |493             |1005             |4                |108       |1                  |NULL         |NULL          |NULL           |Jonokuchi 7 East |1007          |808       |Jonokuchi 6 East |1006          |803       |1977-12-14           |1976-02-17           |1993-11-03|15      |17      |1993-03-01      |1992-09-01      |1993-03-01       |1992-09-01       |0                |1                |
[2025-11-12T22:18:38.100+0000] {spark_submit.py:571} INFO - |11 |Jonidan  |4066  |Jonidan 52 East  |Gojoro      |oshidashi  |64     |5409  |Jonidan 61 East  |Masakaze   |Gojoro     |4066    |        |1993111164|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198911    |190.0      |4066   |2005-11-01T00:00:00Z|147.0      |4066           |4         |NULL               |504           |446             |950              |113              |96        |17                 |NULL         |NULL          |NULL           |Jonidan 61 East  |961           |701       |Jonidan 52 East  |952           |683       |1973-08-18           |1970-12-15           |1993-11-11|20      |22      |1989-11-01      |1987-09-01      |1989-11-01       |1987-09-01       |4                |6                |
[2025-11-12T22:18:38.101+0000] {spark_submit.py:571} INFO - |12 |Jonokuchi|3571  |Jonokuchi 3 East |Dewanoyu    |yoritaoshi |25     |5385  |Jonokuchi 7 East |Fujiwaka   |Fujiwaka   |5385    |        |1993111225|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199209    |171.5      |3571   |2005-03-01T00:00:00Z|135.0      |3571           |0         |NULL               |242           |241             |483              |NULL             |75        |NULL               |NULL         |NULL          |NULL           |Jonokuchi 7 East |1007          |808       |Jonokuchi 3 East |1003          |791       |1976-04-16           |1976-02-17           |1993-11-12|17      |17      |1992-09-01      |1992-09-01      |1992-09-01       |1992-09-01       |1                |1                |
[2025-11-12T22:18:38.101+0000] {spark_submit.py:571} INFO - |14 |Jonidan  |5098  |Jonidan 44 East  |Denryu      |yorikiri   |43     |5409  |Jonidan 61 East  |Masakaze   |Masakaze   |5409    |        |1993111443|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198903    |178.0      |5098   |1999-05-01T00:00:00Z|105.0      |5098           |0         |NULL               |181           |192             |373              |NULL             |56        |NULL               |NULL         |NULL          |NULL           |Jonidan 61 East  |961           |701       |Jonidan 44 East  |944           |667       |1973-11-22           |1970-12-15           |1993-11-14|19      |22      |1989-03-01      |1987-09-01      |1989-03-01       |1987-09-01       |4                |6                |
[2025-11-12T22:18:38.101+0000] {spark_submit.py:571} INFO - |4  |Jonidan  |5972  |Jonidan 60 East  |Yutoyama    |yoritaoshi |57     |5409  |Jonidan 61 East  |Masakaze   |Masakaze   |5409    |        |1993110457|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |199103    |177.0      |5972   |1994-11-01T00:00:00Z|88.0       |5972           |0         |NULL               |68            |73              |141              |NULL             |22        |NULL               |NULL         |NULL          |NULL           |Jonidan 61 East  |961           |701       |Jonidan 60 East  |960           |699       |1975-07-04           |1970-12-15           |1993-11-04|18      |22      |1991-03-01      |1987-09-01      |1991-03-01       |1987-09-01       |2                |6                |
[2025-11-12T22:18:38.102+0000] {spark_submit.py:571} INFO - |9  |Jonidan  |4873  |Jonidan 42 East  |Tsurunohana |hatakikomi |61     |4823  |Jonidan 47 East  |Hirohata   |Tsurunohana|4873    |        |1996010961|0      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |198903    |180.0      |4873   |2001-03-01T00:00:00Z|131.5      |4873           |0         |NULL               |225           |260             |485              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |Jonidan 47 East  |947           |673       |Jonidan 42 East  |942           |663       |1973-06-09           |1975-12-10           |1996-01-09|22      |20      |1989-03-01      |1994-01-01      |1989-03-01       |1994-01-01       |6                |2                |
[2025-11-12T22:18:38.102+0000] {spark_submit.py:571} INFO - |8  |Jonidan  |3966  |Jonidan 98 West  |Sano        |oshidashi  |38     |5385  |Jonidan 97 West  |Fujiwaka   |Fujiwaka   |5385    |        |1996010838|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199211    |177.5      |3966   |2007-07-01T00:00:00Z|166.5      |3966           |0         |NULL               |271           |325             |596              |NULL             |88        |NULL               |NULL         |NULL          |NULL           |Jonidan 97 West  |997           |774       |Jonidan 98 West  |998           |776       |1976-05-07           |1976-02-17           |1996-01-08|19      |19      |1992-11-01      |1992-09-01      |1992-11-01       |1992-09-01       |3                |3                |
[2025-11-12T22:18:38.102+0000] {spark_submit.py:571} INFO - |4  |Sandanme |5100  |Sandanme 22 East |Senshinryu  |yorikiri   |38     |4894  |Sandanme 23 East |Kantoryu   |Senshinryu |5100    |        |1996010438|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198903    |178.0      |5100   |1999-07-01T00:00:00Z|114.0      |5100           |0         |NULL               |214           |213             |427              |NULL             |62        |NULL               |NULL         |NULL          |NULL           |Sandanme 23 East |823           |383       |Sandanme 22 East |822           |380       |1973-08-17           |1970-11-18           |1996-01-04|22      |25      |1989-03-01      |1989-01-01      |1989-03-01       |1989-01-01       |6                |7                |
[2025-11-12T22:18:38.103+0000] {spark_submit.py:571} INFO - |13 |Jonidan  |5708  |Jonidan 38 East  |Hoken       |yorikiri   |42     |4823  |Jonidan 47 East  |Hirohata   |Hirohata   |4823    |        |1996011342|1      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199211    |189.0      |5708   |1996-07-01T00:00:00Z|116.0      |5708           |0         |NULL               |58            |62              |120              |NULL             |21        |NULL               |NULL         |NULL          |NULL           |Jonidan 47 East  |947           |673       |Jonidan 38 East  |938           |655       |1974-09-28           |1975-12-10           |1996-01-13|21      |20      |1992-11-01      |1994-01-01      |1992-11-01       |1994-01-01       |3                |2                |
[2025-11-12T22:18:38.103+0000] {spark_submit.py:571} INFO - |8  |Sandanme |4061  |Sandanme 17 East |Kanenoumi   |yorikiri   |42     |4894  |Sandanme 13 West |Kantoryu   |Kanenoumi  |4061    |        |1993090842|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |199103    |184.0      |4061   |2006-05-01T00:00:00Z|156.0      |4061           |4         |NULL               |469           |453             |922              |102              |91        |17                 |NULL         |NULL          |NULL           |Sandanme 13 West |813           |361       |Sandanme 17 East |817           |369       |1976-01-07           |1970-11-18           |1993-09-08|17      |22      |1991-03-01      |1989-01-01      |1991-03-01       |1989-01-01       |2                |4                |
[2025-11-12T22:18:38.103+0000] {spark_submit.py:571} INFO - |1  |Sandanme |5554  |Sandanme 13 East |Fukuda      |oshidashi  |42     |4894  |Sandanme 13 West |Kantoryu   |Fukuda     |5554    |        |1993090142|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198603    |190.5      |5554   |1994-11-01T00:00:00Z|132.2      |5554           |0         |NULL               |175           |181             |356              |NULL             |52        |NULL               |NULL         |NULL          |NULL           |Sandanme 13 West |813           |361       |Sandanme 13 East |813           |360       |1970-07-15           |1970-11-18           |1993-09-01|23      |22      |1986-03-01      |1989-01-01      |1986-03-01       |1989-01-01       |7                |4                |
[2025-11-12T22:18:38.103+0000] {spark_submit.py:571} INFO - |13 |Jonidan  |5328  |Jonidan 176 East |Uemura      |uwatenage  |7      |5385  |Jonidan 171 West |Fujiwaka   |Uemura     |5328    |        |199309137 |0      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |176.0      |5328   |1998-01-01T00:00:00Z|126.5      |5328           |0         |NULL               |96            |89              |185              |NULL             |29        |NULL               |NULL         |NULL          |NULL           |Jonidan 171 West |1071          |1065      |Jonidan 176 East |1076          |1083      |1977-05-02           |1976-02-17           |1993-09-13|16      |17      |1993-03-01      |1992-09-01      |1993-03-01       |1992-09-01       |0                |1                |
[2025-11-12T22:18:38.104+0000] {spark_submit.py:571} INFO - |12 |Makushita|3749  |Makushita 25 East|Wakakosho   |yorikiri   |18     |5409  |Makushita 26 West|Masakaze   |Masakaze   |5409    |        |1996031218|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |199005    |184.5      |3749   |2005-03-01T00:00:00Z|176.0      |3749           |0         |NULL               |415           |400             |815              |13               |89        |2                  |NULL         |NULL          |NULL           |Makushita 26 West|726           |177       |Makushita 25 East|725           |174       |1975-03-04           |1970-12-15           |1996-03-12|21      |25      |1990-05-01      |1987-09-01      |1990-05-01       |1987-09-01       |5                |8                |
[2025-11-12T22:18:38.104+0000] {spark_submit.py:571} INFO - |15 |Makushita|3669  |Makushita 30 West|Tsuchihashi |hatakikomi |11     |5409  |Makushita 26 West|Masakaze   |Masakaze   |5409    |        |1996031511|1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198905    |174.0      |3669   |2006-11-01T00:00:00Z|88.0       |3669           |2         |NULL               |365           |369             |734              |NULL             |105       |NULL               |NULL         |NULL          |NULL           |Makushita 26 West|726           |177       |Makushita 30 West|730           |186       |1973-09-25           |1970-12-15           |1996-03-15|22      |25      |1989-05-01      |1987-09-01      |1989-05-01       |1987-09-01       |6                |8                |
[2025-11-12T22:18:38.105+0000] {spark_submit.py:571} INFO - |9  |Sandanme |4984  |Sandanme 57 East |Tsukasaryu  |yorikiri   |22     |4894  |Sandanme 59 East |Kantoryu   |Tsukasaryu |4984    |        |1996030922|0      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198805    |172.0      |4984   |1999-11-01T00:00:00Z|123.0      |4984           |0         |NULL               |235           |248             |483              |NULL             |69        |NULL               |NULL         |NULL          |NULL           |Sandanme 59 East |859           |456       |Sandanme 57 East |857           |452       |1972-11-04           |1970-11-18           |1996-03-09|23      |25      |1988-05-01      |1989-01-01      |1988-05-01       |1989-01-01       |7                |7                |
[2025-11-12T22:18:38.105+0000] {spark_submit.py:571} INFO - |4  |Sandanme |5068  |Sandanme 58 East |Kamisawa    |yorikiri   |21     |4894  |Sandanme 59 East |Kantoryu   |Kantoryu   |4894    |        |1996030421|1      |NULL            |198901    |176.0      |4894   |2001-01-01T00:00:00Z|150.0      |4894           |0         |NULL               |242           |240             |482              |NULL             |72        |NULL               |NULL         |NULL          |NULL           |NULL            |198901    |182.0      |5068   |2000-03-01T00:00:00Z|110.0      |5068           |0         |NULL               |227           |214             |441              |NULL             |67        |NULL               |NULL         |NULL          |NULL           |Sandanme 59 East |859           |456       |Sandanme 58 East |858           |454       |1970-09-06           |1970-11-18           |1996-03-04|25      |25      |1989-01-01      |1989-01-01      |1989-01-01       |1989-01-01       |7                |7                |
[2025-11-12T22:18:38.105+0000] {spark_submit.py:571} INFO - |9  |Makushita|3907  |Makushita 27 West|Kimenryu    |yorikiri   |17     |5409  |Makushita 26 West|Masakaze   |Kimenryu   |3907    |        |1996030917|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |198503    |189.5      |3907   |2010-09-01T00:00:00Z|144.5      |3907           |1         |NULL               |534           |519             |1053             |NULL             |153       |NULL               |NULL         |NULL          |NULL           |Makushita 26 West|726           |177       |Makushita 27 West|727           |179       |1969-09-29           |1970-12-15           |1996-03-09|26      |25      |1985-03-01      |1987-09-01      |1985-03-01       |1987-09-01       |11               |8                |
[2025-11-12T22:18:38.106+0000] {spark_submit.py:571} INFO - |13 |Jonidan  |4959  |Jonidan 65 East  |Kai         |uwatenage  |34     |5385  |Jonidan 69 West  |Fujiwaka   |Kai        |4959    |        |1996031334|0      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |186.0      |4959   |2000-07-01T00:00:00Z|134.0      |4959           |0         |NULL               |149           |133             |282              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |Jonidan 69 West  |969           |718       |Jonidan 65 East  |965           |709       |1977-05-17           |1976-02-17           |1996-03-13|18      |20      |1993-03-01      |1992-09-01      |1993-03-01       |1992-09-01       |3                |3                |
[2025-11-12T22:18:38.106+0000] {spark_submit.py:571} INFO - |1  |Jonidan  |4942  |Jonidan 70 East  |Wakayanagi  |hatakikomi |50     |5385  |Jonidan 69 West  |Fujiwaka   |Fujiwaka   |5385    |        |1996030150|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199303    |174.0      |4942   |2000-05-01T00:00:00Z|117.0      |4942           |1         |NULL               |140           |143             |283              |NULL             |43        |NULL               |NULL         |NULL          |NULL           |Jonidan 69 West  |969           |718       |Jonidan 70 East  |970           |719       |1977-05-10           |1976-02-17           |1996-03-01|18      |20      |1993-03-01      |1992-09-01      |1993-03-01       |1992-09-01       |3                |3                |
[2025-11-12T22:18:38.106+0000] {spark_submit.py:571} INFO - |3  |Jonidan  |5310  |Jonidan 71 East  |Asanishiharu|yoritaoshi |50     |5385  |Jonidan 69 West  |Fujiwaka   |Fujiwaka   |5385    |        |1996030350|1      |NULL            |199209    |173.5      |5385   |1997-09-01T00:00:00Z|105.0      |5385           |0         |NULL               |98            |105             |203              |NULL             |30        |NULL               |NULL         |NULL          |NULL           |NULL            |199305    |176.0      |5310   |1998-01-01T00:00:00Z|96.0       |5310           |0         |NULL               |90            |94              |184              |NULL             |28        |NULL               |NULL         |NULL          |NULL           |Jonidan 69 West  |969           |718       |Jonidan 71 East  |971           |721       |1973-09-15           |1976-02-17           |1996-03-03|22      |20      |1993-05-01      |1992-09-01      |1993-05-01       |1992-09-01       |2                |3                |
[2025-11-12T22:18:38.107+0000] {spark_submit.py:571} INFO - |12 |Jonidan  |3599  |Jonidan 78 East  |Tamanosho   |yorikiri   |45     |4823  |Jonidan 82 East  |Hirohata   |Tamanosho  |3599    |        |1996031245|0      |NULL            |199401    |174.5      |4823   |2001-05-01T00:00:00Z|133.5      |4823           |2         |NULL               |141           |122             |263              |NULL             |44        |NULL               |NULL         |NULL          |NULL           |NULL            |199105    |176.0      |3599   |2008-03-01T00:00:00Z|141.0      |3599           |0         |NULL               |322           |362             |684              |NULL             |101       |NULL               |NULL         |NULL          |NULL           |Jonidan 82 East  |982           |743       |Jonidan 78 East  |978           |735       |1972-04-28           |1975-12-10           |1996-03-12|23      |20      |1991-05-01      |1994-01-01      |1991-05-01       |1994-01-01       |4                |2                |
[2025-11-12T22:18:38.107+0000] {spark_submit.py:571} INFO - |1  |Makushita|1147  |Makushita 34 East|Saganobori  |yorikiri   |14     |5409  |Makushita 34 West|Masakaze   |Saganobori |1147    |        |1994110114|0      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |197703    |190.0      |1147   |1996-01-01T00:00:00Z|117.0      |1147           |0         |NULL               |516           |497             |1013             |5                |113       |1                  |NULL         |NULL          |NULL           |Makushita 34 West|734           |195       |Makushita 34 East|734           |194       |1961-11-27           |1970-12-15           |1994-11-01|32      |23      |1977-03-01      |1987-09-01      |1977-03-01       |1987-09-01       |17               |7                |
[2025-11-12T22:18:38.107+0000] {spark_submit.py:571} INFO - |15 |Makushita|4619  |Makushita 44 East|Nakanoyama  |oshidashi  |8      |5409  |Makushita 34 West|Masakaze   |Masakaze   |5409    |        |199411158 |1      |NULL            |198709    |185.0      |5409   |1997-05-01T00:00:00Z|169.0      |5409           |2         |NULL               |200           |139             |339              |NULL             |58        |NULL               |NULL         |NULL          |NULL           |NULL            |199003    |183.0      |4619   |2003-09-01T00:00:00Z|138.0      |4619           |1         |NULL               |280           |247             |527              |NULL             |81        |NULL               |NULL         |NULL          |NULL           |Makushita 34 West|734           |195       |Makushita 44 East|744           |214       |1974-06-03           |1970-12-15           |1994-11-15|20      |23      |1990-03-01      |1987-09-01      |1990-03-01       |1987-09-01       |4                |7                |
[2025-11-12T22:18:38.108+0000] {spark_submit.py:571} INFO - +---+---------+------+-----------------+------------+-----------+-------+------+-----------------+-----------+-----------+--------+--------+----------+-------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+----------------+----------+-----------+-------+--------------------+-----------+---------------+----------+-------------------+--------------+----------------+-----------------+-----------------+----------+-------------------+-------------+--------------+---------------+-----------------+--------------+----------+-----------------+--------------+----------+---------------------+---------------------+----------+--------+--------+----------------+----------------+-----------------+-----------------+-----------------+-----------------+
[2025-11-12T22:18:38.108+0000] {spark_submit.py:571} INFO - only showing top 50 rows
[2025-11-12T22:18:38.108+0000] {spark_submit.py:571} INFO - 
[2025-11-12T22:18:38.295+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO BlockManagerInfo: Removed broadcast_9_piece0 on eb021f2c8a8b:35921 in memory (size: 14.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:38.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.18.0.5:45133 in memory (size: 14.1 KiB, free: 434.4 MiB)
[2025-11-12T22:18:38.537+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:38.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:38.613+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO CodeGenerator: Code generated in 32.232398 ms
[2025-11-12T22:18:38.619+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 221.7 KiB, free 433.9 MiB)
[2025-11-12T22:18:38.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 433.9 MiB)
[2025-11-12T22:18:38.630+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on eb021f2c8a8b:35921 (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:18:38.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO SparkContext: Created broadcast 10 from head at Imputer.scala:170
[2025-11-12T22:18:38.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:18:38.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO DAGScheduler: Registering RDD 39 (head at Imputer.scala:170) as input to shuffle 1
[2025-11-12T22:18:38.638+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO DAGScheduler: Got map stage job 8 (head at Imputer.scala:170) with 2 output partitions
[2025-11-12T22:18:38.638+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (head at Imputer.scala:170)
[2025-11-12T22:18:38.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:38.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:38.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[39] at head at Imputer.scala:170), which has no missing parents
[2025-11-12T22:18:38.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 42.0 KiB, free 433.8 MiB)
[2025-11-12T22:18:38.642+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.3 KiB, free 433.8 MiB)
[2025-11-12T22:18:38.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on eb021f2c8a8b:35921 (size: 14.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:38.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:38.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[39] at head at Imputer.scala:170) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:18:38.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO TaskSchedulerImpl: Adding task set 9.0 with 2 tasks resource profile 0
[2025-11-12T22:18:38.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:18:38.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:18:38.678+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:40603 (size: 14.3 KiB, free: 434.4 MiB)
[2025-11-12T22:18:38.679+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.18.0.5:45133 (size: 14.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:38.757+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:45133 (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:18:38.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.18.0.5:40603 (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:18:41.389+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 2743 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:18:41.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 2963 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:18:41.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-11-12T22:18:41.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: ShuffleMapStage 9 (head at Imputer.scala:170) finished in 2.971 s
[2025-11-12T22:18:41.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:18:41.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: running: Set()
[2025-11-12T22:18:41.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:18:41.613+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: failed: Set()
[2025-11-12T22:18:41.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on eb021f2c8a8b:35921 in memory (size: 14.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:41.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.5:40603 in memory (size: 14.3 KiB, free: 434.4 MiB)
[2025-11-12T22:18:41.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.18.0.5:45133 in memory (size: 14.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:41.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO CodeGenerator: Code generated in 18.814315 ms
[2025-11-12T22:18:41.651+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO SparkContext: Starting job: head at Imputer.scala:170
[2025-11-12T22:18:41.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Got job 9 (head at Imputer.scala:170) with 1 output partitions
[2025-11-12T22:18:41.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Final stage: ResultStage 11 (head at Imputer.scala:170)
[2025-11-12T22:18:41.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2025-11-12T22:18:41.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:41.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[42] at head at Imputer.scala:170), which has no missing parents
[2025-11-12T22:18:41.655+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 25.7 KiB, free 433.9 MiB)
[2025-11-12T22:18:41.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 9.3 KiB, free 433.8 MiB)
[2025-11-12T22:18:41.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on eb021f2c8a8b:35921 (size: 9.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:41.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:41.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[42] at head at Imputer.scala:170) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:41.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2025-11-12T22:18:41.661+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:18:41.674+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.18.0.5:45133 (size: 9.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:41.680+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 172.18.0.5:34294
[2025-11-12T22:18:41.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Removed broadcast_8_piece0 on eb021f2c8a8b:35921 in memory (size: 38.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:41.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.18.0.5:45133 in memory (size: 38.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:41.720+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 58 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:18:41.720+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2025-11-12T22:18:41.721+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: ResultStage 11 (head at Imputer.scala:170) finished in 0.068 s
[2025-11-12T22:18:41.721+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:41.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2025-11-12T22:18:41.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Job 9 finished: head at Imputer.scala:170, took 0.070302 s
[2025-11-12T22:18:41.736+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO CodeGenerator: Code generated in 8.629274 ms
[2025-11-12T22:18:41.775+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO CodeGenerator: Code generated in 5.186925 ms
[2025-11-12T22:18:41.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO SparkContext: Starting job: head at Imputer.scala:259
[2025-11-12T22:18:41.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Got job 10 (head at Imputer.scala:259) with 1 output partitions
[2025-11-12T22:18:41.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Final stage: ResultStage 12 (head at Imputer.scala:259)
[2025-11-12T22:18:41.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:41.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:41.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[46] at head at Imputer.scala:259), which has no missing parents
[2025-11-12T22:18:41.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 22.5 KiB, free 434.1 MiB)
[2025-11-12T22:18:41.788+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 434.1 MiB)
[2025-11-12T22:18:41.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on eb021f2c8a8b:35921 (size: 9.0 KiB, free: 434.3 MiB)
[2025-11-12T22:18:41.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:41.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[46] at head at Imputer.scala:259) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:41.790+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-11-12T22:18:41.791+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10137 bytes)
[2025-11-12T22:18:41.803+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.18.0.5:45133 (size: 9.0 KiB, free: 434.3 MiB)
[2025-11-12T22:18:41.844+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 54 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:18:41.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-11-12T22:18:41.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: ResultStage 12 (head at Imputer.scala:259) finished in 0.060 s
[2025-11-12T22:18:41.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:41.846+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
[2025-11-12T22:18:41.846+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Job 10 finished: head at Imputer.scala:259, took 0.062846 s
[2025-11-12T22:18:41.849+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO SparkContext: Starting job: head at Imputer.scala:259
[2025-11-12T22:18:41.850+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Got job 11 (head at Imputer.scala:259) with 1 output partitions
[2025-11-12T22:18:41.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Final stage: ResultStage 13 (head at Imputer.scala:259)
[2025-11-12T22:18:41.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:41.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:41.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[46] at head at Imputer.scala:259), which has no missing parents
[2025-11-12T22:18:41.854+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 22.5 KiB, free 434.1 MiB)
[2025-11-12T22:18:41.856+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 9.0 KiB, free 434.1 MiB)
[2025-11-12T22:18:41.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on eb021f2c8a8b:35921 (size: 9.0 KiB, free: 434.3 MiB)
[2025-11-12T22:18:41.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:41.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[46] at head at Imputer.scala:259) (first 15 tasks are for partitions Vector(1))
[2025-11-12T22:18:41.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2025-11-12T22:18:41.860+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10383 bytes)
[2025-11-12T22:18:41.874+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.18.0.5:40603 (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:18:41.913+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 55 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:18:41.914+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-11-12T22:18:41.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: ResultStage 13 (head at Imputer.scala:259) finished in 0.062 s
[2025-11-12T22:18:41.918+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:41.918+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
[2025-11-12T22:18:41.919+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO DAGScheduler: Job 11 finished: head at Imputer.scala:259, took 0.065044 s
[2025-11-12T22:18:41.924+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:41 INFO CodeGenerator: Code generated in 7.15341 ms
[2025-11-12T22:18:42.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:42 INFO BlockManagerInfo: Removed broadcast_12_piece0 on eb021f2c8a8b:35921 in memory (size: 9.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:42.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:42 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.18.0.5:45133 in memory (size: 9.3 KiB, free: 434.4 MiB)
[2025-11-12T22:18:42.107+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:42 INFO BlockManagerInfo: Removed broadcast_14_piece0 on eb021f2c8a8b:35921 in memory (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:18:42.115+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:42 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.18.0.5:40603 in memory (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:18:42.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:42 INFO BlockManagerInfo: Removed broadcast_13_piece0 on eb021f2c8a8b:35921 in memory (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:18:42.126+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:42 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.18.0.5:45133 in memory (size: 9.0 KiB, free: 434.4 MiB)
[2025-11-12T22:18:42.382+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:42 INFO BlockManagerInfo: Removed broadcast_10_piece0 on eb021f2c8a8b:35921 in memory (size: 37.4 KiB, free: 434.4 MiB)
[2025-11-12T22:18:42.385+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:42 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.5:45133 in memory (size: 37.4 KiB, free: 434.4 MiB)
[2025-11-12T22:18:42.385+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:42 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.18.0.5:40603 in memory (size: 37.4 KiB, free: 434.4 MiB)
[2025-11-12T22:18:49.572+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO MongoRelation: requiredColumns: id, filters:
[2025-11-12T22:18:49.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:49.590+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.590+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2408 = ) THEN false ELSE isnull(kimarite#2408) END OR CASE WHEN (kimarite#2408 = ) THEN true ELSE (kimarite#2408 = NA) END) THEN false ELSE CASE WHEN (kimarite#2408 = ) THEN true ELSE isnotnull(kimarite#2408) END END
[2025-11-12T22:18:49.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2862 = ) THEN false ELSE isnull(kimarite#2862) END OR CASE WHEN (kimarite#2862 = ) THEN true ELSE (kimarite#2862 = NA) END) THEN false ELSE CASE WHEN (kimarite#2862 = ) THEN true ELSE isnotnull(kimarite#2862) END END
[2025-11-12T22:18:49.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:49.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7767 = ) THEN false ELSE isnull(kimarite#7767) END OR CASE WHEN (kimarite#7767 = ) THEN true ELSE (kimarite#7767 = NA) END) THEN false ELSE CASE WHEN (kimarite#7767 = ) THEN true ELSE isnotnull(kimarite#7767) END END
[2025-11-12T22:18:49.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7971 = ) THEN false ELSE isnull(kimarite#7971) END OR CASE WHEN (kimarite#7971 = ) THEN true ELSE (kimarite#7971 = NA) END) THEN false ELSE CASE WHEN (kimarite#7971 = ) THEN true ELSE isnotnull(kimarite#7971) END END
[2025-11-12T22:18:49.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:49.604+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.604+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11315 = ) THEN false ELSE isnull(kimarite#11315) END OR CASE WHEN (kimarite#11315 = ) THEN true ELSE (kimarite#11315 = NA) END) THEN false ELSE CASE WHEN (kimarite#11315 = ) THEN true ELSE isnotnull(kimarite#11315) END END
[2025-11-12T22:18:49.605+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.605+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11519 = ) THEN false ELSE isnull(kimarite#11519) END OR CASE WHEN (kimarite#11519 = ) THEN true ELSE (kimarite#11519 = NA) END) THEN false ELSE CASE WHEN (kimarite#11519 = ) THEN true ELSE isnotnull(kimarite#11519) END END
[2025-11-12T22:18:49.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:49.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14375 = ) THEN false ELSE isnull(kimarite#14375) END OR CASE WHEN (kimarite#14375 = ) THEN true ELSE (kimarite#14375 = NA) END) THEN false ELSE CASE WHEN (kimarite#14375 = ) THEN true ELSE isnotnull(kimarite#14375) END END
[2025-11-12T22:18:49.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:49.608+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14579 = ) THEN false ELSE isnull(kimarite#14579) END OR CASE WHEN (kimarite#14579 = ) THEN true ELSE (kimarite#14579 = NA) END) THEN false ELSE CASE WHEN (kimarite#14579 = ) THEN true ELSE isnotnull(kimarite#14579) END END
[2025-11-12T22:18:49.726+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO CodeGenerator: Code generated in 5.374532 ms
[2025-11-12T22:18:49.728+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: Registering RDD 51 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2025-11-12T22:18:49.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: Got map stage job 12 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:18:49.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:18:49.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:49.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:49.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:18:49.732+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.8 KiB, free 434.4 MiB)
[2025-11-12T22:18:49.732+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.4 MiB)
[2025-11-12T22:18:49.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on eb021f2c8a8b:35921 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:49.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:49.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:18:49.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks resource profile 0
[2025-11-12T22:18:49.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 11355 bytes)
[2025-11-12T22:18:49.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 15) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 11479 bytes)
[2025-11-12T22:18:49.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO CodeGenerator: Code generated in 5.688745 ms
[2025-11-12T22:18:49.744+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=sumo.jrywipx.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='atlas-efvaxv-shard-0'}
[2025-11-12T22:18:49.745+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO MongoClientCache: Creating MongoClient: []
[2025-11-12T22:18:49.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Cluster description not yet available. Waiting for 30000 ms before timing out
[2025-11-12T22:18:49.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:18:49.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.5:45133 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:49.751+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.18.0.5:40603 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:18:49.751+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:18:49.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:18:49.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: No server chosen by com.mongodb.client.internal.MongoClientDelegate$1@48c02a39 from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 30000 ms before timing out
[2025-11-12T22:18:49.850+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 116 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:18:49.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 15) in 150 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:18:49.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2025-11-12T22:18:49.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0.156 s
[2025-11-12T22:18:49.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:18:49.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: running: Set()
[2025-11-12T22:18:49.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:18:49.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO DAGScheduler: failed: Set()
[2025-11-12T22:18:49.897+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO connection: Opened connection [connectionId{localValue:5, serverValue:108269}] to ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017
[2025-11-12T22:18:49.901+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO connection: Opened connection [connectionId{localValue:6, serverValue:101757}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:18:49.914+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO connection: Opened connection [connectionId{localValue:7, serverValue:98805}] to ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017
[2025-11-12T22:18:49.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=49227122, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:18:49 UTC 2025, lastUpdateTimeNanos=6851353620237}
[2025-11-12T22:18:49.950+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=45475460, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az3'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff0000000000000045, setVersion=7, lastWriteDate=Wed Nov 12 22:18:49 UTC 2025, lastUpdateTimeNanos=6851353759243}
[2025-11-12T22:18:49.951+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Setting max election id to 7fffffff0000000000000045 from replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:18:49.951+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Setting max set version to 7 from replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:18:49.951+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Discovered replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:18:49.952+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=49227122, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:18:49 UTC 2025, lastUpdateTimeNanos=6851353620237}]}. Waiting for 30000 ms before timing out
[2025-11-12T22:18:49.973+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:49 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=58817236, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az1'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:18:49 UTC 2025, lastUpdateTimeNanos=6851379796265}
[2025-11-12T22:18:50.232+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO connection: Opened connection [connectionId{localValue:8, serverValue:101781}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:18:50.439+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Registering RDD 53 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2025-11-12T22:18:50.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Got map stage job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:18:50.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Final stage: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:18:50.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:50.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:50.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:18:50.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 28.2 KiB, free 434.3 MiB)
[2025-11-12T22:18:50.442+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 13.3 KiB, free 434.3 MiB)
[2025-11-12T22:18:50.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on eb021f2c8a8b:35921 (size: 13.3 KiB, free: 434.4 MiB)
[2025-11-12T22:18:50.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:50.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[53] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:50.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-11-12T22:18:50.444+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 16) (172.18.0.5, executor 0, partition 0, ANY, 10279 bytes)
[2025-11-12T22:18:50.456+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.18.0.5:45133 (size: 13.3 KiB, free: 434.4 MiB)
[2025-11-12T22:18:50.486+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO CodeGenerator: Code generated in 33.471643 ms
[2025-11-12T22:18:50.491+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 221.4 KiB, free 434.1 MiB)
[2025-11-12T22:18:50.496+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 434.1 MiB)
[2025-11-12T22:18:50.497+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:50.498+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO SparkContext: Created broadcast 17 from count at NativeMethodAccessorImpl.java:0
[2025-11-12T22:18:50.498+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:18:50.512+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Registering RDD 57 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2025-11-12T22:18:50.514+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Got map stage job 14 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:18:50.514+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:18:50.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:50.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:50.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:18:50.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 43.7 KiB, free 434.0 MiB)
[2025-11-12T22:18:50.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 434.0 MiB)
[2025-11-12T22:18:50.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on eb021f2c8a8b:35921 (size: 18.9 KiB, free: 434.3 MiB)
[2025-11-12T22:18:50.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:50.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:18:50.518+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks resource profile 0
[2025-11-12T22:18:50.519+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:18:50.527+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:50.528+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:50.529+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:50.529+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:50.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.5:40603 (size: 18.9 KiB, free: 434.4 MiB)
[2025-11-12T22:18:50.531+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:50.531+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:50.532+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:50.532+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:50.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:50 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:51.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 18) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:18:51.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 16) in 1202 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:18:51.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-11-12T22:18:51.648+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 1.207 s
[2025-11-12T22:18:51.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:18:51.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: running: Set(ShuffleMapStage 16)
[2025-11-12T22:18:51.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:18:51.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: failed: Set()
[2025-11-12T22:18:51.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:51.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:51.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:51.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:51.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:51.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:51.661+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:51.661+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:51.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.18.0.5:45133 (size: 18.9 KiB, free: 434.4 MiB)
[2025-11-12T22:18:51.681+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:18:51.728+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:18:51.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:18:51.732+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: Final stage: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:18:51.732+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-11-12T22:18:51.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:51.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[59] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:18:51.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.2 KiB, free 434.0 MiB)
[2025-11-12T22:18:51.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 434.0 MiB)
[2025-11-12T22:18:51.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on eb021f2c8a8b:35921 (size: 4.2 KiB, free: 434.3 MiB)
[2025-11-12T22:18:51.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:51.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[59] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:51.736+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-11-12T22:18:51.791+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:51 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:52.696+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 19) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10152 bytes)
[2025-11-12T22:18:52.697+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 2178 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:18:52.713+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.18.0.5:40603 (size: 4.2 KiB, free: 434.3 MiB)
[2025-11-12T22:18:52.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 172.18.0.5:34292
[2025-11-12T22:18:52.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 19) in 72 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:18:52.769+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-11-12T22:18:52.770+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.037 s
[2025-11-12T22:18:52.771+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:52.771+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-11-12T22:18:52.771+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.040506 s
[2025-11-12T22:18:52.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO CodeGenerator: Code generated in 5.019016 ms
[2025-11-12T22:18:52.788+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 178.0 B, free 434.0 MiB)
[2025-11-12T22:18:52.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on eb021f2c8a8b:35921 (size: 178.0 B, free: 434.3 MiB)
[2025-11-12T22:18:52.790+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO SparkContext: Created broadcast 20 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:18:52.797+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:52.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:52.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:52.799+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:52.800+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:52.800+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:52.801+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:52.801+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:52.813+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:18:52.846+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO CodeGenerator: Code generated in 5.144521 ms
[2025-11-12T22:18:52.849+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: Registering RDD 62 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2025-11-12T22:18:52.850+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: Got map stage job 16 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:18:52.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: Final stage: ShuffleMapStage 20 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:18:52.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2025-11-12T22:18:52.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:52.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:18:52.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 15.8 KiB, free 434.0 MiB)
[2025-11-12T22:18:52.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.0 MiB)
[2025-11-12T22:18:52.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on eb021f2c8a8b:35921 (size: 7.6 KiB, free: 434.3 MiB)
[2025-11-12T22:18:52.854+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:52.854+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:52.854+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2025-11-12T22:18:52.855+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10138 bytes)
[2025-11-12T22:18:52.868+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.18.0.5:40603 (size: 7.6 KiB, free: 434.3 MiB)
[2025-11-12T22:18:52.873+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 172.18.0.5:34292
[2025-11-12T22:18:52.897+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.18.0.5:40603 (size: 178.0 B, free: 434.3 MiB)
[2025-11-12T22:18:52.935+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 80 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:18:52.936+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2025-11-12T22:18:52.937+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: ShuffleMapStage 20 (count at NativeMethodAccessorImpl.java:0) finished in 0.086 s
[2025-11-12T22:18:52.937+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:18:52.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: running: Set(ShuffleMapStage 16)
[2025-11-12T22:18:52.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:18:52.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO DAGScheduler: failed: Set()
[2025-11-12T22:18:52.943+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:52.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:52.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:52.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:52.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:52.950+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:52.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:52.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:53.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 18) in 2294 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:18:53.940+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-11-12T22:18:53.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO DAGScheduler: ShuffleMapStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 3.427 s
[2025-11-12T22:18:53.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:18:53.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO DAGScheduler: running: Set()
[2025-11-12T22:18:53.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:18:53.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO DAGScheduler: failed: Set()
[2025-11-12T22:18:53.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:53.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:53.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:53.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:53.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:53.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:53.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:53.950+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:53.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:18:53.958+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:18:53.959+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:18:53.960+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:18:53.961+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:18:53.962+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:18:53.980+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:53.980+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:53.981+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:53.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:53.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:53.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:53.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:53.986+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:53.989+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO CodeGenerator: Code generated in 13.065163 ms
[2025-11-12T22:18:53.999+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:53 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:18:54.000+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Got job 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:18:54.000+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Final stage: ResultStage 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:18:54.001+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
[2025-11-12T22:18:54.001+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:54.001+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[65] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:18:54.005+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 45.4 KiB, free 433.9 MiB)
[2025-11-12T22:18:54.010+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 20.4 KiB, free 433.9 MiB)
[2025-11-12T22:18:54.011+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on eb021f2c8a8b:35921 (size: 20.4 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.012+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:54.013+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[65] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:18:54.013+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-11-12T22:18:54.013+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_15_piece0 on eb021f2c8a8b:35921 in memory (size: 8.7 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.014+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 21) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:18:54.015+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.5:40603 in memory (size: 8.7 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.016+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.18.0.5:45133 in memory (size: 8.7 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.021+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_19_piece0 on eb021f2c8a8b:35921 in memory (size: 4.2 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.022+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.18.0.5:40603 in memory (size: 4.2 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.18.0.5:45133 (size: 20.4 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.026+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_18_piece0 on eb021f2c8a8b:35921 in memory (size: 18.9 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.027+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.5:40603 in memory (size: 18.9 KiB, free: 434.4 MiB)
[2025-11-12T22:18:54.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.18.0.5:45133 in memory (size: 18.9 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.033+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_16_piece0 on eb021f2c8a8b:35921 in memory (size: 13.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.033+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.18.0.5:45133 in memory (size: 13.3 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.036+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_21_piece0 on eb021f2c8a8b:35921 in memory (size: 7.6 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.038+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.18.0.5:40603 in memory (size: 7.6 KiB, free: 434.4 MiB)
[2025-11-12T22:18:54.045+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 172.18.0.5:34294
[2025-11-12T22:18:54.118+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 21) in 104 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:18:54.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-11-12T22:18:54.120+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: ResultStage 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.114 s
[2025-11-12T22:18:54.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:18:54.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
[2025-11-12T22:18:54.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Job 17 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.119256 s
[2025-11-12T22:18:54.133+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO CodeGenerator: Code generated in 5.051318 ms
[2025-11-12T22:18:54.152+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 46.9 KiB, free 434.0 MiB)
[2025-11-12T22:18:54.153+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on eb021f2c8a8b:35921 (size: 46.9 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO SparkContext: Created broadcast 23 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:18:54.163+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:54.164+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:54.165+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:54.165+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:54.166+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:54.166+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:54.167+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:18:54.167+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:18:54.213+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO CodeGenerator: Code generated in 9.380104 ms
[2025-11-12T22:18:54.240+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO CodeGenerator: Code generated in 16.102394 ms
[2025-11-12T22:18:54.245+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 221.6 KiB, free 433.8 MiB)
[2025-11-12T22:18:54.253+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 433.8 MiB)
[2025-11-12T22:18:54.254+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on eb021f2c8a8b:35921 (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO SparkContext: Created broadcast 24 from count at NativeMethodAccessorImpl.java:0
[2025-11-12T22:18:54.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:18:54.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO CodeGenerator: Code generated in 14.204612 ms
[2025-11-12T22:18:54.290+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 221.6 KiB, free 433.6 MiB)
[2025-11-12T22:18:54.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 433.5 MiB)
[2025-11-12T22:18:54.299+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on eb021f2c8a8b:35921 (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:18:54.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO SparkContext: Created broadcast 25 from count at NativeMethodAccessorImpl.java:0
[2025-11-12T22:18:54.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:18:54.334+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Registering RDD 75 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
[2025-11-12T22:18:54.335+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Got map stage job 18 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:18:54.335+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Final stage: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:18:54.335+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:18:54.336+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:18:54.336+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[75] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:18:54.347+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 78.7 KiB, free 433.5 MiB)
[2025-11-12T22:18:54.349+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 433.4 MiB)
[2025-11-12T22:18:54.349+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on eb021f2c8a8b:35921 (size: 29.4 KiB, free: 434.2 MiB)
[2025-11-12T22:18:54.350+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:18:54.350+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[75] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:18:54.353+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks resource profile 0
[2025-11-12T22:18:54.354+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 22) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:18:54.354+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 23) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:18:54.369+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.5:40603 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.370+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.18.0.5:45133 (size: 29.4 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.474+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.5:40603 (size: 46.9 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.18.0.5:45133 (size: 46.9 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.555+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.5:40603 (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:18:54.570+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:54 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.18.0.5:45133 (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:18:55.451+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:55 INFO MongoClientCache: Closing MongoClient: [ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017,ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017,ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017]
[2025-11-12T22:18:55.497+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:55 INFO connection: Closed connection [connectionId{localValue:8, serverValue:101781}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017 because the pool has been closed.
[2025-11-12T22:18:57.375+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:57 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 24) (172.18.0.5, executor 1, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:18:57.376+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:57 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 23) in 3023 ms on 172.18.0.5 (executor 1) (1/4)
[2025-11-12T22:18:57.414+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:57 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.5:40603 (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:18:57.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:57 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 25) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:18:57.642+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:57 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 22) in 3291 ms on 172.18.0.5 (executor 0) (2/4)
[2025-11-12T22:18:57.680+0000] {spark_submit.py:571} INFO - 25/11/12 22:18:57 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.18.0.5:45133 (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:19:00.396+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 25) in 2756 ms on 172.18.0.5 (executor 0) (3/4)
[2025-11-12T22:19:00.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 24) in 3334 ms on 172.18.0.5 (executor 1) (4/4)
[2025-11-12T22:19:00.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool
[2025-11-12T22:19:00.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: ShuffleMapStage 23 (count at NativeMethodAccessorImpl.java:0) finished in 6.373 s
[2025-11-12T22:19:00.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:00.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: running: Set()
[2025-11-12T22:19:00.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:00.711+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:00.717+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:00.718+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:00.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO CodeGenerator: Code generated in 2.919226 ms
[2025-11-12T22:19:00.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO CodeGenerator: Code generated in 3.627256 ms
[2025-11-12T22:19:00.754+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:00.755+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: Got job 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:19:00.755+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: Final stage: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:00.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
[2025-11-12T22:19:00.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:00.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:00.761+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 69.5 KiB, free 433.4 MiB)
[2025-11-12T22:19:00.762+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 433.3 MiB)
[2025-11-12T22:19:00.763+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on eb021f2c8a8b:35921 (size: 29.0 KiB, free: 434.2 MiB)
[2025-11-12T22:19:00.763+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:00.764+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[81] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:00.764+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
[2025-11-12T22:19:00.764+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 26) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:00.773+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.18.0.5:40603 (size: 29.0 KiB, free: 434.2 MiB)
[2025-11-12T22:19:00.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 172.18.0.5:34292
[2025-11-12T22:19:00.951+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 26) in 187 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:00.954+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool
[2025-11-12T22:19:00.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.192 s
[2025-11-12T22:19:00.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:00.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
[2025-11-12T22:19:00.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO DAGScheduler: Job 19 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.198338 s
[2025-11-12T22:19:00.962+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 108.4 KiB, free 433.2 MiB)
[2025-11-12T22:19:00.963+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on eb021f2c8a8b:35921 (size: 108.4 KiB, free: 434.1 MiB)
[2025-11-12T22:19:00.963+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO SparkContext: Created broadcast 28 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:00.968+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:00 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:01.012+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO CodeGenerator: Code generated in 21.298118 ms
[2025-11-12T22:19:01.022+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Registering RDD 84 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
[2025-11-12T22:19:01.023+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Got map stage job 20 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:01.024+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Final stage: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:01.024+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
[2025-11-12T22:19:01.024+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:01.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[84] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:01.026+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 115.4 KiB, free 433.1 MiB)
[2025-11-12T22:19:01.027+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 47.9 KiB, free 433.1 MiB)
[2025-11-12T22:19:01.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on eb021f2c8a8b:35921 (size: 47.9 KiB, free: 434.0 MiB)
[2025-11-12T22:19:01.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:01.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[84] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:01.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
[2025-11-12T22:19:01.029+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 27) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10141 bytes)
[2025-11-12T22:19:01.039+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.18.0.5:45133 (size: 47.9 KiB, free: 434.1 MiB)
[2025-11-12T22:19:01.079+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 172.18.0.5:34294
[2025-11-12T22:19:01.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.18.0.5:45133 (size: 108.4 KiB, free: 434.0 MiB)
[2025-11-12T22:19:01.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 27) in 155 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:01.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool
[2025-11-12T22:19:01.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0.162 s
[2025-11-12T22:19:01.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:01.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: running: Set()
[2025-11-12T22:19:01.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:01.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:01.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:01.207+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:19:01.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO CodeGenerator: Code generated in 13.635788 ms
[2025-11-12T22:19:01.241+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Registering RDD 87 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
[2025-11-12T22:19:01.242+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Got map stage job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:01.242+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Final stage: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:01.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
[2025-11-12T22:19:01.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:01.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[87] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:01.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 120.1 KiB, free 432.9 MiB)
[2025-11-12T22:19:01.250+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 49.2 KiB, free 432.9 MiB)
[2025-11-12T22:19:01.251+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on eb021f2c8a8b:35921 (size: 49.2 KiB, free: 434.0 MiB)
[2025-11-12T22:19:01.251+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:01.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[87] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:01.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
[2025-11-12T22:19:01.259+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 28) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:01.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_26_piece0 on eb021f2c8a8b:35921 in memory (size: 29.4 KiB, free: 434.0 MiB)
[2025-11-12T22:19:01.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.18.0.5:40603 in memory (size: 29.4 KiB, free: 434.2 MiB)
[2025-11-12T22:19:01.264+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.18.0.5:45133 in memory (size: 29.4 KiB, free: 434.1 MiB)
[2025-11-12T22:19:01.269+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_22_piece0 on eb021f2c8a8b:35921 in memory (size: 20.4 KiB, free: 434.0 MiB)
[2025-11-12T22:19:01.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.18.0.5:45133 in memory (size: 20.4 KiB, free: 434.1 MiB)
[2025-11-12T22:19:01.273+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.18.0.5:45133 (size: 49.2 KiB, free: 434.0 MiB)
[2025-11-12T22:19:01.276+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_29_piece0 on eb021f2c8a8b:35921 in memory (size: 47.9 KiB, free: 434.1 MiB)
[2025-11-12T22:19:01.277+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.18.0.5:45133 in memory (size: 47.9 KiB, free: 434.1 MiB)
[2025-11-12T22:19:01.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_27_piece0 on eb021f2c8a8b:35921 in memory (size: 29.0 KiB, free: 434.1 MiB)
[2025-11-12T22:19:01.290+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.18.0.5:40603 in memory (size: 29.0 KiB, free: 434.2 MiB)
[2025-11-12T22:19:01.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 172.18.0.5:34294
[2025-11-12T22:19:01.329+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 28) in 71 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:01.330+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool
[2025-11-12T22:19:01.331+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: ShuffleMapStage 32 (count at NativeMethodAccessorImpl.java:0) finished in 0.087 s
[2025-11-12T22:19:01.331+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:01.331+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: running: Set()
[2025-11-12T22:19:01.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:01.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:01.353+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO CodeGenerator: Code generated in 5.647743 ms
[2025-11-12T22:19:01.365+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:01.367+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Got job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:01.367+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Final stage: ResultStage 37 (count at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:01.367+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
[2025-11-12T22:19:01.368+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:01.368+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[90] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:01.368+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 12.5 KiB, free 433.3 MiB)
[2025-11-12T22:19:01.370+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.3 MiB)
[2025-11-12T22:19:01.370+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on eb021f2c8a8b:35921 (size: 5.9 KiB, free: 434.1 MiB)
[2025-11-12T22:19:01.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:01.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[90] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:01.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
[2025-11-12T22:19:01.372+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 29) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:01.384+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.18.0.5:40603 (size: 5.9 KiB, free: 434.2 MiB)
[2025-11-12T22:19:01.389+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 172.18.0.5:34292
[2025-11-12T22:19:01.407+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 29) in 34 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:01.408+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-11-12T22:19:01.408+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: ResultStage 37 (count at NativeMethodAccessorImpl.java:0) finished in 0.040 s
[2025-11-12T22:19:01.409+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:01.409+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
[2025-11-12T22:19:01.409+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO DAGScheduler: Job 22 finished: count at NativeMethodAccessorImpl.java:0, took 0.042979 s
[2025-11-12T22:19:01.413+0000] {spark_submit.py:571} INFO - Preparing to score 21 match(es) where both rikishi have profiles
[2025-11-12T22:19:01.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_31_piece0 on eb021f2c8a8b:35921 in memory (size: 5.9 KiB, free: 434.1 MiB)
[2025-11-12T22:19:01.723+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:01 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.18.0.5:40603 in memory (size: 5.9 KiB, free: 434.2 MiB)
[2025-11-12T22:19:02.089+0000] {spark_submit.py:571} INFO - Rows being sent to model.transform (sample):
[2025-11-12T22:19:02.404+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:02 INFO BlockManagerInfo: Removed broadcast_30_piece0 on eb021f2c8a8b:35921 in memory (size: 49.2 KiB, free: 434.1 MiB)
[2025-11-12T22:19:02.406+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:02 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.18.0.5:45133 in memory (size: 49.2 KiB, free: 434.1 MiB)
[2025-11-12T22:19:03.334+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_17_piece0 on eb021f2c8a8b:35921 in memory (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:03.335+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.5:40603 in memory (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:03.336+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.18.0.5:45133 in memory (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:03.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_24_piece0 on eb021f2c8a8b:35921 in memory (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:19:03.341+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.5:40603 in memory (size: 37.4 KiB, free: 434.3 MiB)
[2025-11-12T22:19:03.342+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.18.0.5:45133 in memory (size: 37.4 KiB, free: 434.2 MiB)
[2025-11-12T22:19:03.345+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_28_piece0 on eb021f2c8a8b:35921 in memory (size: 108.4 KiB, free: 434.3 MiB)
[2025-11-12T22:19:03.347+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.18.0.5:45133 in memory (size: 108.4 KiB, free: 434.3 MiB)
[2025-11-12T22:19:03.352+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_20_piece0 on eb021f2c8a8b:35921 in memory (size: 178.0 B, free: 434.3 MiB)
[2025-11-12T22:19:03.353+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.18.0.5:40603 in memory (size: 178.0 B, free: 434.3 MiB)
[2025-11-12T22:19:03.357+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_25_piece0 on eb021f2c8a8b:35921 in memory (size: 37.4 KiB, free: 434.4 MiB)
[2025-11-12T22:19:03.358+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.18.0.5:40603 in memory (size: 37.4 KiB, free: 434.4 MiB)
[2025-11-12T22:19:03.359+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.18.0.5:45133 in memory (size: 37.4 KiB, free: 434.4 MiB)
[2025-11-12T22:19:03.367+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_23_piece0 on eb021f2c8a8b:35921 in memory (size: 46.9 KiB, free: 434.4 MiB)
[2025-11-12T22:19:03.368+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.5:45133 in memory (size: 46.9 KiB, free: 434.4 MiB)
[2025-11-12T22:19:03.369+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.18.0.5:40603 in memory (size: 46.9 KiB, free: 434.4 MiB)
[2025-11-12T22:19:03.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO MongoRelation: requiredColumns: id, filters:
[2025-11-12T22:19:03.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.871+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.872+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.872+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.872+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.873+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.876+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.876+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2408 = ) THEN false ELSE isnull(kimarite#2408) END OR CASE WHEN (kimarite#2408 = ) THEN true ELSE (kimarite#2408 = NA) END) THEN false ELSE CASE WHEN (kimarite#2408 = ) THEN true ELSE isnotnull(kimarite#2408) END END
[2025-11-12T22:19:03.879+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.879+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2862 = ) THEN false ELSE isnull(kimarite#2862) END OR CASE WHEN (kimarite#2862 = ) THEN true ELSE (kimarite#2862 = NA) END) THEN false ELSE CASE WHEN (kimarite#2862 = ) THEN true ELSE isnotnull(kimarite#2862) END END
[2025-11-12T22:19:03.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:03.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:03.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.883+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4728 = ) THEN false ELSE isnull(kimarite#4728) END OR CASE WHEN (kimarite#4728 = ) THEN true ELSE (kimarite#4728 = NA) END) THEN false ELSE CASE WHEN (kimarite#4728 = ) THEN true ELSE isnotnull(kimarite#4728) END END
[2025-11-12T22:19:03.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4932 = ) THEN false ELSE isnull(kimarite#4932) END OR CASE WHEN (kimarite#4932 = ) THEN true ELSE (kimarite#4932 = NA) END) THEN false ELSE CASE WHEN (kimarite#4932 = ) THEN true ELSE isnotnull(kimarite#4932) END END
[2025-11-12T22:19:03.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:03.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:03.891+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.891+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4043 = ) THEN false ELSE isnull(kimarite#4043) END OR CASE WHEN (kimarite#4043 = ) THEN true ELSE (kimarite#4043 = NA) END) THEN false ELSE CASE WHEN (kimarite#4043 = ) THEN true ELSE isnotnull(kimarite#4043) END END
[2025-11-12T22:19:03.891+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.891+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4247 = ) THEN false ELSE isnull(kimarite#4247) END OR CASE WHEN (kimarite#4247 = ) THEN true ELSE (kimarite#4247 = NA) END) THEN false ELSE CASE WHEN (kimarite#4247 = ) THEN true ELSE isnotnull(kimarite#4247) END END
[2025-11-12T22:19:03.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7767 = ) THEN false ELSE isnull(kimarite#7767) END OR CASE WHEN (kimarite#7767 = ) THEN true ELSE (kimarite#7767 = NA) END) THEN false ELSE CASE WHEN (kimarite#7767 = ) THEN true ELSE isnotnull(kimarite#7767) END END
[2025-11-12T22:19:03.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.904+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7971 = ) THEN false ELSE isnull(kimarite#7971) END OR CASE WHEN (kimarite#7971 = ) THEN true ELSE (kimarite#7971 = NA) END) THEN false ELSE CASE WHEN (kimarite#7971 = ) THEN true ELSE isnotnull(kimarite#7971) END END
[2025-11-12T22:19:03.906+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:03.906+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:03.907+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.907+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#9603 = ) THEN false ELSE isnull(kimarite#9603) END OR CASE WHEN (kimarite#9603 = ) THEN true ELSE (kimarite#9603 = NA) END) THEN false ELSE CASE WHEN (kimarite#9603 = ) THEN true ELSE isnotnull(kimarite#9603) END END
[2025-11-12T22:19:03.910+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.910+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#9807 = ) THEN false ELSE isnull(kimarite#9807) END OR CASE WHEN (kimarite#9807 = ) THEN true ELSE (kimarite#9807 = NA) END) THEN false ELSE CASE WHEN (kimarite#9807 = ) THEN true ELSE isnotnull(kimarite#9807) END END
[2025-11-12T22:19:03.911+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:03.911+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:03.915+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#10215 = ) THEN false ELSE isnull(kimarite#10215) END OR CASE WHEN (kimarite#10215 = ) THEN true ELSE (kimarite#10215 = NA) END) THEN false ELSE CASE WHEN (kimarite#10215 = ) THEN true ELSE isnotnull(kimarite#10215) END END
[2025-11-12T22:19:03.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#10419 = ) THEN false ELSE isnull(kimarite#10419) END OR CASE WHEN (kimarite#10419 = ) THEN true ELSE (kimarite#10419 = NA) END) THEN false ELSE CASE WHEN (kimarite#10419 = ) THEN true ELSE isnotnull(kimarite#10419) END END
[2025-11-12T22:19:03.921+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.922+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.922+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.923+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.923+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.923+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.926+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.926+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11315 = ) THEN false ELSE isnull(kimarite#11315) END OR CASE WHEN (kimarite#11315 = ) THEN true ELSE (kimarite#11315 = NA) END) THEN false ELSE CASE WHEN (kimarite#11315 = ) THEN true ELSE isnotnull(kimarite#11315) END END
[2025-11-12T22:19:03.929+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.929+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11519 = ) THEN false ELSE isnull(kimarite#11519) END OR CASE WHEN (kimarite#11519 = ) THEN true ELSE (kimarite#11519 = NA) END) THEN false ELSE CASE WHEN (kimarite#11519 = ) THEN true ELSE isnotnull(kimarite#11519) END END
[2025-11-12T22:19:03.931+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:03.931+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:03.931+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.932+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11927 = ) THEN false ELSE isnull(kimarite#11927) END OR CASE WHEN (kimarite#11927 = ) THEN true ELSE (kimarite#11927 = NA) END) THEN false ELSE CASE WHEN (kimarite#11927 = ) THEN true ELSE isnotnull(kimarite#11927) END END
[2025-11-12T22:19:03.933+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.934+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#12131 = ) THEN false ELSE isnull(kimarite#12131) END OR CASE WHEN (kimarite#12131 = ) THEN true ELSE (kimarite#12131 = NA) END) THEN false ELSE CASE WHEN (kimarite#12131 = ) THEN true ELSE isnotnull(kimarite#12131) END END
[2025-11-12T22:19:03.935+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:03.935+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:03.937+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#12539 = ) THEN false ELSE isnull(kimarite#12539) END OR CASE WHEN (kimarite#12539 = ) THEN true ELSE (kimarite#12539 = NA) END) THEN false ELSE CASE WHEN (kimarite#12539 = ) THEN true ELSE isnotnull(kimarite#12539) END END
[2025-11-12T22:19:03.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#12743 = ) THEN false ELSE isnull(kimarite#12743) END OR CASE WHEN (kimarite#12743 = ) THEN true ELSE (kimarite#12743 = NA) END) THEN false ELSE CASE WHEN (kimarite#12743 = ) THEN true ELSE isnotnull(kimarite#12743) END END
[2025-11-12T22:19:03.940+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:03.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14375 = ) THEN false ELSE isnull(kimarite#14375) END OR CASE WHEN (kimarite#14375 = ) THEN true ELSE (kimarite#14375 = NA) END) THEN false ELSE CASE WHEN (kimarite#14375 = ) THEN true ELSE isnotnull(kimarite#14375) END END
[2025-11-12T22:19:03.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14579 = ) THEN false ELSE isnull(kimarite#14579) END OR CASE WHEN (kimarite#14579 = ) THEN true ELSE (kimarite#14579 = NA) END) THEN false ELSE CASE WHEN (kimarite#14579 = ) THEN true ELSE isnotnull(kimarite#14579) END END
[2025-11-12T22:19:03.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:03.950+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:03.950+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.951+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16211 = ) THEN false ELSE isnull(kimarite#16211) END OR CASE WHEN (kimarite#16211 = ) THEN true ELSE (kimarite#16211 = NA) END) THEN false ELSE CASE WHEN (kimarite#16211 = ) THEN true ELSE isnotnull(kimarite#16211) END END
[2025-11-12T22:19:03.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.954+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16415 = ) THEN false ELSE isnull(kimarite#16415) END OR CASE WHEN (kimarite#16415 = ) THEN true ELSE (kimarite#16415 = NA) END) THEN false ELSE CASE WHEN (kimarite#16415 = ) THEN true ELSE isnotnull(kimarite#16415) END END
[2025-11-12T22:19:03.954+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:03.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:03.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16823 = ) THEN false ELSE isnull(kimarite#16823) END OR CASE WHEN (kimarite#16823 = ) THEN true ELSE (kimarite#16823 = NA) END) THEN false ELSE CASE WHEN (kimarite#16823 = ) THEN true ELSE isnotnull(kimarite#16823) END END
[2025-11-12T22:19:03.958+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:03.958+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:03 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#17027 = ) THEN false ELSE isnull(kimarite#17027) END OR CASE WHEN (kimarite#17027 = ) THEN true ELSE (kimarite#17027 = NA) END) THEN false ELSE CASE WHEN (kimarite#17027 = ) THEN true ELSE isnotnull(kimarite#17027) END END
[2025-11-12T22:19:04.175+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: Registering RDD 95 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 9
[2025-11-12T22:19:04.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: Got map stage job 23 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:04.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: Final stage: ShuffleMapStage 38 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:04.179+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:04.182+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:04.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[95] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:04.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 16.8 KiB, free 434.4 MiB)
[2025-11-12T22:19:04.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.4 MiB)
[2025-11-12T22:19:04.185+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on eb021f2c8a8b:35921 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:19:04.185+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:04.185+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[95] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:04.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO TaskSchedulerImpl: Adding task set 38.0 with 2 tasks resource profile 0
[2025-11-12T22:19:04.187+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 30) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 11355 bytes)
[2025-11-12T22:19:04.187+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 31) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11479 bytes)
[2025-11-12T22:19:04.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=sumo.jrywipx.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='atlas-efvaxv-shard-0'}
[2025-11-12T22:19:04.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO MongoClientCache: Creating MongoClient: []
[2025-11-12T22:19:04.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Cluster description not yet available. Waiting for 30000 ms before timing out
[2025-11-12T22:19:04.193+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:19:04.195+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:19:04.196+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:19:04.196+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: No server chosen by com.mongodb.client.internal.MongoClientDelegate$1@77cf26c from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 30000 ms before timing out
[2025-11-12T22:19:04.201+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.5:45133 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:19:04.202+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.18.0.5:40603 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:19:04.268+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 30) in 82 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:19:04.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 31) in 83 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:19:04.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool
[2025-11-12T22:19:04.272+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: ShuffleMapStage 38 (showString at NativeMethodAccessorImpl.java:0) finished in 0.095 s
[2025-11-12T22:19:04.273+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:04.273+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: running: Set()
[2025-11-12T22:19:04.273+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:04.274+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:04.537+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO connection: Opened connection [connectionId{localValue:10, serverValue:101730}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:19:04.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO connection: Opened connection [connectionId{localValue:11, serverValue:98851}] to ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017
[2025-11-12T22:19:04.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO connection: Opened connection [connectionId{localValue:9, serverValue:108309}] to ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017
[2025-11-12T22:19:04.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=43555078, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:19:04 UTC 2025, lastUpdateTimeNanos=6865989404328}
[2025-11-12T22:19:04.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: No server chosen by ReadPreferenceServerSelector{readPreference=primary} from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=43555078, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:19:04 UTC 2025, lastUpdateTimeNanos=6865989404328}]}. Waiting for 30000 ms before timing out
[2025-11-12T22:19:04.591+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=53727117, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az3'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff0000000000000045, setVersion=7, lastWriteDate=Wed Nov 12 22:19:04 UTC 2025, lastUpdateTimeNanos=6865999514364}
[2025-11-12T22:19:04.591+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Setting max election id to 7fffffff0000000000000045 from replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:19:04.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Setting max set version to 7 from replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:19:04.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Discovered replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:19:04.596+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=59008644, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az1'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:19:04 UTC 2025, lastUpdateTimeNanos=6866004829394}
[2025-11-12T22:19:04.909+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:04 INFO connection: Opened connection [connectionId{localValue:12, serverValue:101784}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:19:05.094+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Registering RDD 97 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 10
[2025-11-12T22:19:05.095+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Got map stage job 24 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:05.095+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Final stage: ShuffleMapStage 39 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:05.096+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:05.096+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:05.096+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[97] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:05.096+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 28.2 KiB, free 434.3 MiB)
[2025-11-12T22:19:05.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 13.2 KiB, free 434.3 MiB)
[2025-11-12T22:19:05.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on eb021f2c8a8b:35921 (size: 13.2 KiB, free: 434.4 MiB)
[2025-11-12T22:19:05.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:05.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[97] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:05.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-11-12T22:19:05.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 32) (172.18.0.5, executor 1, partition 0, ANY, 10279 bytes)
[2025-11-12T22:19:05.103+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO CodeGenerator: Code generated in 6.737892 ms
[2025-11-12T22:19:05.106+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 221.4 KiB, free 434.1 MiB)
[2025-11-12T22:19:05.107+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.18.0.5:40603 (size: 13.2 KiB, free: 434.4 MiB)
[2025-11-12T22:19:05.111+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 434.1 MiB)
[2025-11-12T22:19:05.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:05.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO SparkContext: Created broadcast 34 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:05.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:05.126+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO CodeGenerator: Code generated in 7.921942 ms
[2025-11-12T22:19:05.129+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 221.4 KiB, free 433.9 MiB)
[2025-11-12T22:19:05.133+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.8 MiB)
[2025-11-12T22:19:05.134+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:05.134+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO SparkContext: Created broadcast 35 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:05.134+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:05.137+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Registering RDD 105 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 11
[2025-11-12T22:19:05.138+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Got map stage job 25 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:19:05.138+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:05.139+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:05.139+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:05.139+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[105] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:05.140+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 26.9 KiB, free 433.8 MiB)
[2025-11-12T22:19:05.141+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 433.8 MiB)
[2025-11-12T22:19:05.141+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on eb021f2c8a8b:35921 (size: 9.5 KiB, free: 434.3 MiB)
[2025-11-12T22:19:05.141+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:05.142+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[105] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:19:05.142+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO TaskSchedulerImpl: Adding task set 40.0 with 4 tasks resource profile 0
[2025-11-12T22:19:05.142+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 33) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:19:05.152+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.18.0.5:45133 (size: 9.5 KiB, free: 434.4 MiB)
[2025-11-12T22:19:05.173+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO CodeGenerator: Code generated in 27.629596 ms
[2025-11-12T22:19:05.176+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 221.4 KiB, free 433.6 MiB)
[2025-11-12T22:19:05.181+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:05.182+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.5 MiB)
[2025-11-12T22:19:05.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:05.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO SparkContext: Created broadcast 37 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:05.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:05.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Registering RDD 109 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 12
[2025-11-12T22:19:05.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Got map stage job 26 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:05.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:05.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:05.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:05.191+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[109] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:05.191+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 52.1 KiB, free 433.5 MiB)
[2025-11-12T22:19:05.192+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 433.5 MiB)
[2025-11-12T22:19:05.192+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on eb021f2c8a8b:35921 (size: 22.1 KiB, free: 434.2 MiB)
[2025-11-12T22:19:05.192+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:05.192+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[109] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:05.193+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO TaskSchedulerImpl: Adding task set 41.0 with 2 tasks resource profile 0
[2025-11-12T22:19:05.209+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO CodeGenerator: Code generated in 16.65132 ms
[2025-11-12T22:19:05.211+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 221.4 KiB, free 433.3 MiB)
[2025-11-12T22:19:05.216+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.2 MiB)
[2025-11-12T22:19:05.217+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:05.217+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO SparkContext: Created broadcast 39 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:05.218+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:05.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Registering RDD 113 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 13
[2025-11-12T22:19:05.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Got map stage job 27 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:05.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Final stage: ShuffleMapStage 42 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:05.224+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:05.224+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:05.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[113] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:05.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 43.7 KiB, free 433.2 MiB)
[2025-11-12T22:19:05.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 433.2 MiB)
[2025-11-12T22:19:05.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on eb021f2c8a8b:35921 (size: 18.9 KiB, free: 434.2 MiB)
[2025-11-12T22:19:05.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:05.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[113] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:05.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO TaskSchedulerImpl: Adding task set 42.0 with 2 tasks resource profile 0
[2025-11-12T22:19:05.254+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:05.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:05.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:05.259+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:05.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:05.261+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:05.264+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:05.265+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:05.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:05.272+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:05.274+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:05.274+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:05.278+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:05.278+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:05.281+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:05.282+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:05.283+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:05.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:05.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:05.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:05.291+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:05.291+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:05.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:05.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:05.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 34) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:19:05.717+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 32) in 619 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:05.717+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-11-12T22:19:05.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: ShuffleMapStage 39 (showString at NativeMethodAccessorImpl.java:0) finished in 0.622 s
[2025-11-12T22:19:05.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:05.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: running: Set(ShuffleMapStage 42, ShuffleMapStage 40, ShuffleMapStage 41)
[2025-11-12T22:19:05.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:05.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:05.726+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.18.0.5:40603 (size: 9.5 KiB, free: 434.4 MiB)
[2025-11-12T22:19:05.740+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Removed broadcast_32_piece0 on eb021f2c8a8b:35921 in memory (size: 8.7 KiB, free: 434.2 MiB)
[2025-11-12T22:19:05.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.5:40603 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:19:05.742+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.18.0.5:45133 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-12T22:19:05.745+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Removed broadcast_33_piece0 on eb021f2c8a8b:35921 in memory (size: 13.2 KiB, free: 434.2 MiB)
[2025-11-12T22:19:05.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.18.0.5:40603 in memory (size: 13.2 KiB, free: 434.4 MiB)
[2025-11-12T22:19:05.747+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:05.747+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:05.751+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 434.4 MiB)
[2025-11-12T22:19:05.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:05.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:05.753+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:05.754+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:05.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:05.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:05.761+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:05.761+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:05.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:05.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:05.770+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:05.771+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:05.774+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:05.774+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:05.776+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:05.776+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:05.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:05.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:05.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:05.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:05.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:05.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:05.847+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:05.912+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:05.913+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Got job 28 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:19:05.913+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Final stage: ResultStage 44 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:05.913+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
[2025-11-12T22:19:05.914+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:05.914+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[115] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:05.915+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 8.2 KiB, free 433.2 MiB)
[2025-11-12T22:19:05.915+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 433.2 MiB)
[2025-11-12T22:19:05.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on eb021f2c8a8b:35921 (size: 4.2 KiB, free: 434.2 MiB)
[2025-11-12T22:19:05.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:05.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[115] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:05.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:05 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
[2025-11-12T22:19:07.723+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:07 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 35) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:19:07.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:07 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 33) in 2581 ms on 172.18.0.5 (executor 0) (1/4)
[2025-11-12T22:19:07.740+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:07 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:08.040+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:08 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 36) (172.18.0.5, executor 1, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:19:08.041+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:08 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 34) in 2326 ms on 172.18.0.5 (executor 1) (2/4)
[2025-11-12T22:19:08.059+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:08 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:09.883+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:09 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 37) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:19:09.884+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:09 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 35) in 2160 ms on 172.18.0.5 (executor 0) (3/4)
[2025-11-12T22:19:09.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:09 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.18.0.5:45133 (size: 22.1 KiB, free: 434.3 MiB)
[2025-11-12T22:19:09.992+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:09 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:10.015+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO TaskSetManager: Starting task 1.0 in stage 41.0 (TID 38) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:19:10.016+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 36) in 1975 ms on 172.18.0.5 (executor 1) (4/4)
[2025-11-12T22:19:10.017+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-11-12T22:19:10.018+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: ShuffleMapStage 40 (showString at NativeMethodAccessorImpl.java:0) finished in 4.877 s
[2025-11-12T22:19:10.019+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:10.019+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: running: Set(ShuffleMapStage 42, ResultStage 44, ShuffleMapStage 41)
[2025-11-12T22:19:10.019+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:10.020+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:10.033+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.18.0.5:40603 (size: 22.1 KiB, free: 434.3 MiB)
[2025-11-12T22:19:10.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:10.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:10.044+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:10.045+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:10.049+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:10.051+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:10.054+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:10.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:10.063+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:10.064+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:10.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:10.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:10.071+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:10.072+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:10.077+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:10.078+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:10.082+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:10.083+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:10.087+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:10.088+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:10.095+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:10.096+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:10.099+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:10.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:10.152+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO MongoClientCache: Closing MongoClient: [ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017,ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017,ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017]
[2025-11-12T22:19:10.174+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:19:10.180+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:19:10.181+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:10.182+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:19:10.185+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO ShufflePartitionsUtil: For shuffle(11), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:19:10.198+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO connection: Closed connection [connectionId{localValue:12, serverValue:101784}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017 because the pool has been closed.
[2025-11-12T22:19:10.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO CodeGenerator: Code generated in 31.380258 ms
[2025-11-12T22:19:10.335+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO CodeGenerator: Code generated in 12.840256 ms
[2025-11-12T22:19:10.363+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Registering RDD 120 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 14
[2025-11-12T22:19:10.364+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Got map stage job 29 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:10.365+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Final stage: ShuffleMapStage 46 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:10.366+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
[2025-11-12T22:19:10.366+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:10.367+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[120] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:10.369+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 63.5 KiB, free 433.1 MiB)
[2025-11-12T22:19:10.379+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 27.8 KiB, free 433.1 MiB)
[2025-11-12T22:19:10.381+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on eb021f2c8a8b:35921 (size: 27.8 KiB, free: 434.2 MiB)
[2025-11-12T22:19:10.382+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:10.383+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[120] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:10.384+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO TaskSchedulerImpl: Adding task set 46.0 with 2 tasks resource profile 0
[2025-11-12T22:19:10.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO CodeGenerator: Code generated in 59.62428 ms
[2025-11-12T22:19:10.450+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO CodeGenerator: Code generated in 10.559557 ms
[2025-11-12T22:19:10.466+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Registering RDD 125 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 15
[2025-11-12T22:19:10.467+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Got map stage job 30 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:10.467+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Final stage: ShuffleMapStage 47 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:10.468+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
[2025-11-12T22:19:10.468+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:10.469+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[125] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:10.476+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 64.7 KiB, free 433.1 MiB)
[2025-11-12T22:19:10.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 28.5 KiB, free 433.0 MiB)
[2025-11-12T22:19:10.478+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on eb021f2c8a8b:35921 (size: 28.5 KiB, free: 434.1 MiB)
[2025-11-12T22:19:10.479+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:10.480+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[125] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:10.480+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks resource profile 0
[2025-11-12T22:19:10.486+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:10.487+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:10.493+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:10.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:10.496+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:10.496+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:10.500+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:10.501+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:10.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO BlockManagerInfo: Removed broadcast_36_piece0 on eb021f2c8a8b:35921 in memory (size: 9.5 KiB, free: 434.2 MiB)
[2025-11-12T22:19:10.519+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.18.0.5:45133 in memory (size: 9.5 KiB, free: 434.3 MiB)
[2025-11-12T22:19:10.520+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:10.521+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:10.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.18.0.5:40603 in memory (size: 9.5 KiB, free: 434.3 MiB)
[2025-11-12T22:19:10.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:10.527+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:10.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:10.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:10.548+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:10.549+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:10.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:10.554+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:10.559+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:10.560+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:10.566+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:10.567+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:10.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:10.570+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:10 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:12.268+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 39) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:19:12.269+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 37) in 2385 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:19:12.278+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.18.0.5:45133 (size: 18.9 KiB, free: 434.3 MiB)
[2025-11-12T22:19:12.316+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:12.402+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 40) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:19:12.403+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO TaskSetManager: Finished task 1.0 in stage 41.0 (TID 38) in 2388 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:19:12.404+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool
[2025-11-12T22:19:12.404+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: ShuffleMapStage 41 (showString at NativeMethodAccessorImpl.java:0) finished in 7.214 s
[2025-11-12T22:19:12.404+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:12.405+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: running: Set(ShuffleMapStage 46, ShuffleMapStage 42, ShuffleMapStage 47, ResultStage 44)
[2025-11-12T22:19:12.405+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:12.406+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:12.412+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.18.0.5:40603 (size: 18.9 KiB, free: 434.3 MiB)
[2025-11-12T22:19:12.425+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:12.425+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:12.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:12.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:12.435+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:12.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:12.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:12.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:12.446+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:12.447+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:12.449+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:12.450+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:12.451+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:12.460+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:12.464+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:12.470+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:12.470+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:12.474+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:12.475+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:12.480+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:12.481+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:12.488+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:12.488+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:12.492+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:12.492+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:12.533+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.536+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.542+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.543+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.545+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.548+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.550+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.551+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.554+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.556+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:12.618+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:19:12.619+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:19:12.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO CodeGenerator: Code generated in 23.579621 ms
[2025-11-12T22:19:12.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: Registering RDD 129 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 16
[2025-11-12T22:19:12.661+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: Got map stage job 31 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:12.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: Final stage: ShuffleMapStage 49 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:12.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
[2025-11-12T22:19:12.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:12.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[129] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:12.664+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 70.6 KiB, free 433.0 MiB)
[2025-11-12T22:19:12.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 433.0 MiB)
[2025-11-12T22:19:12.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on eb021f2c8a8b:35921 (size: 28.0 KiB, free: 434.1 MiB)
[2025-11-12T22:19:12.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:12.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[129] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:12.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
[2025-11-12T22:19:12.679+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:12.680+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:12.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:12.683+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:12.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:12.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:12.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:12.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:12.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:12.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:12.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:12.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:12.696+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:12.697+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:12.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:12.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:12.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:12.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:12.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:12.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:12.711+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:12.711+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:12.713+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:12.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:14.406+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 41) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10152 bytes)
[2025-11-12T22:19:14.407+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 39) in 2138 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:19:14.414+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.18.0.5:45133 (size: 4.2 KiB, free: 434.2 MiB)
[2025-11-12T22:19:14.417+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 172.18.0.5:34294
[2025-11-12T22:19:14.427+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 42) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:14.428+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 41) in 22 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:14.428+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool
[2025-11-12T22:19:14.429+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: ResultStage 44 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 8.514 s
[2025-11-12T22:19:14.429+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:14.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
[2025-11-12T22:19:14.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Job 28 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 8.516411 s
[2025-11-12T22:19:14.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 178.0 B, free 433.0 MiB)
[2025-11-12T22:19:14.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on eb021f2c8a8b:35921 (size: 178.0 B, free: 434.1 MiB)
[2025-11-12T22:19:14.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO SparkContext: Created broadcast 45 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:14.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.18.0.5:45133 (size: 27.8 KiB, free: 434.2 MiB)
[2025-11-12T22:19:14.447+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:14.448+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:14.450+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:14.451+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:14.452+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:14.452+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:14.454+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:14.454+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:14.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:14.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:14.459+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:14.460+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:14.462+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.18.0.5:34294
[2025-11-12T22:19:14.464+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:14.465+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:14.470+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:14.471+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:14.472+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:14.473+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:14.475+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:14.476+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:14.481+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:14.484+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:14.484+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:14.485+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:14.507+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO ShufflePartitionsUtil: For shuffle(9), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:14.525+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 43) (172.18.0.5, executor 1, partition 1, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:14.531+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 40) in 2128 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:19:14.536+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-11-12T22:19:14.543+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: ShuffleMapStage 42 (showString at NativeMethodAccessorImpl.java:0) finished in 9.309 s
[2025-11-12T22:19:14.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:14.545+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: running: Set(ShuffleMapStage 49, ShuffleMapStage 46, ShuffleMapStage 47)
[2025-11-12T22:19:14.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:14.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:14.564+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.18.0.5:40603 (size: 27.8 KiB, free: 434.2 MiB)
[2025-11-12T22:19:14.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO CodeGenerator: Code generated in 8.093851 ms
[2025-11-12T22:19:14.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Registering RDD 132 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 17
[2025-11-12T22:19:14.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Got map stage job 32 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:14.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Final stage: ShuffleMapStage 51 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:14.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
[2025-11-12T22:19:14.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:14.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[132] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:14.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 15.8 KiB, free 433.0 MiB)
[2025-11-12T22:19:14.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 432.9 MiB)
[2025-11-12T22:19:14.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on eb021f2c8a8b:35921 (size: 7.6 KiB, free: 434.1 MiB)
[2025-11-12T22:19:14.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:14.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[132] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:14.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
[2025-11-12T22:19:14.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 172.18.0.5:34292
[2025-11-12T22:19:14.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:14.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:14.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:14.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:14.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:14.617+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:14.619+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:14.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:14.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:14.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:14.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:14.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:14.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:14.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:14.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:14.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:14.642+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:14.642+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:14.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:14.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:14.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:14.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:14.655+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:14.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:14.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:14.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:14.693+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:14.694+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:14.695+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:14.698+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:14.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:14.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:14.801+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO CodeGenerator: Code generated in 24.096843 ms
[2025-11-12T22:19:14.815+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:14.816+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Got job 33 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:19:14.817+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Final stage: ResultStage 53 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:14.817+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
[2025-11-12T22:19:14.821+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:14.821+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[135] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:14.824+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 45.4 KiB, free 432.9 MiB)
[2025-11-12T22:19:14.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 20.4 KiB, free 432.9 MiB)
[2025-11-12T22:19:14.834+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on eb021f2c8a8b:35921 (size: 20.4 KiB, free: 434.1 MiB)
[2025-11-12T22:19:14.836+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:14.836+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[135] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:14.837+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
[2025-11-12T22:19:14.927+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Removed broadcast_41_piece0 on eb021f2c8a8b:35921 in memory (size: 4.2 KiB, free: 434.1 MiB)
[2025-11-12T22:19:14.928+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.18.0.5:45133 in memory (size: 4.2 KiB, free: 434.2 MiB)
[2025-11-12T22:19:14.934+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Removed broadcast_38_piece0 on eb021f2c8a8b:35921 in memory (size: 22.1 KiB, free: 434.1 MiB)
[2025-11-12T22:19:14.937+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.18.0.5:45133 in memory (size: 22.1 KiB, free: 434.2 MiB)
[2025-11-12T22:19:14.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.18.0.5:40603 in memory (size: 22.1 KiB, free: 434.2 MiB)
[2025-11-12T22:19:14.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Removed broadcast_40_piece0 on eb021f2c8a8b:35921 in memory (size: 18.9 KiB, free: 434.1 MiB)
[2025-11-12T22:19:14.952+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.18.0.5:45133 in memory (size: 18.9 KiB, free: 434.2 MiB)
[2025-11-12T22:19:14.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:14 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.18.0.5:40603 in memory (size: 18.9 KiB, free: 434.2 MiB)
[2025-11-12T22:19:16.983+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:16 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 44) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:16.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:16 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 42) in 2556 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:19:16.991+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:16 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.18.0.5:45133 (size: 28.5 KiB, free: 434.2 MiB)
[2025-11-12T22:19:17.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 45) (172.18.0.5, executor 1, partition 1, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:17.057+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 43) in 2532 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:19:17.060+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-11-12T22:19:17.061+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: ShuffleMapStage 46 (showString at NativeMethodAccessorImpl.java:0) finished in 6.691 s
[2025-11-12T22:19:17.061+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:17.062+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: running: Set(ShuffleMapStage 51, ShuffleMapStage 49, ResultStage 53, ShuffleMapStage 47)
[2025-11-12T22:19:17.062+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:17.062+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:17.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.18.0.5:40603 (size: 28.5 KiB, free: 434.2 MiB)
[2025-11-12T22:19:17.083+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:17.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:17.088+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:17.089+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:17.089+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:17.090+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:17.093+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:17.094+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:17.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:17.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:17.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:17.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:17.105+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:17.106+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:17.110+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:17.110+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:17.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:17.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:17.116+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:17.116+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:17.120+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:17.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:17.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:17.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:17.151+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:19:17.153+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:19:17.204+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:19:17.214+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO CodeGenerator: Code generated in 7.62343 ms
[2025-11-12T22:19:17.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:17.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: Got job 34 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-11-12T22:19:17.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: Final stage: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:17.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
[2025-11-12T22:19:17.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:17.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[138] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:17.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 60.7 KiB, free 433.0 MiB)
[2025-11-12T22:19:17.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 26.3 KiB, free 432.9 MiB)
[2025-11-12T22:19:17.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on eb021f2c8a8b:35921 (size: 26.3 KiB, free: 434.1 MiB)
[2025-11-12T22:19:17.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:17.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[138] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:17.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:17 INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks resource profile 0
[2025-11-12T22:19:18.448+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 46) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:18.449+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 44) in 1465 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:19:18.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.18.0.5:45133 (size: 28.0 KiB, free: 434.2 MiB)
[2025-11-12T22:19:18.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 172.18.0.5:34294
[2025-11-12T22:19:18.634+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 47) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10138 bytes)
[2025-11-12T22:19:18.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 46) in 187 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:18.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool
[2025-11-12T22:19:18.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: ShuffleMapStage 49 (showString at NativeMethodAccessorImpl.java:0) finished in 5.973 s
[2025-11-12T22:19:18.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:18.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: running: Set(ShuffleMapStage 51, ResultStage 53, ResultStage 55, ShuffleMapStage 47)
[2025-11-12T22:19:18.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:18.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:18.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.18.0.5:45133 (size: 7.6 KiB, free: 434.2 MiB)
[2025-11-12T22:19:18.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 172.18.0.5:34294
[2025-11-12T22:19:18.654+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:18.655+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:18.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:18.660+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:18.661+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.18.0.5:45133 (size: 178.0 B, free: 434.2 MiB)
[2025-11-12T22:19:18.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:18.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:18.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:18.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:18.669+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:18.669+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:18.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:18.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:18.674+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:18.674+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:18.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:18.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:18.680+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:18.680+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:18.683+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:18.683+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:18.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 48) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:18.685+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 47) in 52 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:18.685+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool
[2025-11-12T22:19:18.685+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: ShuffleMapStage 51 (showString at NativeMethodAccessorImpl.java:0) finished in 4.101 s
[2025-11-12T22:19:18.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:18.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: running: Set(ResultStage 53, ResultStage 55, ShuffleMapStage 47)
[2025-11-12T22:19:18.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:18.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:18.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:18.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:18.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:18.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:18.693+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.18.0.5:45133 (size: 20.4 KiB, free: 434.1 MiB)
[2025-11-12T22:19:18.699+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 172.18.0.5:34294
[2025-11-12T22:19:18.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.712+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.715+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.717+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.719+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 49) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:18.727+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 45) in 1670 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:19:18.728+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool
[2025-11-12T22:19:18.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: ShuffleMapStage 47 (showString at NativeMethodAccessorImpl.java:0) finished in 8.254 s
[2025-11-12T22:19:18.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:18.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: running: Set(ResultStage 53, ResultStage 55)
[2025-11-12T22:19:18.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:18.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:18.731+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.737+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.18.0.5:40603 (size: 26.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:18.739+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 50) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:18.740+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 48) in 56 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:18.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool
[2025-11-12T22:19:18.743+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: ResultStage 53 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 3.921 s
[2025-11-12T22:19:18.744+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.745+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:18.746+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
[2025-11-12T22:19:18.747+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Job 33 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 3.928102 s
[2025-11-12T22:19:18.747+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.748+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.18.0.5:34292
[2025-11-12T22:19:18.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:18.760+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 432.9 MiB)
[2025-11-12T22:19:18.761+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.18.0.5:45133 (size: 26.3 KiB, free: 434.1 MiB)
[2025-11-12T22:19:18.762+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on eb021f2c8a8b:35921 (size: 47.0 KiB, free: 434.1 MiB)
[2025-11-12T22:19:18.763+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO SparkContext: Created broadcast 49 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:18.770+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 172.18.0.5:34294
[2025-11-12T22:19:18.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Removed broadcast_44_piece0 on eb021f2c8a8b:35921 in memory (size: 28.0 KiB, free: 434.1 MiB)
[2025-11-12T22:19:18.793+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.18.0.5:45133 in memory (size: 28.0 KiB, free: 434.1 MiB)
[2025-11-12T22:19:18.800+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Removed broadcast_46_piece0 on eb021f2c8a8b:35921 in memory (size: 7.6 KiB, free: 434.1 MiB)
[2025-11-12T22:19:18.803+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.18.0.5:45133 in memory (size: 7.6 KiB, free: 434.2 MiB)
[2025-11-12T22:19:18.806+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Removed broadcast_47_piece0 on eb021f2c8a8b:35921 in memory (size: 20.4 KiB, free: 434.1 MiB)
[2025-11-12T22:19:18.821+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.18.0.5:45133 in memory (size: 20.4 KiB, free: 434.2 MiB)
[2025-11-12T22:19:18.859+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO CodeGenerator: Code generated in 12.720151 ms
[2025-11-12T22:19:18.860+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO CodeGenerator: Code generated in 12.619846 ms
[2025-11-12T22:19:18.863+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:18.865+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:18.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:18.870+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:18.872+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:18.872+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:18.873+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:18.874+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:18.874+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:18.874+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:18.875+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:18.875+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:18.875+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:18.876+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:18.876+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:18.876+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:18.877+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Got job 35 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:19:18.878+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:18.878+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Final stage: ResultStage 58 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:18.879+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
[2025-11-12T22:19:18.879+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:18.880+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:18.881+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[144] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:18.881+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:18.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:18.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:18.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:18.883+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 67.3 KiB, free 433.0 MiB)
[2025-11-12T22:19:18.883+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:18.884+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:18.884+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:18.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:18.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 433.0 MiB)
[2025-11-12T22:19:18.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on eb021f2c8a8b:35921 (size: 27.2 KiB, free: 434.1 MiB)
[2025-11-12T22:19:18.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:18.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[144] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:18.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
[2025-11-12T22:19:18.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Got job 36 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:19:18.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Final stage: ResultStage 59 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:18.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
[2025-11-12T22:19:18.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:18.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[146] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:18.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 70.2 KiB, free 432.9 MiB)
[2025-11-12T22:19:18.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 432.9 MiB)
[2025-11-12T22:19:18.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on eb021f2c8a8b:35921 (size: 27.9 KiB, free: 434.1 MiB)
[2025-11-12T22:19:18.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:18.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[146] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:18.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0
[2025-11-12T22:19:18.910+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:19:18.912+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:19:18.956+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added taskresult_49 in memory on 172.18.0.5:40603 (size: 1231.5 KiB, free: 433.0 MiB)
[2025-11-12T22:19:18.962+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added taskresult_50 in memory on 172.18.0.5:45133 (size: 1257.6 KiB, free: 432.9 MiB)
[2025-11-12T22:19:18.964+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:19:18.964+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 51) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:18.970+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 52) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:18.977+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.18.0.5:40603 (size: 27.2 KiB, free: 432.9 MiB)
[2025-11-12T22:19:18.980+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO CodeGenerator: Code generated in 12.886458 ms
[2025-11-12T22:19:18.983+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.18.0.5:45133 (size: 27.9 KiB, free: 432.9 MiB)
[2025-11-12T22:19:18.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TransportClientFactory: Successfully created connection to /172.18.0.5:45133 after 2 ms (0 ms spent in bootstraps)
[2025-11-12T22:19:18.988+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO TransportClientFactory: Successfully created connection to /172.18.0.5:40603 after 2 ms (0 ms spent in bootstraps)
[2025-11-12T22:19:19.000+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:18 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:19.002+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Got job 37 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-11-12T22:19:19.002+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Final stage: ResultStage 61 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:19.003+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
[2025-11-12T22:19:19.003+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:19.003+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[149] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:19.004+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.18.0.5:34294
[2025-11-12T22:19:19.009+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to 172.18.0.5:34292
[2025-11-12T22:19:19.010+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 61.9 KiB, free 432.8 MiB)
[2025-11-12T22:19:19.011+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 26.8 KiB, free 432.8 MiB)
[2025-11-12T22:19:19.011+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on eb021f2c8a8b:35921 (size: 26.8 KiB, free: 434.0 MiB)
[2025-11-12T22:19:19.013+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:19.015+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 61 (MapPartitionsRDD[149] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:19.016+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Adding task set 61.0 with 2 tasks resource profile 0
[2025-11-12T22:19:19.022+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 50) in 283 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:19:19.023+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 49) in 298 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:19:19.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-11-12T22:19:19.029+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: ResultStage 55 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.800 s
[2025-11-12T22:19:19.032+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:19.034+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
[2025-11-12T22:19:19.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Job 34 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.803440 s
[2025-11-12T22:19:19.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed taskresult_50 on 172.18.0.5:45133 in memory (size: 1257.6 KiB, free: 434.1 MiB)
[2025-11-12T22:19:19.036+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed taskresult_49 on 172.18.0.5:40603 in memory (size: 1231.5 KiB, free: 434.1 MiB)
[2025-11-12T22:19:19.036+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO CodeGenerator: Code generated in 5.782051 ms
[2025-11-12T22:19:19.140+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 53) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:19.144+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 54) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:19.146+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 51) in 182 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:19.147+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool
[2025-11-12T22:19:19.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: ResultStage 58 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.267 s
[2025-11-12T22:19:19.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 52) in 177 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:19.149+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:19.152+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool
[2025-11-12T22:19:19.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
[2025-11-12T22:19:19.155+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Job 35 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.273207 s
[2025-11-12T22:19:19.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: ResultStage 59 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.258 s
[2025-11-12T22:19:19.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:19.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
[2025-11-12T22:19:19.157+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Job 36 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.272534 s
[2025-11-12T22:19:19.164+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 432.7 MiB)
[2025-11-12T22:19:19.166+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on eb021f2c8a8b:35921 (size: 90.5 KiB, free: 434.0 MiB)
[2025-11-12T22:19:19.167+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 54 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:19.168+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 56.1 KiB, free 432.7 MiB)
[2025-11-12T22:19:19.168+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on eb021f2c8a8b:35921 (size: 56.1 KiB, free: 433.9 MiB)
[2025-11-12T22:19:19.169+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 55 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:19.170+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_50_piece0 on eb021f2c8a8b:35921 in memory (size: 27.2 KiB, free: 433.9 MiB)
[2025-11-12T22:19:19.173+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.18.0.5:40603 (size: 26.8 KiB, free: 434.1 MiB)
[2025-11-12T22:19:19.180+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.18.0.5:40603 in memory (size: 27.2 KiB, free: 434.1 MiB)
[2025-11-12T22:19:19.191+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_51_piece0 on eb021f2c8a8b:35921 in memory (size: 27.9 KiB, free: 434.0 MiB)
[2025-11-12T22:19:19.196+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.18.0.5:45133 (size: 26.8 KiB, free: 434.1 MiB)
[2025-11-12T22:19:19.197+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 428.8 MiB)
[2025-11-12T22:19:19.197+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.5:34292
[2025-11-12T22:19:19.198+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on eb021f2c8a8b:35921 (size: 4.0 MiB, free: 430.0 MiB)
[2025-11-12T22:19:19.198+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_53_piece1 stored as bytes in memory (estimated size 1048.4 KiB, free 427.8 MiB)
[2025-11-12T22:19:19.198+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.18.0.5:45133 in memory (size: 27.9 KiB, free: 434.1 MiB)
[2025-11-12T22:19:19.199+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_53_piece1 in memory on eb021f2c8a8b:35921 (size: 1048.4 KiB, free: 428.9 MiB)
[2025-11-12T22:19:19.199+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 53 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:19.206+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 172.18.0.5:34294
[2025-11-12T22:19:19.209+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:19.212+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:19.214+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:19.215+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:19.215+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:19.216+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:19.216+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:19.216+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:19.217+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:19.217+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:19.217+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:19.218+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:19.220+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:19.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:19.224+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:19.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:19.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:19.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:19.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:19.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:19.229+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:19.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:19.232+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:19.233+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:19.275+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:19.276+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:19.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:19.292+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:19.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:19.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:19.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_43_piece0 on eb021f2c8a8b:35921 in memory (size: 28.5 KiB, free: 429.0 MiB)
[2025-11-12T22:19:19.294+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.18.0.5:40603 in memory (size: 28.5 KiB, free: 434.2 MiB)
[2025-11-12T22:19:19.294+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.18.0.5:45133 in memory (size: 28.5 KiB, free: 434.2 MiB)
[2025-11-12T22:19:19.295+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:19.295+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:19.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_48_piece0 on eb021f2c8a8b:35921 in memory (size: 26.3 KiB, free: 429.0 MiB)
[2025-11-12T22:19:19.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:19.299+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:19.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:19.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:19.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.18.0.5:45133 in memory (size: 26.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:19.305+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.18.0.5:40603 in memory (size: 26.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:19.308+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:19.309+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:19.311+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:19.316+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:19.317+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:19.318+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:19.319+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:19.320+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:19.321+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_42_piece0 on eb021f2c8a8b:35921 in memory (size: 27.8 KiB, free: 429.0 MiB)
[2025-11-12T22:19:19.321+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.18.0.5:45133 in memory (size: 27.8 KiB, free: 434.2 MiB)
[2025-11-12T22:19:19.321+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:19.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:19.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.18.0.5:40603 in memory (size: 27.8 KiB, free: 434.2 MiB)
[2025-11-12T22:19:19.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:19.323+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:19.391+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added taskresult_53 in memory on 172.18.0.5:40603 (size: 1247.7 KiB, free: 433.0 MiB)
[2025-11-12T22:19:19.402+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 53) in 262 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:19:19.405+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed taskresult_53 on 172.18.0.5:40603 in memory (size: 1247.7 KiB, free: 434.2 MiB)
[2025-11-12T22:19:19.413+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added taskresult_54 in memory on 172.18.0.5:45133 (size: 1248.0 KiB, free: 433.0 MiB)
[2025-11-12T22:19:19.423+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 54) in 281 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:19:19.424+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool
[2025-11-12T22:19:19.425+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: ResultStage 61 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.417 s
[2025-11-12T22:19:19.425+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:19.426+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
[2025-11-12T22:19:19.426+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Job 37 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.423974 s
[2025-11-12T22:19:19.426+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Removed taskresult_54 on 172.18.0.5:45133 in memory (size: 1248.0 KiB, free: 434.2 MiB)
[2025-11-12T22:19:19.504+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO CodeGenerator: Code generated in 23.880134 ms
[2025-11-12T22:19:19.508+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 222.7 KiB, free 427.9 MiB)
[2025-11-12T22:19:19.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 427.8 MiB)
[2025-11-12T22:19:19.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on eb021f2c8a8b:35921 (size: 37.8 KiB, free: 429.0 MiB)
[2025-11-12T22:19:19.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 56 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:19.517+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:19.521+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Registering RDD 153 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 18
[2025-11-12T22:19:19.521+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Got map stage job 38 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:19.522+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:19.523+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:19.523+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:19.523+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[153] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:19.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 37.7 KiB, free 427.8 MiB)
[2025-11-12T22:19:19.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 427.8 MiB)
[2025-11-12T22:19:19.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on eb021f2c8a8b:35921 (size: 13.4 KiB, free: 429.0 MiB)
[2025-11-12T22:19:19.525+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:19.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[153] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:19.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Adding task set 62.0 with 2 tasks resource profile 0
[2025-11-12T22:19:19.526+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 55) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:19:19.527+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSetManager: Starting task 1.0 in stage 62.0 (TID 56) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:19:19.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 423.8 MiB)
[2025-11-12T22:19:19.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on eb021f2c8a8b:35921 (size: 4.0 MiB, free: 425.0 MiB)
[2025-11-12T22:19:19.531+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_57_piece1 stored as bytes in memory (estimated size 1054.7 KiB, free 422.8 MiB)
[2025-11-12T22:19:19.531+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_57_piece1 in memory on eb021f2c8a8b:35921 (size: 1054.7 KiB, free: 423.9 MiB)
[2025-11-12T22:19:19.532+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 57 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:19.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.18.0.5:45133 (size: 13.4 KiB, free: 434.2 MiB)
[2025-11-12T22:19:19.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.18.0.5:40603 (size: 13.4 KiB, free: 434.2 MiB)
[2025-11-12T22:19:19.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO CodeGenerator: Code generated in 19.070626 ms
[2025-11-12T22:19:19.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TorrentBroadcast: Started reading broadcast variable 49 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:19:19.548+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TorrentBroadcast: Reading broadcast variable 49 took 1 ms
[2025-11-12T22:19:19.555+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TorrentBroadcast: Started reading broadcast variable 55 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:19:19.556+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TorrentBroadcast: Reading broadcast variable 55 took 0 ms
[2025-11-12T22:19:19.567+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO CodeGenerator: Code generated in 7.613729 ms
[2025-11-12T22:19:19.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 221.3 KiB, free 422.5 MiB)
[2025-11-12T22:19:19.575+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 422.5 MiB)
[2025-11-12T22:19:19.577+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 423.9 MiB)
[2025-11-12T22:19:19.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 59 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:19.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:19.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.18.0.5:45133 (size: 4.0 MiB, free: 430.2 MiB)
[2025-11-12T22:19:19.591+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.18.0.5:40603 (size: 4.0 MiB, free: 430.2 MiB)
[2025-11-12T22:19:19.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_53_piece1 in memory on 172.18.0.5:45133 (size: 1048.4 KiB, free: 429.2 MiB)
[2025-11-12T22:19:19.599+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO CodeGenerator: Code generated in 9.764623 ms
[2025-11-12T22:19:19.600+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_53_piece1 in memory on 172.18.0.5:40603 (size: 1048.4 KiB, free: 429.2 MiB)
[2025-11-12T22:19:19.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 221.3 KiB, free 422.3 MiB)
[2025-11-12T22:19:19.608+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 422.2 MiB)
[2025-11-12T22:19:19.609+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 423.9 MiB)
[2025-11-12T22:19:19.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 60 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:19.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:19.619+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.18.0.5:45133 (size: 90.5 KiB, free: 429.1 MiB)
[2025-11-12T22:19:19.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.18.0.5:40603 (size: 90.5 KiB, free: 429.1 MiB)
[2025-11-12T22:19:19.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Registering RDD 162 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 19
[2025-11-12T22:19:19.627+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Got map stage job 39 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:19:19.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Final stage: ShuffleMapStage 63 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:19.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:19.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:19.630+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[162] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:19.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 120.4 KiB, free 422.1 MiB)
[2025-11-12T22:19:19.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.18.0.5:45133 (size: 56.1 KiB, free: 429.0 MiB)
[2025-11-12T22:19:19.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 43.7 KiB, free 422.1 MiB)
[2025-11-12T22:19:19.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on eb021f2c8a8b:35921 (size: 43.7 KiB, free: 423.8 MiB)
[2025-11-12T22:19:19.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:19.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[162] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:19:19.638+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Adding task set 63.0 with 4 tasks resource profile 0
[2025-11-12T22:19:19.638+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.18.0.5:40603 (size: 56.1 KiB, free: 429.0 MiB)
[2025-11-12T22:19:19.642+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.18.0.5:45133 (size: 37.8 KiB, free: 429.0 MiB)
[2025-11-12T22:19:19.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:19.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:19.645+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.18.0.5:40603 (size: 37.8 KiB, free: 429.0 MiB)
[2025-11-12T22:19:19.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:19.648+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:19.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TorrentBroadcast: Started reading broadcast variable 57 with 2 pieces (estimated total size 8.0 MiB)
[2025-11-12T22:19:19.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TorrentBroadcast: Reading broadcast variable 57 took 0 ms
[2025-11-12T22:19:19.713+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TorrentBroadcast: Started reading broadcast variable 54 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:19:19.713+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TorrentBroadcast: Reading broadcast variable 54 took 0 ms
[2025-11-12T22:19:19.756+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO CodeGenerator: Code generated in 35.179224 ms
[2025-11-12T22:19:19.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 222.7 KiB, free 421.9 MiB)
[2025-11-12T22:19:19.768+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 421.8 MiB)
[2025-11-12T22:19:19.769+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on eb021f2c8a8b:35921 (size: 37.8 KiB, free: 423.8 MiB)
[2025-11-12T22:19:19.770+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 62 from showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:19.770+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:19.775+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Registering RDD 166 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 20
[2025-11-12T22:19:19.776+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Got map stage job 40 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:19.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Final stage: ShuffleMapStage 64 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:19.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:19.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:19.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[166] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:19.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 37.7 KiB, free 421.8 MiB)
[2025-11-12T22:19:19.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 421.8 MiB)
[2025-11-12T22:19:19.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on eb021f2c8a8b:35921 (size: 13.5 KiB, free: 423.8 MiB)
[2025-11-12T22:19:19.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:19.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[166] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:19.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:19 INFO TaskSchedulerImpl: Adding task set 64.0 with 2 tasks resource profile 0
[2025-11-12T22:19:24.099+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:24 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 57) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:19:24.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:24 INFO TaskSetManager: Finished task 1.0 in stage 62.0 (TID 56) in 4573 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:19:24.107+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:24 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.18.0.5:45133 (size: 43.7 KiB, free: 429.0 MiB)
[2025-11-12T22:19:24.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:24 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.18.0.5:45133 (size: 47.0 KiB, free: 428.9 MiB)
[2025-11-12T22:19:24.171+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:24 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 428.9 MiB)
[2025-11-12T22:19:25.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 58) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:19:25.431+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 55) in 5905 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:19:25.431+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool
[2025-11-12T22:19:25.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO DAGScheduler: ShuffleMapStage 62 (showString at NativeMethodAccessorImpl.java:0) finished in 5.908 s
[2025-11-12T22:19:25.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:25.433+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO DAGScheduler: running: Set(ShuffleMapStage 63, ShuffleMapStage 64)
[2025-11-12T22:19:25.433+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:25.434+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:25.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.18.0.5:40603 (size: 43.7 KiB, free: 429.0 MiB)
[2025-11-12T22:19:25.467+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.18.0.5:40603 (size: 47.0 KiB, free: 428.9 MiB)
[2025-11-12T22:19:25.506+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 428.9 MiB)
[2025-11-12T22:19:25.533+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO TaskSetManager: Starting task 2.0 in stage 63.0 (TID 59) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:19:25.533+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 57) in 1435 ms on 172.18.0.5 (executor 0) (1/4)
[2025-11-12T22:19:25.557+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:25 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 428.8 MiB)
[2025-11-12T22:19:26.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:26 INFO TaskSetManager: Starting task 3.0 in stage 63.0 (TID 60) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:19:26.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:26 INFO TaskSetManager: Finished task 2.0 in stage 63.0 (TID 59) in 1055 ms on 172.18.0.5 (executor 0) (2/4)
[2025-11-12T22:19:27.251+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 61) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:19:27.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 58) in 1822 ms on 172.18.0.5 (executor 1) (3/4)
[2025-11-12T22:19:27.259+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.18.0.5:40603 (size: 13.5 KiB, free: 428.9 MiB)
[2025-11-12T22:19:27.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO BlockManagerInfo: Added broadcast_57_piece1 in memory on 172.18.0.5:40603 (size: 1054.7 KiB, free: 427.8 MiB)
[2025-11-12T22:19:27.297+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.18.0.5:40603 (size: 4.0 MiB, free: 423.8 MiB)
[2025-11-12T22:19:27.321+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.18.0.5:40603 (size: 37.8 KiB, free: 423.8 MiB)
[2025-11-12T22:19:27.914+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 62) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:19:27.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO TaskSetManager: Finished task 3.0 in stage 63.0 (TID 60) in 1328 ms on 172.18.0.5 (executor 0) (4/4)
[2025-11-12T22:19:27.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool
[2025-11-12T22:19:27.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO DAGScheduler: ShuffleMapStage 63 (showString at NativeMethodAccessorImpl.java:0) finished in 8.289 s
[2025-11-12T22:19:27.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:27.918+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO DAGScheduler: running: Set(ShuffleMapStage 64)
[2025-11-12T22:19:27.918+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:27.919+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:27.922+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.18.0.5:45133 (size: 13.5 KiB, free: 428.8 MiB)
[2025-11-12T22:19:27.936+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:27.937+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:27.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:27.940+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:27.943+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO BlockManagerInfo: Added broadcast_57_piece1 in memory on 172.18.0.5:45133 (size: 1054.7 KiB, free: 427.8 MiB)
[2025-11-12T22:19:27.959+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.18.0.5:45133 (size: 4.0 MiB, free: 423.8 MiB)
[2025-11-12T22:19:27.977+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:19:27.978+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:19:27.982+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.18.0.5:45133 (size: 37.8 KiB, free: 423.8 MiB)
[2025-11-12T22:19:27.998+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:27 INFO CodeGenerator: Code generated in 14.988749 ms
[2025-11-12T22:19:28.008+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO DAGScheduler: Registering RDD 170 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 21
[2025-11-12T22:19:28.009+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO DAGScheduler: Got map stage job 41 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:28.009+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO DAGScheduler: Final stage: ShuffleMapStage 66 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:28.009+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
[2025-11-12T22:19:28.010+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:28.010+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[170] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:28.012+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 133.5 KiB, free 421.7 MiB)
[2025-11-12T22:19:28.013+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 48.7 KiB, free 421.6 MiB)
[2025-11-12T22:19:28.014+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on eb021f2c8a8b:35921 (size: 48.7 KiB, free: 423.7 MiB)
[2025-11-12T22:19:28.014+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:28.014+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[170] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:28.014+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:28 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
[2025-11-12T22:19:32.472+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 63) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:32.474+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 62) in 4558 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:19:32.480+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.18.0.5:45133 (size: 48.7 KiB, free: 423.7 MiB)
[2025-11-12T22:19:32.489+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to 172.18.0.5:34294
[2025-11-12T22:19:32.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 63) in 184 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:32.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool
[2025-11-12T22:19:32.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: ShuffleMapStage 66 (showString at NativeMethodAccessorImpl.java:0) finished in 4.647 s
[2025-11-12T22:19:32.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:32.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: running: Set(ShuffleMapStage 64)
[2025-11-12T22:19:32.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:32.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:32.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:32.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:32.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:32.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO CodeGenerator: Code generated in 3.399947 ms
[2025-11-12T22:19:32.713+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:32.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: Got job 42 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:19:32.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: Final stage: ResultStage 69 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:32.715+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
[2025-11-12T22:19:32.715+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:32.715+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[174] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:32.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_61_piece0 on eb021f2c8a8b:35921 in memory (size: 43.7 KiB, free: 423.8 MiB)
[2025-11-12T22:19:32.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.18.0.5:45133 in memory (size: 43.7 KiB, free: 423.8 MiB)
[2025-11-12T22:19:32.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.18.0.5:40603 in memory (size: 43.7 KiB, free: 423.8 MiB)
[2025-11-12T22:19:32.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 119.0 KiB, free 421.7 MiB)
[2025-11-12T22:19:32.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 43.9 KiB, free 421.6 MiB)
[2025-11-12T22:19:32.731+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on eb021f2c8a8b:35921 (size: 43.9 KiB, free: 423.7 MiB)
[2025-11-12T22:19:32.731+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:32.732+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[174] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:32.732+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
[2025-11-12T22:19:32.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_58_piece0 on eb021f2c8a8b:35921 in memory (size: 13.4 KiB, free: 423.7 MiB)
[2025-11-12T22:19:32.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 64) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:32.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.18.0.5:40603 in memory (size: 13.4 KiB, free: 423.9 MiB)
[2025-11-12T22:19:32.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.18.0.5:45133 in memory (size: 13.4 KiB, free: 423.8 MiB)
[2025-11-12T22:19:32.738+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_64_piece0 on eb021f2c8a8b:35921 in memory (size: 48.7 KiB, free: 423.8 MiB)
[2025-11-12T22:19:32.739+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.18.0.5:45133 in memory (size: 48.7 KiB, free: 423.8 MiB)
[2025-11-12T22:19:32.741+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.18.0.5:45133 (size: 43.9 KiB, free: 423.8 MiB)
[2025-11-12T22:19:32.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to 172.18.0.5:34294
[2025-11-12T22:19:32.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 64) in 61 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:32.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-11-12T22:19:32.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: ResultStage 69 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.075 s
[2025-11-12T22:19:32.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:32.797+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
[2025-11-12T22:19:32.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO DAGScheduler: Job 42 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.082057 s
[2025-11-12T22:19:32.801+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 158.7 KiB, free 421.7 MiB)
[2025-11-12T22:19:32.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on eb021f2c8a8b:35921 (size: 158.7 KiB, free: 423.6 MiB)
[2025-11-12T22:19:32.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO SparkContext: Created broadcast 66 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:32.818+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_52_piece0 on eb021f2c8a8b:35921 in memory (size: 26.8 KiB, free: 423.7 MiB)
[2025-11-12T22:19:32.820+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.18.0.5:45133 in memory (size: 26.8 KiB, free: 423.8 MiB)
[2025-11-12T22:19:32.821+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:32 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.18.0.5:40603 in memory (size: 26.8 KiB, free: 423.9 MiB)
[2025-11-12T22:19:33.102+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 61) in 5851 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:19:33.103+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool
[2025-11-12T22:19:33.103+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: ShuffleMapStage 64 (showString at NativeMethodAccessorImpl.java:0) finished in 13.326 s
[2025-11-12T22:19:33.103+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:33.104+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: running: Set()
[2025-11-12T22:19:33.104+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:33.104+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:33.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 20896825, minimum partition size: 1048576
[2025-11-12T22:19:33.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 22743821, minimum partition size: 1048576
[2025-11-12T22:19:33.115+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO ShufflePartitionsUtil: For shuffle(18), advisory target size: 67108864, actual target size 20896825, minimum partition size: 1048576
[2025-11-12T22:19:33.116+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 22743821, minimum partition size: 1048576
[2025-11-12T22:19:33.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO CodeGenerator: Code generated in 3.772364 ms
[2025-11-12T22:19:33.160+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO CodeGenerator: Code generated in 7.467723 ms
[2025-11-12T22:19:33.172+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO CodeGenerator: Code generated in 6.689989 ms
[2025-11-12T22:19:33.182+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: Registering RDD 182 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 22
[2025-11-12T22:19:33.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: Got map stage job 43 (showString at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:33.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: Final stage: ShuffleMapStage 72 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:33.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70, ShuffleMapStage 71)
[2025-11-12T22:19:33.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:33.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[182] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:33.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 257.6 KiB, free 421.5 MiB)
[2025-11-12T22:19:33.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 86.6 KiB, free 421.4 MiB)
[2025-11-12T22:19:33.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on eb021f2c8a8b:35921 (size: 86.6 KiB, free: 423.6 MiB)
[2025-11-12T22:19:33.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:33.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[182] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:33.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO TaskSchedulerImpl: Adding task set 72.0 with 2 tasks resource profile 0
[2025-11-12T22:19:33.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 65) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10247 bytes)
[2025-11-12T22:19:33.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 66) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10247 bytes)
[2025-11-12T22:19:33.197+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.18.0.5:45133 (size: 86.6 KiB, free: 423.7 MiB)
[2025-11-12T22:19:33.198+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.18.0.5:40603 (size: 86.6 KiB, free: 423.8 MiB)
[2025-11-12T22:19:33.211+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to 172.18.0.5:34294
[2025-11-12T22:19:33.214+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to 172.18.0.5:34292
[2025-11-12T22:19:33.232+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.18.0.5:45133 (size: 158.7 KiB, free: 423.6 MiB)
[2025-11-12T22:19:33.235+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.18.0.5:40603 (size: 158.7 KiB, free: 423.6 MiB)
[2025-11-12T22:19:33.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:33 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 65) in 727 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:19:34.026+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 66) in 835 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:19:34.026+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-11-12T22:19:34.027+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: ShuffleMapStage 72 (showString at NativeMethodAccessorImpl.java:0) finished in 0.843 s
[2025-11-12T22:19:34.027+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:34.027+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: running: Set()
[2025-11-12T22:19:34.027+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:34.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:34.036+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:34.037+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:34.063+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO CodeGenerator: Code generated in 2.726018 ms
[2025-11-12T22:19:34.067+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO CodeGenerator: Code generated in 2.565311 ms
[2025-11-12T22:19:34.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:34.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Got job 44 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:19:34.085+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Final stage: ResultStage 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:34.085+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
[2025-11-12T22:19:34.085+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:34.086+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[188] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:34.090+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 240.5 KiB, free 421.2 MiB)
[2025-11-12T22:19:34.091+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 81.3 KiB, free 421.1 MiB)
[2025-11-12T22:19:34.091+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on eb021f2c8a8b:35921 (size: 81.3 KiB, free: 423.5 MiB)
[2025-11-12T22:19:34.091+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:34.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[188] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:34.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
[2025-11-12T22:19:34.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 67) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:34.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.18.0.5:45133 (size: 81.3 KiB, free: 423.5 MiB)
[2025-11-12T22:19:34.110+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to 172.18.0.5:34294
[2025-11-12T22:19:34.176+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 67) in 84 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:34.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-11-12T22:19:34.179+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: ResultStage 76 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.091 s
[2025-11-12T22:19:34.179+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:34.180+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
[2025-11-12T22:19:34.180+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Job 44 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.093497 s
[2025-11-12T22:19:34.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 350.0 KiB, free 420.8 MiB)
[2025-11-12T22:19:34.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on eb021f2c8a8b:35921 (size: 350.0 KiB, free: 423.1 MiB)
[2025-11-12T22:19:34.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO SparkContext: Created broadcast 69 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:34.191+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:34.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Removed broadcast_67_piece0 on eb021f2c8a8b:35921 in memory (size: 86.6 KiB, free: 423.2 MiB)
[2025-11-12T22:19:34.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.18.0.5:45133 in memory (size: 86.6 KiB, free: 423.6 MiB)
[2025-11-12T22:19:34.224+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.18.0.5:40603 in memory (size: 86.6 KiB, free: 423.7 MiB)
[2025-11-12T22:19:34.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Removed broadcast_68_piece0 on eb021f2c8a8b:35921 in memory (size: 81.3 KiB, free: 423.3 MiB)
[2025-11-12T22:19:34.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 172.18.0.5:45133 in memory (size: 81.3 KiB, free: 423.7 MiB)
[2025-11-12T22:19:34.230+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Removed broadcast_65_piece0 on eb021f2c8a8b:35921 in memory (size: 43.9 KiB, free: 423.4 MiB)
[2025-11-12T22:19:34.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.18.0.5:45133 in memory (size: 43.9 KiB, free: 423.7 MiB)
[2025-11-12T22:19:34.233+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Removed broadcast_63_piece0 on eb021f2c8a8b:35921 in memory (size: 13.5 KiB, free: 423.4 MiB)
[2025-11-12T22:19:34.234+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.18.0.5:45133 in memory (size: 13.5 KiB, free: 423.7 MiB)
[2025-11-12T22:19:34.234+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.18.0.5:40603 in memory (size: 13.5 KiB, free: 423.7 MiB)
[2025-11-12T22:19:34.238+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TorrentBroadcast: Started reading broadcast variable 69 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:19:34.238+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TorrentBroadcast: Reading broadcast variable 69 took 0 ms
[2025-11-12T22:19:34.277+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO CodeGenerator: Code generated in 22.797787 ms
[2025-11-12T22:19:34.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Registering RDD 191 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 23
[2025-11-12T22:19:34.294+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Got map stage job 45 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:34.295+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Final stage: ShuffleMapStage 79 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:34.295+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
[2025-11-12T22:19:34.296+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:34.296+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[191] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:34.303+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 366.9 KiB, free 421.3 MiB)
[2025-11-12T22:19:34.305+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 118.4 KiB, free 421.2 MiB)
[2025-11-12T22:19:34.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on eb021f2c8a8b:35921 (size: 118.4 KiB, free: 423.3 MiB)
[2025-11-12T22:19:34.306+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:34.307+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[191] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:34.307+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0
[2025-11-12T22:19:34.308+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 68) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10141 bytes)
[2025-11-12T22:19:34.319+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 172.18.0.5:40603 (size: 118.4 KiB, free: 423.6 MiB)
[2025-11-12T22:19:34.354+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to 172.18.0.5:34292
[2025-11-12T22:19:34.423+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.18.0.5:40603 (size: 350.0 KiB, free: 423.3 MiB)
[2025-11-12T22:19:34.501+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 68) in 192 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:34.501+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-11-12T22:19:34.502+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: ShuffleMapStage 79 (showString at NativeMethodAccessorImpl.java:0) finished in 0.208 s
[2025-11-12T22:19:34.503+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:34.503+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: running: Set()
[2025-11-12T22:19:34.503+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:34.504+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:34.506+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:34.538+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:19:34.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO CodeGenerator: Code generated in 29.779789 ms
[2025-11-12T22:19:34.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:34.617+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Got job 46 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:34.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Final stage: ResultStage 83 (showString at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:34.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
[2025-11-12T22:19:34.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:34.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[194] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:34.623+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 439.8 KiB, free 420.7 MiB)
[2025-11-12T22:19:34.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 135.3 KiB, free 420.6 MiB)
[2025-11-12T22:19:34.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on eb021f2c8a8b:35921 (size: 135.3 KiB, free: 423.1 MiB)
[2025-11-12T22:19:34.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:34.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[194] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:34.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0
[2025-11-12T22:19:34.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 69) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:19:34.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 172.18.0.5:40603 (size: 135.3 KiB, free: 423.2 MiB)
[2025-11-12T22:19:34.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to 172.18.0.5:34292
[2025-11-12T22:19:34.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 69) in 75 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:34.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool
[2025-11-12T22:19:34.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: ResultStage 83 (showString at NativeMethodAccessorImpl.java:0) finished in 0.084 s
[2025-11-12T22:19:34.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:34.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished
[2025-11-12T22:19:34.704+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO DAGScheduler: Job 46 finished: showString at NativeMethodAccessorImpl.java:0, took 0.086125 s
[2025-11-12T22:19:34.717+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO CodeGenerator: Code generated in 9.92773 ms
[2025-11-12T22:19:34.767+0000] {spark_submit.py:571} INFO - +-------------------+----------+-----------------+-------------------+----------+-----------------+-------------------+----------+----------+-----------------+-----------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+-----------------+-----------------+---------------------+---------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+-----------------------------------+-----------------------------------+
[2025-11-12T22:19:34.767+0000] {spark_submit.py:571} INFO - |id                 |west_yusho|west_makuuchiWins|west_Makuuchi_basho|east_yusho|east_makuuchiWins|east_Makuuchi_basho|west_order|east_order|east_years_active|west_years_active|rolling_winloss_west|rolling_winloss_east|west_winRate      |east_winRate       |west_makuuchiWinRate|east_makuuchiWinRate|height_difference|weight_difference|west_kimarite_entropy|east_kimarite_entropy|west_specialist_oshi|east_specialist_oshi|west_specialist_yotsu|east_specialist_yotsu|west_specialist_other|east_specialist_other|west_winrate_vs_opponent_specialist|east_winrate_vs_opponent_specialist|
[2025-11-12T22:19:34.768+0000] {spark_submit.py:571} INFO - +-------------------+----------+-----------------+-------------------+----------+-----------------+-------------------+----------+----------+-----------------+-----------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+-----------------+-----------------+---------------------+---------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+-----------------------------------+-----------------------------------+
[2025-11-12T22:19:34.768+0000] {spark_submit.py:571} INFO - |202511-2-13-14-8857|2         |19               |2                  |4         |695              |96                 |31        |20        |21               |1                |0.68                |0.36                |0.7368421052631579|0.5063437139561707 |9.5                 |7.239583333333333   |-4.0             |-27.0            |0.7925445602668123   |0.5879402871378228   |0                   |1                   |1                    |0                    |0                    |0                    |0.6833333333333333                 |0.5155555555555555                 |
[2025-11-12T22:19:34.769+0000] {spark_submit.py:571} INFO - |202511-2-1-95-164  |1         |34               |5                  |2         |0                |0                  |47        |67        |5                |4                |0.49                |0.52                |0.5551724137931034|0.6148148148148148 |6.8                 |0.0                 |-6.0             |-27.0            |0.7498673285617448   |0.6175674444063989   |1                   |0                   |0                    |1                    |0                    |0                    |0.48872180451127817                |0.6503067484662577                 |
[2025-11-12T22:19:34.769+0000] {spark_submit.py:571} INFO - |202511-2-0-39-82   |4         |0                |0                  |1         |266              |41                 |76        |69        |16               |4                |0.51                |0.31                |0.6276150627615062|0.5040577096483319 |0.0                 |6.487804878048781   |1.0              |5.0              |0.8598018415412542   |0.9070249177889054   |0                   |0                   |1                    |1                    |0                    |0                    |0.6666666666666666                 |0.4803921568627451                 |
[2025-11-12T22:19:34.769+0000] {spark_submit.py:571} INFO - |202511-2-8-86-21   |0         |223              |31                 |1         |35               |5                  |48        |54        |5                |10               |0.44                |0.45                |0.5217391304347826|0.5808383233532934 |7.193548387096774   |7.0                 |-20.0            |-32.0            |0.7563888604676292   |0.8305056100482502   |1                   |0                   |0                    |1                    |0                    |0                    |0.5366876310272537                 |0.5738636363636364                 |
[2025-11-12T22:19:34.770+0000] {spark_submit.py:571} INFO - |202511-2-14-61-28  |5         |217              |31                 |2         |70               |9                  |34        |33        |4                |10               |0.52                |0.49                |0.5840840840840841|0.5451713395638629 |7.0                 |7.777777777777778   |-15.0            |-25.0            |0.9371476746962436   |0.6311157554173754   |1                   |1                   |0                    |0                    |0                    |0                    |0.6417910447761194                 |0.5480225988700564                 |
[2025-11-12T22:19:34.770+0000] {spark_submit.py:571} INFO - |202511-2-12-8853-33|4         |441              |58                 |0         |56               |7                  |40        |30        |2                |11               |0.56                |0.39                |0.5380549682875264|0.6025641025641025 |7.603448275862069   |8.0                 |-1.0             |9.0              |0.9489018316223805   |0.5713529766817182   |1                   |0                   |0                    |1                    |0                    |0                    |0.5456790123456791                 |0.6263736263736264                 |
[2025-11-12T22:19:34.770+0000] {spark_submit.py:571} INFO - |202511-2-6-102-55  |2         |66               |10                 |3         |58               |9                  |41        |50        |8                |7                |0.26                |0.62                |0.5679611650485437|0.5957446808510638 |6.6                 |6.444444444444445   |1.0              |-11.0            |0.6541641621361      |0.44395124109390044  |0                   |1                   |1                    |0                    |0                    |0                    |0.6263736263736264                 |0.6245059288537549                 |
[2025-11-12T22:19:34.771+0000] {spark_submit.py:571} INFO - |202511-2-7-9-8     |4         |172              |26                 |4         |449              |57                 |28        |38        |13               |7                |0.39                |0.45                |0.5301204819277109|0.5524861878453039 |6.615384615384615   |7.87719298245614    |8.0              |4.0              |0.8176124819683551   |0.39731713197878044  |1                   |1                   |0                    |0                    |0                    |0                    |0.4984984984984985                 |0.5670926517571885                 |
[2025-11-12T22:19:34.771+0000] {spark_submit.py:571} INFO - |202511-2-9-11-34   |1         |170              |24                 |3         |157              |23                 |36        |29        |8                |9                |0.4                 |0.31                |0.5403225806451613|0.5441941074523396 |7.083333333333333   |6.826086956521739   |-14.0            |-38.0            |1.096679130577557    |0.6791248703175683   |1                   |1                   |0                    |0                    |0                    |0                    |0.6007905138339921                 |0.5933609958506224                 |
[2025-11-12T22:19:34.771+0000] {spark_submit.py:571} INFO - |202511-2-5-615-56  |2         |99               |14                 |1         |16               |2                  |25        |37        |2                |4                |0.62                |0.51                |0.5508474576271186|0.643312101910828  |7.071428571428571   |8.0                 |3.0              |51.0             |0.6064741792020734   |0.9829007277151562   |1                   |1                   |0                    |0                    |0                    |0                    |0.54337899543379                   |0.5507246376811594                 |
[2025-11-12T22:19:34.772+0000] {spark_submit.py:571} INFO - |202511-2-10-50-22  |8         |302              |40                 |3         |107              |15                 |21        |35        |4                |12               |0.42                |0.43                |0.5710928319623971|0.559748427672956  |7.55                |7.133333333333334   |-7.0             |-10.0            |0.5214577162888486   |0.7335415199735977   |1                   |1                   |0                    |0                    |0                    |0                    |0.546916890080429                  |0.5314685314685315                 |
[2025-11-12T22:19:34.772+0000] {spark_submit.py:571} INFO - |202511-2-19-8850-3 |1         |54               |7                  |5         |125              |11                 |22        |1         |2                |2                |0.57                |0.85                |0.6487804878048781|0.7607655502392344 |7.714285714285714   |11.363636363636363  |-11.0            |-23.0            |0.8319680104123204   |0.7905144807321831   |0                   |1                   |1                    |0                    |0                    |0                    |0.6982758620689655                 |0.7368421052631579                 |
[2025-11-12T22:19:34.772+0000] {spark_submit.py:571} INFO - |202511-2-2-35-49   |0         |88               |13                 |3         |411              |59                 |49        |46        |22               |11               |0.61                |0.44                |0.5359477124183006|0.49510763209393344|6.769230769230769   |6.966101694915254   |10.0             |51.80000000000001|0.7950766985998653   |0.7789425866178192   |1                   |0                   |0                    |1                    |0                    |0                    |0.541501976284585                  |0.4800498753117207                 |
[2025-11-12T22:19:34.772+0000] {spark_submit.py:571} INFO - |202511-2-20-37-19  |3         |279              |31                 |0         |281              |37                 |2         |32        |15               |7                |0.72                |0.64                |0.6278260869565218|0.5443548387096774 |9.0                 |7.594594594594595   |4.0              |-21.0            |0.881179631551791    |0.6758574307137932   |0                   |1                   |1                    |0                    |0                    |0                    |0.6327077747989276                 |0.5329768270944741                 |
[2025-11-12T22:19:34.773+0000] {spark_submit.py:571} INFO - |202511-2-4-83-26   |4         |459              |58                 |2         |50               |7                  |43        |45        |6                |10               |0.56                |0.47                |0.5480349344978166|0.568              |7.913793103448276   |7.142857142857143   |0.0              |33.0             |0.8095005650823321   |0.7507797907442465   |1                   |0                   |0                    |1                    |0                    |0                    |0.52                               |0.5833333333333334                 |
[2025-11-12T22:19:34.773+0000] {spark_submit.py:571} INFO - |202511-2-3-15-40   |4         |104              |16                 |7         |252              |37                 |71        |52        |19               |9                |0.62                |0.4                 |0.5358361774744027|0.5385996409335727 |6.5                 |6.8108108108108105  |-5.0             |-8.0             |0.8562647409702899   |0.6802857028438637   |1                   |0                   |0                    |1                    |0                    |0                    |0.548                              |0.5640535372848948                 |
[2025-11-12T22:19:34.773+0000] {spark_submit.py:571} INFO - |202511-2-18-20-7   |4         |283              |34                 |2         |279              |32                 |12        |5         |9                |10               |0.56                |0.56                |0.5910364145658263|0.6011644832605532 |8.323529411764707   |8.71875             |-3.0             |-30.0            |0.9323291550562125   |0.8746033103785462   |0                   |1                   |1                    |0                    |0                    |0                    |0.586864406779661                  |0.6243654822335025                 |
[2025-11-12T22:19:34.774+0000] {spark_submit.py:571} INFO - |202511-2-16-8854-13|3         |194              |23                 |2         |44               |4                  |27        |17        |2                |13               |0.49                |0.59                |0.5641646489104116|0.7878787878787878 |8.434782608695652   |11.0                |5.0              |10.0             |0.8561612558041493   |0.9668019211700329   |0                   |0                   |1                    |1                    |0                    |0                    |0.5852941176470589                 |0.803921568627451                  |
[2025-11-12T22:19:34.774+0000] {spark_submit.py:571} INFO - |202511-2-15-24-44  |1         |634              |85                 |0         |146              |19                 |16        |26        |9                |20               |0.5                 |0.49                |0.5691756272401434|0.5451388888888888 |7.458823529411765   |7.684210526315789   |10.0             |39.0             |0.8753144276860274   |0.8200490170869682   |1                   |0                   |0                    |1                    |0                    |0                    |0.5933734939759037                 |0.5459610027855153                 |
[2025-11-12T22:19:34.774+0000] {spark_submit.py:571} INFO - |202511-2-11-74-71  |3         |92               |12                 |3         |104              |14                 |39        |24        |4                |9                |0.73                |0.75                |0.5156482861400894|0.5653333333333334 |7.666666666666667   |7.428571428571429   |-8.0             |-43.0            |0.7791407409054228   |0.7730572300070738   |1                   |0                   |0                    |1                    |0                    |0                    |0.525065963060686                  |0.6398305084745762                 |
[2025-11-12T22:19:34.774+0000] {spark_submit.py:571} INFO - |202511-2-17-12-41  |1         |168              |22                 |5         |223              |28                 |23        |11        |8                |7                |0.5                 |0.62                |0.5528756957328386|0.617363344051447  |7.636363636363637   |7.964285714285714   |7.0              |42.0             |0.7205765794596204   |0.8960016071734727   |1                   |1                   |0                    |0                    |0                    |0                    |0.5474683544303798                 |0.6111111111111112                 |
[2025-11-12T22:19:34.775+0000] {spark_submit.py:571} INFO - +-------------------+----------+-----------------+-------------------+----------+-----------------+-------------------+----------+----------+-----------------+-----------------+--------------------+--------------------+------------------+-------------------+--------------------+--------------------+-----------------+-----------------+---------------------+---------------------+--------------------+--------------------+---------------------+---------------------+---------------------+---------------------+-----------------------------------+-----------------------------------+
[2025-11-12T22:19:34.775+0000] {spark_submit.py:571} INFO - 
[2025-11-12T22:19:34.775+0000] {spark_submit.py:571} INFO - Attempting to load PipelineModel on driver from s3a://ryans-sumo-bucket/models/xgboost_model
[2025-11-12T22:19:34.777+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 222.8 KiB, free 420.4 MiB)
[2025-11-12T22:19:34.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 420.3 MiB)
[2025-11-12T22:19:34.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on eb021f2c8a8b:35921 (size: 33.3 KiB, free: 423.1 MiB)
[2025-11-12T22:19:34.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:34 INFO SparkContext: Created broadcast 72 from textFile at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:35.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:19:35.242+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181
[2025-11-12T22:19:35.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Got job 47 (runJob at PythonRDD.scala:181) with 1 output partitions
[2025-11-12T22:19:35.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Final stage: ResultStage 84 (runJob at PythonRDD.scala:181)
[2025-11-12T22:19:35.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:35.244+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:35.244+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Submitting ResultStage 84 (PythonRDD[197] at RDD at PythonRDD.scala:53), which has no missing parents
[2025-11-12T22:19:35.246+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 8.2 KiB, free 420.3 MiB)
[2025-11-12T22:19:35.247+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 420.3 MiB)
[2025-11-12T22:19:35.247+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on eb021f2c8a8b:35921 (size: 5.1 KiB, free: 423.1 MiB)
[2025-11-12T22:19:35.247+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:35.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (PythonRDD[197] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:35.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
[2025-11-12T22:19:35.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 70) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10213 bytes)
[2025-11-12T22:19:35.267+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 172.18.0.5:40603 (size: 5.1 KiB, free: 423.2 MiB)
[2025-11-12T22:19:35.276+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 172.18.0.5:40603 (size: 33.3 KiB, free: 423.1 MiB)
[2025-11-12T22:19:35.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 70) in 344 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:35.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool
[2025-11-12T22:19:35.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: ResultStage 84 (runJob at PythonRDD.scala:181) finished in 0.349 s
[2025-11-12T22:19:35.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:35.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished
[2025-11-12T22:19:35.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Job 47 finished: runJob at PythonRDD.scala:181, took 0.351091 s
[2025-11-12T22:19:35.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 222.8 KiB, free 420.1 MiB)
[2025-11-12T22:19:35.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 420.1 MiB)
[2025-11-12T22:19:35.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on eb021f2c8a8b:35921 (size: 33.3 KiB, free: 423.0 MiB)
[2025-11-12T22:19:35.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO SparkContext: Created broadcast 74 from textFile at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:35.835+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:19:35.843+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181
[2025-11-12T22:19:35.844+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Got job 48 (runJob at PythonRDD.scala:181) with 1 output partitions
[2025-11-12T22:19:35.844+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Final stage: ResultStage 85 (runJob at PythonRDD.scala:181)
[2025-11-12T22:19:35.844+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:35.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:35.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Submitting ResultStage 85 (PythonRDD[200] at RDD at PythonRDD.scala:53), which has no missing parents
[2025-11-12T22:19:35.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 8.3 KiB, free 420.1 MiB)
[2025-11-12T22:19:35.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 420.1 MiB)
[2025-11-12T22:19:35.846+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on eb021f2c8a8b:35921 (size: 5.2 KiB, free: 423.0 MiB)
[2025-11-12T22:19:35.846+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:35.846+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (PythonRDD[200] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:35.847+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0
[2025-11-12T22:19:35.847+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 71) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10251 bytes)
[2025-11-12T22:19:35.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 172.18.0.5:40603 (size: 5.2 KiB, free: 423.1 MiB)
[2025-11-12T22:19:35.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:35 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 172.18.0.5:40603 (size: 33.3 KiB, free: 423.1 MiB)
[2025-11-12T22:19:36.034+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 71) in 187 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:36.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool
[2025-11-12T22:19:36.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: ResultStage 85 (runJob at PythonRDD.scala:181) finished in 0.190 s
[2025-11-12T22:19:36.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:36.036+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
[2025-11-12T22:19:36.036+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Job 48 finished: runJob at PythonRDD.scala:181, took 0.191731 s
[2025-11-12T22:19:36.048+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 222.8 KiB, free 419.9 MiB)
[2025-11-12T22:19:36.053+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Removed broadcast_75_piece0 on eb021f2c8a8b:35921 in memory (size: 5.2 KiB, free: 423.0 MiB)
[2025-11-12T22:19:36.055+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 172.18.0.5:40603 in memory (size: 5.2 KiB, free: 423.1 MiB)
[2025-11-12T22:19:36.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 419.8 MiB)
[2025-11-12T22:19:36.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on eb021f2c8a8b:35921 (size: 33.3 KiB, free: 423.0 MiB)
[2025-11-12T22:19:36.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO SparkContext: Created broadcast 76 from textFile at ReadWrite.scala:587
[2025-11-12T22:19:36.057+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Removed broadcast_73_piece0 on eb021f2c8a8b:35921 in memory (size: 5.1 KiB, free: 423.0 MiB)
[2025-11-12T22:19:36.058+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 172.18.0.5:40603 in memory (size: 5.1 KiB, free: 423.1 MiB)
[2025-11-12T22:19:36.059+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Removed broadcast_71_piece0 on eb021f2c8a8b:35921 in memory (size: 135.3 KiB, free: 423.2 MiB)
[2025-11-12T22:19:36.060+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 172.18.0.5:40603 in memory (size: 135.3 KiB, free: 423.2 MiB)
[2025-11-12T22:19:36.062+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Removed broadcast_70_piece0 on eb021f2c8a8b:35921 in memory (size: 118.4 KiB, free: 423.3 MiB)
[2025-11-12T22:19:36.062+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 172.18.0.5:40603 in memory (size: 118.4 KiB, free: 423.3 MiB)
[2025-11-12T22:19:36.283+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:19:36.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO SparkContext: Starting job: first at ReadWrite.scala:587
[2025-11-12T22:19:36.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Got job 49 (first at ReadWrite.scala:587) with 1 output partitions
[2025-11-12T22:19:36.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Final stage: ResultStage 86 (first at ReadWrite.scala:587)
[2025-11-12T22:19:36.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:36.288+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:36.288+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Submitting ResultStage 86 (s3a://ryans-sumo-bucket/models/xgboost_model/stages/0_VectorAssembler_44693654e9ff/metadata MapPartitionsRDD[202] at textFile at ReadWrite.scala:587), which has no missing parents
[2025-11-12T22:19:36.289+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 5.0 KiB, free 420.9 MiB)
[2025-11-12T22:19:36.292+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 420.9 MiB)
[2025-11-12T22:19:36.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on eb021f2c8a8b:35921 (size: 2.9 KiB, free: 423.3 MiB)
[2025-11-12T22:19:36.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:36.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (s3a://ryans-sumo-bucket/models/xgboost_model/stages/0_VectorAssembler_44693654e9ff/metadata MapPartitionsRDD[202] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:36.294+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0
[2025-11-12T22:19:36.294+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 72) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10251 bytes)
[2025-11-12T22:19:36.309+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 172.18.0.5:45133 (size: 2.9 KiB, free: 423.7 MiB)
[2025-11-12T22:19:36.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 172.18.0.5:45133 (size: 33.3 KiB, free: 423.7 MiB)
[2025-11-12T22:19:36.495+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 72) in 202 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:36.496+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool
[2025-11-12T22:19:36.497+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: ResultStage 86 (first at ReadWrite.scala:587) finished in 0.208 s
[2025-11-12T22:19:36.497+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:36.497+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished
[2025-11-12T22:19:36.497+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Job 49 finished: first at ReadWrite.scala:587, took 0.209397 s
[2025-11-12T22:19:36.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 222.8 KiB, free 420.7 MiB)
[2025-11-12T22:19:36.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 420.6 MiB)
[2025-11-12T22:19:36.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on eb021f2c8a8b:35921 (size: 33.3 KiB, free: 423.2 MiB)
[2025-11-12T22:19:36.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO SparkContext: Created broadcast 78 from textFile at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:36.753+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:19:36.761+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181
[2025-11-12T22:19:36.762+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Got job 50 (runJob at PythonRDD.scala:181) with 1 output partitions
[2025-11-12T22:19:36.762+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Final stage: ResultStage 87 (runJob at PythonRDD.scala:181)
[2025-11-12T22:19:36.762+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:36.762+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:36.763+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Submitting ResultStage 87 (PythonRDD[205] at RDD at PythonRDD.scala:53), which has no missing parents
[2025-11-12T22:19:36.763+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 8.3 KiB, free 420.6 MiB)
[2025-11-12T22:19:36.763+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 420.6 MiB)
[2025-11-12T22:19:36.764+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on eb021f2c8a8b:35921 (size: 5.2 KiB, free: 423.2 MiB)
[2025-11-12T22:19:36.764+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:36.764+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (PythonRDD[205] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:36.764+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0
[2025-11-12T22:19:36.765+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 73) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10254 bytes)
[2025-11-12T22:19:36.771+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 172.18.0.5:45133 (size: 5.2 KiB, free: 423.7 MiB)
[2025-11-12T22:19:36.777+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 172.18.0.5:45133 (size: 33.3 KiB, free: 423.6 MiB)
[2025-11-12T22:19:36.961+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 73) in 196 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:36.961+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool
[2025-11-12T22:19:36.962+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: ResultStage 87 (runJob at PythonRDD.scala:181) finished in 0.199 s
[2025-11-12T22:19:36.962+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:36.962+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
[2025-11-12T22:19:36.962+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:36 INFO DAGScheduler: Job 50 finished: runJob at PythonRDD.scala:181, took 0.200452 s
[2025-11-12T22:19:37.569+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 222.8 KiB, free 420.4 MiB)
[2025-11-12T22:19:37.573+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 420.4 MiB)
[2025-11-12T22:19:37.574+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on eb021f2c8a8b:35921 (size: 33.3 KiB, free: 423.2 MiB)
[2025-11-12T22:19:37.574+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO SparkContext: Created broadcast 80 from textFile at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:37.774+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:19:37.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO SparkContext: Starting job: runJob at PythonRDD.scala:181
[2025-11-12T22:19:37.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO DAGScheduler: Got job 51 (runJob at PythonRDD.scala:181) with 1 output partitions
[2025-11-12T22:19:37.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO DAGScheduler: Final stage: ResultStage 88 (runJob at PythonRDD.scala:181)
[2025-11-12T22:19:37.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:37.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:37.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO DAGScheduler: Submitting ResultStage 88 (PythonRDD[208] at RDD at PythonRDD.scala:53), which has no missing parents
[2025-11-12T22:19:37.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 8.3 KiB, free 420.4 MiB)
[2025-11-12T22:19:37.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 420.4 MiB)
[2025-11-12T22:19:37.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on eb021f2c8a8b:35921 (size: 5.2 KiB, free: 423.2 MiB)
[2025-11-12T22:19:37.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:37.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (PythonRDD[208] at RDD at PythonRDD.scala:53) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:37.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0
[2025-11-12T22:19:37.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 74) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10254 bytes)
[2025-11-12T22:19:37.791+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 172.18.0.5:40603 (size: 5.2 KiB, free: 423.3 MiB)
[2025-11-12T22:19:37.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 172.18.0.5:40603 (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:19:37.932+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 74) in 147 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:37.933+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool
[2025-11-12T22:19:37.934+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO DAGScheduler: ResultStage 88 (runJob at PythonRDD.scala:181) finished in 0.150 s
[2025-11-12T22:19:37.934+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:37.934+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
[2025-11-12T22:19:37.935+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO DAGScheduler: Job 51 finished: runJob at PythonRDD.scala:181, took 0.151537 s
[2025-11-12T22:19:37.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 222.8 KiB, free 420.1 MiB)
[2025-11-12T22:19:37.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 33.3 KiB, free 420.1 MiB)
[2025-11-12T22:19:37.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on eb021f2c8a8b:35921 (size: 33.3 KiB, free: 423.2 MiB)
[2025-11-12T22:19:37.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:37 INFO SparkContext: Created broadcast 82 from textFile at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:38.142+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO FileInputFormat: Total input files to process : 1
[2025-11-12T22:19:38.145+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO SparkContext: Starting job: load at /opt/airflow/jobs/spark_mongoNewMatches.py:763
[2025-11-12T22:19:38.145+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO DAGScheduler: Got job 52 (load at /opt/airflow/jobs/spark_mongoNewMatches.py:763) with 2 output partitions
[2025-11-12T22:19:38.146+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO DAGScheduler: Final stage: ResultStage 89 (load at /opt/airflow/jobs/spark_mongoNewMatches.py:763)
[2025-11-12T22:19:38.146+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:38.146+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:38.147+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO DAGScheduler: Submitting ResultStage 89 (s3a://ryans-sumo-bucket/models/xgboost_model/stages/1_SparkXGBClassifier_3de5eb1a1dbb/model MapPartitionsRDD[210] at textFile at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:38.147+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 5.0 KiB, free 420.1 MiB)
[2025-11-12T22:19:38.147+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 2.9 KiB, free 420.1 MiB)
[2025-11-12T22:19:38.147+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on eb021f2c8a8b:35921 (size: 2.9 KiB, free: 423.2 MiB)
[2025-11-12T22:19:38.147+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:38.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 89 (s3a://ryans-sumo-bucket/models/xgboost_model/stages/1_SparkXGBClassifier_3de5eb1a1dbb/model MapPartitionsRDD[210] at textFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:38.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO TaskSchedulerImpl: Adding task set 89.0 with 2 tasks resource profile 0
[2025-11-12T22:19:38.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 75) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10251 bytes)
[2025-11-12T22:19:38.149+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 76) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10251 bytes)
[2025-11-12T22:19:38.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.18.0.5:40603 (size: 2.9 KiB, free: 423.3 MiB)
[2025-11-12T22:19:38.155+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 172.18.0.5:45133 (size: 2.9 KiB, free: 423.6 MiB)
[2025-11-12T22:19:38.159+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.18.0.5:40603 (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:19:38.159+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 172.18.0.5:45133 (size: 33.3 KiB, free: 423.6 MiB)
[2025-11-12T22:19:38.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO BlockManagerInfo: Added taskresult_75 in memory on 172.18.0.5:45133 (size: 1801.1 KiB, free: 421.8 MiB)
[2025-11-12T22:19:38.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 75) in 542 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:19:38.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO BlockManagerInfo: Removed taskresult_75 on 172.18.0.5:45133 in memory (size: 1801.1 KiB, free: 423.6 MiB)
[2025-11-12T22:19:38.698+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 76) in 550 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:19:38.699+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool
[2025-11-12T22:19:38.699+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO DAGScheduler: ResultStage 89 (load at /opt/airflow/jobs/spark_mongoNewMatches.py:763) finished in 0.553 s
[2025-11-12T22:19:38.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:38.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
[2025-11-12T22:19:38.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:38 INFO DAGScheduler: Job 52 finished: load at /opt/airflow/jobs/spark_mongoNewMatches.py:763, took 0.554103 s
[2025-11-12T22:19:38.769+0000] {spark_submit.py:571} INFO - Loaded PipelineModel on driver
[2025-11-12T22:19:39.341+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 208.0 B, free 420.1 MiB)
[2025-11-12T22:19:39.344+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 569.7 KiB, free 419.5 MiB)
[2025-11-12T22:19:39.344+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on eb021f2c8a8b:35921 (size: 569.7 KiB, free: 422.6 MiB)
[2025-11-12T22:19:39.345+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO SparkContext: Created broadcast 84 from broadcast at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:39.464+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_77_piece0 on eb021f2c8a8b:35921 in memory (size: 2.9 KiB, free: 422.6 MiB)
[2025-11-12T22:19:39.465+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 172.18.0.5:45133 in memory (size: 2.9 KiB, free: 423.6 MiB)
[2025-11-12T22:19:39.466+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_80_piece0 on eb021f2c8a8b:35921 in memory (size: 33.3 KiB, free: 422.6 MiB)
[2025-11-12T22:19:39.467+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 172.18.0.5:40603 in memory (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:19:39.469+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_81_piece0 on eb021f2c8a8b:35921 in memory (size: 5.2 KiB, free: 422.6 MiB)
[2025-11-12T22:19:39.470+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 172.18.0.5:40603 in memory (size: 5.2 KiB, free: 423.3 MiB)
[2025-11-12T22:19:39.471+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_72_piece0 on eb021f2c8a8b:35921 in memory (size: 33.3 KiB, free: 422.7 MiB)
[2025-11-12T22:19:39.472+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 172.18.0.5:40603 in memory (size: 33.3 KiB, free: 423.3 MiB)
[2025-11-12T22:19:39.473+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_78_piece0 on eb021f2c8a8b:35921 in memory (size: 33.3 KiB, free: 422.7 MiB)
[2025-11-12T22:19:39.474+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 172.18.0.5:45133 in memory (size: 33.3 KiB, free: 423.6 MiB)
[2025-11-12T22:19:39.476+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_83_piece0 on eb021f2c8a8b:35921 in memory (size: 2.9 KiB, free: 422.7 MiB)
[2025-11-12T22:19:39.476+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.18.0.5:45133 in memory (size: 2.9 KiB, free: 423.6 MiB)
[2025-11-12T22:19:39.477+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 172.18.0.5:40603 in memory (size: 2.9 KiB, free: 423.3 MiB)
[2025-11-12T22:19:39.478+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_79_piece0 on eb021f2c8a8b:35921 in memory (size: 5.2 KiB, free: 422.7 MiB)
[2025-11-12T22:19:39.479+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 172.18.0.5:45133 in memory (size: 5.2 KiB, free: 423.6 MiB)
[2025-11-12T22:19:39.480+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_74_piece0 on eb021f2c8a8b:35921 in memory (size: 33.3 KiB, free: 422.7 MiB)
[2025-11-12T22:19:39.481+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 172.18.0.5:40603 in memory (size: 33.3 KiB, free: 423.4 MiB)
[2025-11-12T22:19:39.482+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_76_piece0 on eb021f2c8a8b:35921 in memory (size: 33.3 KiB, free: 422.8 MiB)
[2025-11-12T22:19:39.483+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:39 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 172.18.0.5:45133 in memory (size: 33.3 KiB, free: 423.7 MiB)
[2025-11-12T22:19:40.800+0000] {spark_submit.py:571} INFO - Model scored rows on driver
[2025-11-12T22:19:41.064+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_57_piece0 on eb021f2c8a8b:35921 in memory (size: 4.0 MiB, free: 426.8 MiB)
[2025-11-12T22:19:41.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_57_piece1 on eb021f2c8a8b:35921 in memory (size: 1054.7 KiB, free: 427.8 MiB)
[2025-11-12T22:19:41.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.18.0.5:40603 in memory (size: 4.0 MiB, free: 427.4 MiB)
[2025-11-12T22:19:41.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.18.0.5:45133 in memory (size: 4.0 MiB, free: 427.7 MiB)
[2025-11-12T22:19:41.067+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_57_piece1 on 172.18.0.5:40603 in memory (size: 1054.7 KiB, free: 428.4 MiB)
[2025-11-12T22:19:41.067+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_57_piece1 on 172.18.0.5:45133 in memory (size: 1054.7 KiB, free: 428.7 MiB)
[2025-11-12T22:19:41.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_45_piece0 on eb021f2c8a8b:35921 in memory (size: 178.0 B, free: 427.8 MiB)
[2025-11-12T22:19:41.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.18.0.5:45133 in memory (size: 178.0 B, free: 428.7 MiB)
[2025-11-12T22:19:41.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_39_piece0 on eb021f2c8a8b:35921 in memory (size: 37.3 KiB, free: 427.8 MiB)
[2025-11-12T22:19:41.072+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.18.0.5:40603 in memory (size: 37.3 KiB, free: 428.4 MiB)
[2025-11-12T22:19:41.072+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.18.0.5:45133 in memory (size: 37.3 KiB, free: 428.7 MiB)
[2025-11-12T22:19:41.074+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_49_piece0 on eb021f2c8a8b:35921 in memory (size: 47.0 KiB, free: 427.9 MiB)
[2025-11-12T22:19:41.075+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.18.0.5:40603 in memory (size: 47.0 KiB, free: 428.5 MiB)
[2025-11-12T22:19:41.076+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.18.0.5:45133 in memory (size: 47.0 KiB, free: 428.8 MiB)
[2025-11-12T22:19:41.077+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_34_piece0 on eb021f2c8a8b:35921 in memory (size: 37.3 KiB, free: 427.9 MiB)
[2025-11-12T22:19:41.078+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.5:40603 in memory (size: 37.3 KiB, free: 428.5 MiB)
[2025-11-12T22:19:41.079+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.18.0.5:45133 in memory (size: 37.3 KiB, free: 428.8 MiB)
[2025-11-12T22:19:41.080+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_55_piece0 on eb021f2c8a8b:35921 in memory (size: 56.1 KiB, free: 428.0 MiB)
[2025-11-12T22:19:41.081+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.18.0.5:45133 in memory (size: 56.1 KiB, free: 428.9 MiB)
[2025-11-12T22:19:41.082+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.18.0.5:40603 in memory (size: 56.1 KiB, free: 428.6 MiB)
[2025-11-12T22:19:41.083+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_53_piece1 on eb021f2c8a8b:35921 in memory (size: 1048.4 KiB, free: 429.0 MiB)
[2025-11-12T22:19:41.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_53_piece0 on eb021f2c8a8b:35921 in memory (size: 4.0 MiB, free: 433.0 MiB)
[2025-11-12T22:19:41.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_53_piece1 on 172.18.0.5:40603 in memory (size: 1048.4 KiB, free: 429.6 MiB)
[2025-11-12T22:19:41.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_53_piece1 on 172.18.0.5:45133 in memory (size: 1048.4 KiB, free: 429.9 MiB)
[2025-11-12T22:19:41.085+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.18.0.5:40603 in memory (size: 4.0 MiB, free: 433.6 MiB)
[2025-11-12T22:19:41.085+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.18.0.5:45133 in memory (size: 4.0 MiB, free: 433.9 MiB)
[2025-11-12T22:19:41.090+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_35_piece0 on eb021f2c8a8b:35921 in memory (size: 37.3 KiB, free: 433.0 MiB)
[2025-11-12T22:19:41.091+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.18.0.5:40603 in memory (size: 37.3 KiB, free: 433.6 MiB)
[2025-11-12T22:19:41.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.18.0.5:45133 in memory (size: 37.3 KiB, free: 433.9 MiB)
[2025-11-12T22:19:41.093+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_37_piece0 on eb021f2c8a8b:35921 in memory (size: 37.3 KiB, free: 433.1 MiB)
[2025-11-12T22:19:41.094+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.18.0.5:40603 in memory (size: 37.3 KiB, free: 433.7 MiB)
[2025-11-12T22:19:41.095+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.18.0.5:45133 in memory (size: 37.3 KiB, free: 434.0 MiB)
[2025-11-12T22:19:41.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_62_piece0 on eb021f2c8a8b:35921 in memory (size: 37.8 KiB, free: 433.1 MiB)
[2025-11-12T22:19:41.099+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.18.0.5:40603 in memory (size: 37.8 KiB, free: 433.7 MiB)
[2025-11-12T22:19:41.099+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.18.0.5:45133 in memory (size: 37.8 KiB, free: 434.0 MiB)
[2025-11-12T22:19:41.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_60_piece0 on eb021f2c8a8b:35921 in memory (size: 37.3 KiB, free: 433.2 MiB)
[2025-11-12T22:19:41.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.18.0.5:45133 in memory (size: 37.3 KiB, free: 434.1 MiB)
[2025-11-12T22:19:41.102+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_56_piece0 on eb021f2c8a8b:35921 in memory (size: 37.8 KiB, free: 433.2 MiB)
[2025-11-12T22:19:41.103+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.18.0.5:45133 in memory (size: 37.8 KiB, free: 434.1 MiB)
[2025-11-12T22:19:41.103+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.18.0.5:40603 in memory (size: 37.8 KiB, free: 433.7 MiB)
[2025-11-12T22:19:41.104+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_69_piece0 on eb021f2c8a8b:35921 in memory (size: 350.0 KiB, free: 433.5 MiB)
[2025-11-12T22:19:41.105+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 172.18.0.5:40603 in memory (size: 350.0 KiB, free: 434.1 MiB)
[2025-11-12T22:19:41.106+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_66_piece0 on eb021f2c8a8b:35921 in memory (size: 158.7 KiB, free: 433.7 MiB)
[2025-11-12T22:19:41.106+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.18.0.5:45133 in memory (size: 158.7 KiB, free: 434.2 MiB)
[2025-11-12T22:19:41.107+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.18.0.5:40603 in memory (size: 158.7 KiB, free: 434.2 MiB)
[2025-11-12T22:19:41.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_59_piece0 on eb021f2c8a8b:35921 in memory (size: 37.3 KiB, free: 433.7 MiB)
[2025-11-12T22:19:41.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.18.0.5:45133 in memory (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:41.109+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.18.0.5:40603 in memory (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:41.111+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_54_piece0 on eb021f2c8a8b:35921 in memory (size: 90.5 KiB, free: 433.8 MiB)
[2025-11-12T22:19:41.111+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.18.0.5:40603 in memory (size: 90.5 KiB, free: 434.4 MiB)
[2025-11-12T22:19:41.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:41 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.18.0.5:45133 in memory (size: 90.5 KiB, free: 434.4 MiB)
[2025-11-12T22:19:45.837+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:45 INFO BlockManagerInfo: Removed broadcast_82_piece0 on eb021f2c8a8b:35921 in memory (size: 33.3 KiB, free: 433.8 MiB)
[2025-11-12T22:19:45.838+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:45 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.18.0.5:45133 in memory (size: 33.3 KiB, free: 434.4 MiB)
[2025-11-12T22:19:45.839+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:45 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 172.18.0.5:40603 in memory (size: 33.3 KiB, free: 434.4 MiB)
[2025-11-12T22:19:46.535+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO MongoRelation: requiredColumns: id, basho, filters:
[2025-11-12T22:19:46.578+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.579+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2408 = ) THEN false ELSE isnull(kimarite#2408) END OR CASE WHEN (kimarite#2408 = ) THEN true ELSE (kimarite#2408 = NA) END) THEN false ELSE CASE WHEN (kimarite#2408 = ) THEN true ELSE isnotnull(kimarite#2408) END END
[2025-11-12T22:19:46.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#2862 = ) THEN false ELSE isnull(kimarite#2862) END OR CASE WHEN (kimarite#2862 = ) THEN true ELSE (kimarite#2862 = NA) END) THEN false ELSE CASE WHEN (kimarite#2862 = ) THEN true ELSE isnotnull(kimarite#2862) END END
[2025-11-12T22:19:46.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:46.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:46.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4728 = ) THEN false ELSE isnull(kimarite#4728) END OR CASE WHEN (kimarite#4728 = ) THEN true ELSE (kimarite#4728 = NA) END) THEN false ELSE CASE WHEN (kimarite#4728 = ) THEN true ELSE isnotnull(kimarite#4728) END END
[2025-11-12T22:19:46.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4932 = ) THEN false ELSE isnull(kimarite#4932) END OR CASE WHEN (kimarite#4932 = ) THEN true ELSE (kimarite#4932 = NA) END) THEN false ELSE CASE WHEN (kimarite#4932 = ) THEN true ELSE isnotnull(kimarite#4932) END END
[2025-11-12T22:19:46.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:46.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:46.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4043 = ) THEN false ELSE isnull(kimarite#4043) END OR CASE WHEN (kimarite#4043 = ) THEN true ELSE (kimarite#4043 = NA) END) THEN false ELSE CASE WHEN (kimarite#4043 = ) THEN true ELSE isnotnull(kimarite#4043) END END
[2025-11-12T22:19:46.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#4247 = ) THEN false ELSE isnull(kimarite#4247) END OR CASE WHEN (kimarite#4247 = ) THEN true ELSE (kimarite#4247 = NA) END) THEN false ELSE CASE WHEN (kimarite#4247 = ) THEN true ELSE isnotnull(kimarite#4247) END END
[2025-11-12T22:19:46.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.599+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.599+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7767 = ) THEN false ELSE isnull(kimarite#7767) END OR CASE WHEN (kimarite#7767 = ) THEN true ELSE (kimarite#7767 = NA) END) THEN false ELSE CASE WHEN (kimarite#7767 = ) THEN true ELSE isnotnull(kimarite#7767) END END
[2025-11-12T22:19:46.602+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.602+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#7971 = ) THEN false ELSE isnull(kimarite#7971) END OR CASE WHEN (kimarite#7971 = ) THEN true ELSE (kimarite#7971 = NA) END) THEN false ELSE CASE WHEN (kimarite#7971 = ) THEN true ELSE isnotnull(kimarite#7971) END END
[2025-11-12T22:19:46.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:46.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:46.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.604+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#9603 = ) THEN false ELSE isnull(kimarite#9603) END OR CASE WHEN (kimarite#9603 = ) THEN true ELSE (kimarite#9603 = NA) END) THEN false ELSE CASE WHEN (kimarite#9603 = ) THEN true ELSE isnotnull(kimarite#9603) END END
[2025-11-12T22:19:46.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#9807 = ) THEN false ELSE isnull(kimarite#9807) END OR CASE WHEN (kimarite#9807 = ) THEN true ELSE (kimarite#9807 = NA) END) THEN false ELSE CASE WHEN (kimarite#9807 = ) THEN true ELSE isnotnull(kimarite#9807) END END
[2025-11-12T22:19:46.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:46.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:46.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#10215 = ) THEN false ELSE isnull(kimarite#10215) END OR CASE WHEN (kimarite#10215 = ) THEN true ELSE (kimarite#10215 = NA) END) THEN false ELSE CASE WHEN (kimarite#10215 = ) THEN true ELSE isnotnull(kimarite#10215) END END
[2025-11-12T22:19:46.613+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.613+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#10419 = ) THEN false ELSE isnull(kimarite#10419) END OR CASE WHEN (kimarite#10419 = ) THEN true ELSE (kimarite#10419 = NA) END) THEN false ELSE CASE WHEN (kimarite#10419 = ) THEN true ELSE isnotnull(kimarite#10419) END END
[2025-11-12T22:19:46.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.617+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.617+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.618+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.618+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11315 = ) THEN false ELSE isnull(kimarite#11315) END OR CASE WHEN (kimarite#11315 = ) THEN true ELSE (kimarite#11315 = NA) END) THEN false ELSE CASE WHEN (kimarite#11315 = ) THEN true ELSE isnotnull(kimarite#11315) END END
[2025-11-12T22:19:46.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11519 = ) THEN false ELSE isnull(kimarite#11519) END OR CASE WHEN (kimarite#11519 = ) THEN true ELSE (kimarite#11519 = NA) END) THEN false ELSE CASE WHEN (kimarite#11519 = ) THEN true ELSE isnotnull(kimarite#11519) END END
[2025-11-12T22:19:46.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:46.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:46.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.622+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#11927 = ) THEN false ELSE isnull(kimarite#11927) END OR CASE WHEN (kimarite#11927 = ) THEN true ELSE (kimarite#11927 = NA) END) THEN false ELSE CASE WHEN (kimarite#11927 = ) THEN true ELSE isnotnull(kimarite#11927) END END
[2025-11-12T22:19:46.623+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.623+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#12131 = ) THEN false ELSE isnull(kimarite#12131) END OR CASE WHEN (kimarite#12131 = ) THEN true ELSE (kimarite#12131 = NA) END) THEN false ELSE CASE WHEN (kimarite#12131 = ) THEN true ELSE isnotnull(kimarite#12131) END END
[2025-11-12T22:19:46.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:46.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:46.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#12539 = ) THEN false ELSE isnull(kimarite#12539) END OR CASE WHEN (kimarite#12539 = ) THEN true ELSE (kimarite#12539 = NA) END) THEN false ELSE CASE WHEN (kimarite#12539 = ) THEN true ELSE isnotnull(kimarite#12539) END END
[2025-11-12T22:19:46.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#12743 = ) THEN false ELSE isnull(kimarite#12743) END OR CASE WHEN (kimarite#12743 = ) THEN true ELSE (kimarite#12743 = NA) END) THEN false ELSE CASE WHEN (kimarite#12743 = ) THEN true ELSE isnotnull(kimarite#12743) END END
[2025-11-12T22:19:46.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.630+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14375 = ) THEN false ELSE isnull(kimarite#14375) END OR CASE WHEN (kimarite#14375 = ) THEN true ELSE (kimarite#14375 = NA) END) THEN false ELSE CASE WHEN (kimarite#14375 = ) THEN true ELSE isnotnull(kimarite#14375) END END
[2025-11-12T22:19:46.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#14579 = ) THEN false ELSE isnull(kimarite#14579) END OR CASE WHEN (kimarite#14579 = ) THEN true ELSE (kimarite#14579 = NA) END) THEN false ELSE CASE WHEN (kimarite#14579 = ) THEN true ELSE isnotnull(kimarite#14579) END END
[2025-11-12T22:19:46.634+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:46.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:46.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16211 = ) THEN false ELSE isnull(kimarite#16211) END OR CASE WHEN (kimarite#16211 = ) THEN true ELSE (kimarite#16211 = NA) END) THEN false ELSE CASE WHEN (kimarite#16211 = ) THEN true ELSE isnotnull(kimarite#16211) END END
[2025-11-12T22:19:46.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16415 = ) THEN false ELSE isnull(kimarite#16415) END OR CASE WHEN (kimarite#16415 = ) THEN true ELSE (kimarite#16415 = NA) END) THEN false ELSE CASE WHEN (kimarite#16415 = ) THEN true ELSE isnotnull(kimarite#16415) END END
[2025-11-12T22:19:46.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:46.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:46.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#16823 = ) THEN false ELSE isnull(kimarite#16823) END OR CASE WHEN (kimarite#16823 = ) THEN true ELSE (kimarite#16823 = NA) END) THEN false ELSE CASE WHEN (kimarite#16823 = ) THEN true ELSE isnotnull(kimarite#16823) END END
[2025-11-12T22:19:46.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.640+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#17027 = ) THEN false ELSE isnull(kimarite#17027) END OR CASE WHEN (kimarite#17027 = ) THEN true ELSE (kimarite#17027 = NA) END) THEN false ELSE CASE WHEN (kimarite#17027 = ) THEN true ELSE isnotnull(kimarite#17027) END END
[2025-11-12T22:19:46.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO MongoRelation: requiredColumns: id, filters:
[2025-11-12T22:19:46.654+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.655+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.655+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.656+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#22919 = ) THEN false ELSE isnull(kimarite#22919) END OR CASE WHEN (kimarite#22919 = ) THEN true ELSE (kimarite#22919 = NA) END) THEN false ELSE CASE WHEN (kimarite#22919 = ) THEN true ELSE isnotnull(kimarite#22919) END END
[2025-11-12T22:19:46.661+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#23123 = ) THEN false ELSE isnull(kimarite#23123) END OR CASE WHEN (kimarite#23123 = ) THEN true ELSE (kimarite#23123 = NA) END) THEN false ELSE CASE WHEN (kimarite#23123 = ) THEN true ELSE isnotnull(kimarite#23123) END END
[2025-11-12T22:19:46.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:46.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:19:46.664+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.664+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#23531 = ) THEN false ELSE isnull(kimarite#23531) END OR CASE WHEN (kimarite#23531 = ) THEN true ELSE (kimarite#23531 = NA) END) THEN false ELSE CASE WHEN (kimarite#23531 = ) THEN true ELSE isnotnull(kimarite#23531) END END
[2025-11-12T22:19:46.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#23735 = ) THEN false ELSE isnull(kimarite#23735) END OR CASE WHEN (kimarite#23735 = ) THEN true ELSE (kimarite#23735 = NA) END) THEN false ELSE CASE WHEN (kimarite#23735 = ) THEN true ELSE isnotnull(kimarite#23735) END END
[2025-11-12T22:19:46.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:46.667+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:19:46.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#24143 = ) THEN false ELSE isnull(kimarite#24143) END OR CASE WHEN (kimarite#24143 = ) THEN true ELSE (kimarite#24143 = NA) END) THEN false ELSE CASE WHEN (kimarite#24143 = ) THEN true ELSE isnotnull(kimarite#24143) END END
[2025-11-12T22:19:46.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#24347 = ) THEN false ELSE isnull(kimarite#24347) END OR CASE WHEN (kimarite#24347 = ) THEN true ELSE (kimarite#24347 = NA) END) THEN false ELSE CASE WHEN (kimarite#24347 = ) THEN true ELSE isnotnull(kimarite#24347) END END
[2025-11-12T22:19:46.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.673+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.673+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.673+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.673+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#25979 = ) THEN false ELSE isnull(kimarite#25979) END OR CASE WHEN (kimarite#25979 = ) THEN true ELSE (kimarite#25979 = NA) END) THEN false ELSE CASE WHEN (kimarite#25979 = ) THEN true ELSE isnotnull(kimarite#25979) END END
[2025-11-12T22:19:46.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#26183 = ) THEN false ELSE isnull(kimarite#26183) END OR CASE WHEN (kimarite#26183 = ) THEN true ELSE (kimarite#26183 = NA) END) THEN false ELSE CASE WHEN (kimarite#26183 = ) THEN true ELSE isnotnull(kimarite#26183) END END
[2025-11-12T22:19:46.678+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:46.678+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:19:46.678+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.679+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#27815 = ) THEN false ELSE isnull(kimarite#27815) END OR CASE WHEN (kimarite#27815 = ) THEN true ELSE (kimarite#27815 = NA) END) THEN false ELSE CASE WHEN (kimarite#27815 = ) THEN true ELSE isnotnull(kimarite#27815) END END
[2025-11-12T22:19:46.680+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.680+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#28019 = ) THEN false ELSE isnull(kimarite#28019) END OR CASE WHEN (kimarite#28019 = ) THEN true ELSE (kimarite#28019 = NA) END) THEN false ELSE CASE WHEN (kimarite#28019 = ) THEN true ELSE isnotnull(kimarite#28019) END END
[2025-11-12T22:19:46.681+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:46.681+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:19:46.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#28427 = ) THEN false ELSE isnull(kimarite#28427) END OR CASE WHEN (kimarite#28427 = ) THEN true ELSE (kimarite#28427 = NA) END) THEN false ELSE CASE WHEN (kimarite#28427 = ) THEN true ELSE isnotnull(kimarite#28427) END END
[2025-11-12T22:19:46.685+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.685+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#28631 = ) THEN false ELSE isnull(kimarite#28631) END OR CASE WHEN (kimarite#28631 = ) THEN true ELSE (kimarite#28631 = NA) END) THEN false ELSE CASE WHEN (kimarite#28631 = ) THEN true ELSE isnotnull(kimarite#28631) END END
[2025-11-12T22:19:46.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#29039 = ) THEN false ELSE isnull(kimarite#29039) END OR CASE WHEN (kimarite#29039 = ) THEN true ELSE (kimarite#29039 = NA) END) THEN false ELSE CASE WHEN (kimarite#29039 = ) THEN true ELSE isnotnull(kimarite#29039) END END
[2025-11-12T22:19:46.695+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.696+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#29243 = ) THEN false ELSE isnull(kimarite#29243) END OR CASE WHEN (kimarite#29243 = ) THEN true ELSE (kimarite#29243 = NA) END) THEN false ELSE CASE WHEN (kimarite#29243 = ) THEN true ELSE isnotnull(kimarite#29243) END END
[2025-11-12T22:19:46.697+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:46.697+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:19:46.697+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.698+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#29651 = ) THEN false ELSE isnull(kimarite#29651) END OR CASE WHEN (kimarite#29651 = ) THEN true ELSE (kimarite#29651 = NA) END) THEN false ELSE CASE WHEN (kimarite#29651 = ) THEN true ELSE isnotnull(kimarite#29651) END END
[2025-11-12T22:19:46.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#29855 = ) THEN false ELSE isnull(kimarite#29855) END OR CASE WHEN (kimarite#29855 = ) THEN true ELSE (kimarite#29855 = NA) END) THEN false ELSE CASE WHEN (kimarite#29855 = ) THEN true ELSE isnotnull(kimarite#29855) END END
[2025-11-12T22:19:46.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:46.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:19:46.704+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#30263 = ) THEN false ELSE isnull(kimarite#30263) END OR CASE WHEN (kimarite#30263 = ) THEN true ELSE (kimarite#30263 = NA) END) THEN false ELSE CASE WHEN (kimarite#30263 = ) THEN true ELSE isnotnull(kimarite#30263) END END
[2025-11-12T22:19:46.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#30467 = ) THEN false ELSE isnull(kimarite#30467) END OR CASE WHEN (kimarite#30467 = ) THEN true ELSE (kimarite#30467 = NA) END) THEN false ELSE CASE WHEN (kimarite#30467 = ) THEN true ELSE isnotnull(kimarite#30467) END END
[2025-11-12T22:19:46.707+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.707+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:46.711+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.711+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#32099 = ) THEN false ELSE isnull(kimarite#32099) END OR CASE WHEN (kimarite#32099 = ) THEN true ELSE (kimarite#32099 = NA) END) THEN false ELSE CASE WHEN (kimarite#32099 = ) THEN true ELSE isnotnull(kimarite#32099) END END
[2025-11-12T22:19:46.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.714+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#32303 = ) THEN false ELSE isnull(kimarite#32303) END OR CASE WHEN (kimarite#32303 = ) THEN true ELSE (kimarite#32303 = NA) END) THEN false ELSE CASE WHEN (kimarite#32303 = ) THEN true ELSE isnotnull(kimarite#32303) END END
[2025-11-12T22:19:46.715+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:46.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:19:46.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.716+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#33935 = ) THEN false ELSE isnull(kimarite#33935) END OR CASE WHEN (kimarite#33935 = ) THEN true ELSE (kimarite#33935 = NA) END) THEN false ELSE CASE WHEN (kimarite#33935 = ) THEN true ELSE isnotnull(kimarite#33935) END END
[2025-11-12T22:19:46.719+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.719+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#34139 = ) THEN false ELSE isnull(kimarite#34139) END OR CASE WHEN (kimarite#34139 = ) THEN true ELSE (kimarite#34139 = NA) END) THEN false ELSE CASE WHEN (kimarite#34139 = ) THEN true ELSE isnotnull(kimarite#34139) END END
[2025-11-12T22:19:46.720+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:46.720+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:19:46.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#34547 = ) THEN false ELSE isnull(kimarite#34547) END OR CASE WHEN (kimarite#34547 = ) THEN true ELSE (kimarite#34547 = NA) END) THEN false ELSE CASE WHEN (kimarite#34547 = ) THEN true ELSE isnotnull(kimarite#34547) END END
[2025-11-12T22:19:46.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:46.723+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO FileSourceStrategy: Post-Scan Filters: CASE WHEN (CASE WHEN (kimarite#34751 = ) THEN false ELSE isnull(kimarite#34751) END OR CASE WHEN (kimarite#34751 = ) THEN true ELSE (kimarite#34751 = NA) END) THEN false ELSE CASE WHEN (kimarite#34751 = ) THEN true ELSE isnotnull(kimarite#34751) END END
[2025-11-12T22:19:46.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO CodeGenerator: Code generated in 4.161181 ms
[2025-11-12T22:19:46.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: Registering RDD 218 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 24
[2025-11-12T22:19:46.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: Got map stage job 53 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:46.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: Final stage: ShuffleMapStage 90 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:46.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:46.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:46.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[218] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:46.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 20.3 KiB, free 433.8 MiB)
[2025-11-12T22:19:46.902+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 9.4 KiB, free 433.8 MiB)
[2025-11-12T22:19:46.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on eb021f2c8a8b:35921 (size: 9.4 KiB, free: 433.8 MiB)
[2025-11-12T22:19:46.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:46.904+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[218] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:46.904+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO TaskSchedulerImpl: Adding task set 90.0 with 2 tasks resource profile 0
[2025-11-12T22:19:46.904+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 77) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 11355 bytes)
[2025-11-12T22:19:46.905+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 78) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 11479 bytes)
[2025-11-12T22:19:46.911+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO CodeGenerator: Code generated in 8.04615 ms
[2025-11-12T22:19:46.914+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.18.0.5:45133 (size: 9.4 KiB, free: 434.4 MiB)
[2025-11-12T22:19:46.915+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 172.18.0.5:40603 (size: 9.4 KiB, free: 434.4 MiB)
[2025-11-12T22:19:46.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO cluster: Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=sumo.jrywipx.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='atlas-efvaxv-shard-0'}
[2025-11-12T22:19:46.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO MongoClientCache: Creating MongoClient: []
[2025-11-12T22:19:46.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO cluster: Cluster description not yet available. Waiting for 30000 ms before timing out
[2025-11-12T22:19:46.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:19:46.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:19:46.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO cluster: Adding discovered server ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017 to client view of cluster
[2025-11-12T22:19:46.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO cluster: No server chosen by com.mongodb.client.internal.MongoClientDelegate$1@1503801b from cluster description ClusterDescription{type=REPLICA_SET, connectionMode=MULTIPLE, serverDescriptions=[ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}, ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=UNKNOWN, state=CONNECTING}]}. Waiting for 30000 ms before timing out
[2025-11-12T22:19:46.977+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 77) in 74 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:19:46.982+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 78) in 78 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:19:46.983+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-11-12T22:19:46.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: ShuffleMapStage 90 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 0.090 s
[2025-11-12T22:19:46.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:46.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: running: Set()
[2025-11-12T22:19:46.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:46.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:46 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:47.266+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO connection: Opened connection [connectionId{localValue:14, serverValue:101930}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:19:47.275+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO connection: Opened connection [connectionId{localValue:15, serverValue:98987}] to ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017
[2025-11-12T22:19:47.281+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO connection: Opened connection [connectionId{localValue:13, serverValue:108452}] to ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017
[2025-11-12T22:19:47.314+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=48024488, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az3'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=7fffffff0000000000000045, setVersion=7, lastWriteDate=Wed Nov 12 22:19:47 UTC 2025, lastUpdateTimeNanos=6908723844751}
[2025-11-12T22:19:47.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=39005496, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az1'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:19:47 UTC 2025, lastUpdateTimeNanos=6908723865352}
[2025-11-12T22:19:47.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO cluster: Setting max election id to 7fffffff0000000000000045 from replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:19:47.315+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO cluster: Setting max set version to 7 from replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:19:47.316+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO cluster: Discovered replica set primary ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:19:47.322+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO cluster: Monitor thread successfully connected to server with description ServerDescription{address=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=40308653, setName='atlas-efvaxv-shard-0', canonicalAddress=ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, hosts=[ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017, ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017], passives=[], arbiters=[], primary='ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017', tagSet=TagSet{[Tag{name='availabilityZone', value='usw2-az2'}, Tag{name='diskState', value='READY'}, Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='US_WEST_2'}, Tag{name='workloadType', value='OPERATIONAL'}]}, electionId=null, setVersion=7, lastWriteDate=Wed Nov 12 22:19:47 UTC 2025, lastUpdateTimeNanos=6908731738294}
[2025-11-12T22:19:47.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO connection: Opened connection [connectionId{localValue:16, serverValue:101907}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017
[2025-11-12T22:19:47.827+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Registering RDD 220 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 25
[2025-11-12T22:19:47.828+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Got map stage job 54 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:47.828+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Final stage: ShuffleMapStage 91 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:47.828+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:47.829+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:47.829+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[220] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:47.829+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 46.3 KiB, free 433.8 MiB)
[2025-11-12T22:19:47.830+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 433.8 MiB)
[2025-11-12T22:19:47.830+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on eb021f2c8a8b:35921 (size: 16.5 KiB, free: 433.8 MiB)
[2025-11-12T22:19:47.830+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:47.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[220] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:47.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0
[2025-11-12T22:19:47.831+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 221.4 KiB, free 433.5 MiB)
[2025-11-12T22:19:47.832+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 79) (172.18.0.5, executor 0, partition 0, ANY, 10279 bytes)
[2025-11-12T22:19:47.834+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.5 MiB)
[2025-11-12T22:19:47.834+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 433.8 MiB)
[2025-11-12T22:19:47.834+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO SparkContext: Created broadcast 87 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:47.835+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:47.836+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 172.18.0.5:45133 (size: 16.5 KiB, free: 434.4 MiB)
[2025-11-12T22:19:47.839+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 221.4 KiB, free 433.3 MiB)
[2025-11-12T22:19:47.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.2 MiB)
[2025-11-12T22:19:47.846+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 433.7 MiB)
[2025-11-12T22:19:47.847+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO SparkContext: Created broadcast 88 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:47.847+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:47.850+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Registering RDD 228 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 26
[2025-11-12T22:19:47.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Got map stage job 55 (javaToPython at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:19:47.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Final stage: ShuffleMapStage 92 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:47.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:47.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:47.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[228] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:47.852+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 26.9 KiB, free 433.2 MiB)
[2025-11-12T22:19:47.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 9.5 KiB, free 433.2 MiB)
[2025-11-12T22:19:47.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on eb021f2c8a8b:35921 (size: 9.5 KiB, free: 433.7 MiB)
[2025-11-12T22:19:47.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:47.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[228] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:19:47.854+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO TaskSchedulerImpl: Adding task set 92.0 with 4 tasks resource profile 0
[2025-11-12T22:19:47.854+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 80) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:19:47.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 221.4 KiB, free 433.0 MiB)
[2025-11-12T22:19:47.861+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.18.0.5:40603 (size: 9.5 KiB, free: 434.4 MiB)
[2025-11-12T22:19:47.863+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 433.0 MiB)
[2025-11-12T22:19:47.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 433.7 MiB)
[2025-11-12T22:19:47.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO SparkContext: Created broadcast 90 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:47.865+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:47.868+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Registering RDD 232 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 27
[2025-11-12T22:19:47.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Got map stage job 56 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:47.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Final stage: ShuffleMapStage 93 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:47.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:47.870+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:47.870+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Submitting ShuffleMapStage 93 (MapPartitionsRDD[232] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:47.870+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:47.870+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 51.7 KiB, free 432.9 MiB)
[2025-11-12T22:19:47.871+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 21.8 KiB, free 432.9 MiB)
[2025-11-12T22:19:47.871+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on eb021f2c8a8b:35921 (size: 21.8 KiB, free: 433.7 MiB)
[2025-11-12T22:19:47.872+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:47.872+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 93 (MapPartitionsRDD[232] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:47.873+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO TaskSchedulerImpl: Adding task set 93.0 with 2 tasks resource profile 0
[2025-11-12T22:19:47.874+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 221.4 KiB, free 432.7 MiB)
[2025-11-12T22:19:47.881+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 432.6 MiB)
[2025-11-12T22:19:47.881+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 433.6 MiB)
[2025-11-12T22:19:47.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO SparkContext: Created broadcast 92 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:19:47.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:19:47.884+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Registering RDD 236 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 28
[2025-11-12T22:19:47.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Got map stage job 57 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:47.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Final stage: ShuffleMapStage 94 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:47.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:47.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:47.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[236] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:47.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 43.2 KiB, free 432.6 MiB)
[2025-11-12T22:19:47.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 18.6 KiB, free 432.6 MiB)
[2025-11-12T22:19:47.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on eb021f2c8a8b:35921 (size: 18.6 KiB, free: 433.6 MiB)
[2025-11-12T22:19:47.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:47.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[236] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:47.888+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO TaskSchedulerImpl: Adding task set 94.0 with 2 tasks resource profile 0
[2025-11-12T22:19:47.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO CodeGenerator: Code generated in 3.013631 ms
[2025-11-12T22:19:47.891+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Registering RDD 238 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 29
[2025-11-12T22:19:47.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Got map stage job 58 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:47.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Final stage: ShuffleMapStage 95 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:47.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:47.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:47.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[238] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:47.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 16.8 KiB, free 432.6 MiB)
[2025-11-12T22:19:47.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 432.5 MiB)
[2025-11-12T22:19:47.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on eb021f2c8a8b:35921 (size: 8.7 KiB, free: 433.6 MiB)
[2025-11-12T22:19:47.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:47.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[238] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:47.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO TaskSchedulerImpl: Adding task set 95.0 with 2 tasks resource profile 0
[2025-11-12T22:19:47.898+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:47 INFO CodeGenerator: Code generated in 4.625501 ms
[2025-11-12T22:19:48.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Registering RDD 240 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 30
[2025-11-12T22:19:48.067+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Got map stage job 59 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:48.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Final stage: ShuffleMapStage 96 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:48.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:19:48.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:48.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[240] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:48.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 28.2 KiB, free 432.5 MiB)
[2025-11-12T22:19:48.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 13.3 KiB, free 432.5 MiB)
[2025-11-12T22:19:48.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on eb021f2c8a8b:35921 (size: 13.3 KiB, free: 433.6 MiB)
[2025-11-12T22:19:48.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:48.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[240] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:48.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0
[2025-11-12T22:19:48.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.104+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.104+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:48.105+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.105+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:48.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.110+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.111+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:48.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:48.116+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.116+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:48.120+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.120+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:48.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.125+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.126+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:48.127+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.127+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:48.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.135+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.135+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:19:48.136+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.136+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:19:48.138+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.138+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.141+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.141+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:19:48.142+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.142+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:19:48.144+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.145+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:19:48.149+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.149+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:19:48.151+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.151+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:19:48.155+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:19:48.439+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 81) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:19:48.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 79) in 609 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:19:48.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-11-12T22:19:48.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: ShuffleMapStage 91 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 0.612 s
[2025-11-12T22:19:48.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:48.442+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: running: Set(ShuffleMapStage 96, ShuffleMapStage 93, ShuffleMapStage 94, ShuffleMapStage 95, ShuffleMapStage 92)
[2025-11-12T22:19:48.442+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:48.442+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:48.445+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 172.18.0.5:45133 (size: 9.5 KiB, free: 434.4 MiB)
[2025-11-12T22:19:48.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:48.473+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO BlockManagerInfo: Removed broadcast_85_piece0 on eb021f2c8a8b:35921 in memory (size: 9.4 KiB, free: 433.6 MiB)
[2025-11-12T22:19:48.474+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.18.0.5:45133 in memory (size: 9.4 KiB, free: 434.3 MiB)
[2025-11-12T22:19:48.475+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 172.18.0.5:40603 in memory (size: 9.4 KiB, free: 434.4 MiB)
[2025-11-12T22:19:48.478+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO BlockManagerInfo: Removed broadcast_86_piece0 on eb021f2c8a8b:35921 in memory (size: 16.5 KiB, free: 433.6 MiB)
[2025-11-12T22:19:48.478+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 172.18.0.5:45133 in memory (size: 16.5 KiB, free: 434.4 MiB)
[2025-11-12T22:19:48.490+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.491+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.493+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:48.495+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.495+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:48.497+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.498+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.504+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.505+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:48.506+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.506+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:48.511+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.511+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.514+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.515+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:48.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.516+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:48.519+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.520+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.523+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.523+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:48.524+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.525+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:48.529+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.530+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.532+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.533+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:19:48.534+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.534+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:19:48.536+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.536+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.539+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.540+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:19:48.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.541+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:19:48.543+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.546+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.547+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:19:48.548+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.548+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:19:48.549+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:48.550+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:48.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:48.553+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:19:48.554+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:48.554+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:19:48.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO ShufflePartitionsUtil: For shuffle(25), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:48.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:48.634+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Got job 60 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:19:48.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Final stage: ResultStage 98 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:48.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
[2025-11-12T22:19:48.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:48.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[242] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:48.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 8.2 KiB, free 432.6 MiB)
[2025-11-12T22:19:48.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 432.6 MiB)
[2025-11-12T22:19:48.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on eb021f2c8a8b:35921 (size: 4.2 KiB, free: 433.6 MiB)
[2025-11-12T22:19:48.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:48.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[242] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:48.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:48 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0
[2025-11-12T22:19:50.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:50 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 82) (172.18.0.5, executor 0, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:19:50.664+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:50 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 81) in 2226 ms on 172.18.0.5 (executor 0) (1/4)
[2025-11-12T22:19:50.673+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:50 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:50.769+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:50 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 83) (172.18.0.5, executor 1, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:19:50.769+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:50 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 80) in 2915 ms on 172.18.0.5 (executor 1) (2/4)
[2025-11-12T22:19:50.778+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:50 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:52.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:52 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 84) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:19:52.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:52 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 83) in 2124 ms on 172.18.0.5 (executor 1) (3/4)
[2025-11-12T22:19:52.898+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:52 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.18.0.5:40603 (size: 21.8 KiB, free: 434.3 MiB)
[2025-11-12T22:19:52.913+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:52 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:53.150+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO MongoClientCache: Closing MongoClient: [ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017,ac-et3nnqq-shard-00-01.jrywipx.mongodb.net:27017,ac-et3nnqq-shard-00-00.jrywipx.mongodb.net:27017]
[2025-11-12T22:19:53.194+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO connection: Closed connection [connectionId{localValue:16, serverValue:101907}] to ac-et3nnqq-shard-00-02.jrywipx.mongodb.net:27017 because the pool has been closed.
[2025-11-12T22:19:53.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 85) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:19:53.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 82) in 2917 ms on 172.18.0.5 (executor 0) (4/4)
[2025-11-12T22:19:53.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool
[2025-11-12T22:19:53.583+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: ShuffleMapStage 92 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 5.730 s
[2025-11-12T22:19:53.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:53.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: running: Set(ShuffleMapStage 96, ShuffleMapStage 93, ShuffleMapStage 94, ResultStage 98, ShuffleMapStage 95)
[2025-11-12T22:19:53.584+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:53.585+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:53.588+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 172.18.0.5:45133 (size: 21.8 KiB, free: 434.3 MiB)
[2025-11-12T22:19:53.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:53.602+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:53.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 434.3 MiB)
[2025-11-12T22:19:53.605+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:53.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:53.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:53.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:53.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:53.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:53.613+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:53.614+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:53.615+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:53.615+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:53.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:53.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:53.623+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:53.623+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:53.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:53.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:53.627+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:53.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:53.630+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:53.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:53.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:53.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:53.638+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:53.638+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:53.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:53.642+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:19:53.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:53.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:19:53.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:53.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:53.651+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:53.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:19:53.654+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:53.654+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:19:53.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:53.659+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:53.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:53.664+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:19:53.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:53.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:19:53.669+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:53.669+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:53.674+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:53.674+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:19:53.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:53.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:19:53.728+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:19:53.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:19:53.731+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:19:53.732+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:19:53.733+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:19:53.734+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 12067996, minimum partition size: 1048576
[2025-11-12T22:19:53.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO CodeGenerator: Code generated in 10.253345 ms
[2025-11-12T22:19:53.754+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO CodeGenerator: Code generated in 3.625858 ms
[2025-11-12T22:19:53.758+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Registering RDD 247 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 31
[2025-11-12T22:19:53.759+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Got map stage job 61 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:53.759+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Final stage: ShuffleMapStage 100 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:53.759+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)
[2025-11-12T22:19:53.760+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:53.760+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[247] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:53.761+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 63.1 KiB, free 432.5 MiB)
[2025-11-12T22:19:53.761+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 432.5 MiB)
[2025-11-12T22:19:53.765+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on eb021f2c8a8b:35921 (size: 27.5 KiB, free: 433.6 MiB)
[2025-11-12T22:19:53.765+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:53.765+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[247] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:53.766+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO TaskSchedulerImpl: Adding task set 100.0 with 2 tasks resource profile 0
[2025-11-12T22:19:53.778+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO CodeGenerator: Code generated in 16.935635 ms
[2025-11-12T22:19:53.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO CodeGenerator: Code generated in 3.984173 ms
[2025-11-12T22:19:53.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Registering RDD 252 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 32
[2025-11-12T22:19:53.790+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Got map stage job 62 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:19:53.790+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Final stage: ShuffleMapStage 101 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:53.791+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 99)
[2025-11-12T22:19:53.791+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:53.791+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[252] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:53.792+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 64.3 KiB, free 432.4 MiB)
[2025-11-12T22:19:53.797+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 432.4 MiB)
[2025-11-12T22:19:53.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on eb021f2c8a8b:35921 (size: 28.0 KiB, free: 433.6 MiB)
[2025-11-12T22:19:53.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:53.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[252] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:53.799+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:53 INFO TaskSchedulerImpl: Adding task set 101.0 with 2 tasks resource profile 0
[2025-11-12T22:19:54.929+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:54 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 86) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:19:54.930+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:54 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 84) in 2038 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:19:54.935+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:54 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.18.0.5:40603 (size: 18.6 KiB, free: 434.2 MiB)
[2025-11-12T22:19:54.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:54 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:55.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO TaskSetManager: Starting task 1.0 in stage 94.0 (TID 87) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:19:55.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 85) in 2223 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:19:55.803+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool
[2025-11-12T22:19:55.803+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: ShuffleMapStage 93 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 7.933 s
[2025-11-12T22:19:55.803+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:55.804+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: running: Set(ShuffleMapStage 96, ShuffleMapStage 100, ShuffleMapStage 101, ShuffleMapStage 94, ResultStage 98, ShuffleMapStage 95)
[2025-11-12T22:19:55.804+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:55.804+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:55.807+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 172.18.0.5:45133 (size: 18.6 KiB, free: 434.2 MiB)
[2025-11-12T22:19:55.820+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:55.828+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:55.829+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:55.833+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:55.834+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:55.835+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:55.836+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:55.838+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:55.839+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:55.842+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:55.842+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:55.843+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:55.843+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:55.847+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:55.847+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:55.849+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:55.850+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:55.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:55.851+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:55.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:55.853+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:55.856+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:55.856+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:55.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:55.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:55.861+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:55.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:55.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:55.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:19:55.865+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:55.865+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:19:55.867+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:55.867+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:55.871+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:55.871+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:19:55.873+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:55.873+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:19:55.876+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:55.876+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:55.880+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:55.880+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:19:55.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:55.883+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:19:55.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:55.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:55.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:55.890+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:19:55.891+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:55.891+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:19:55.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.950+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.951+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.952+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.953+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.954+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.956+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.958+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.959+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.960+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.961+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.962+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.963+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.964+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.965+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.966+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO ShufflePartitionsUtil: For shuffle(27), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:55.967+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:19:55.979+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO CodeGenerator: Code generated in 9.555315 ms
[2025-11-12T22:19:55.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: Registering RDD 256 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 33
[2025-11-12T22:19:55.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: Got map stage job 63 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:55.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: Final stage: ShuffleMapStage 103 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:55.985+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
[2025-11-12T22:19:55.986+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:55.986+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: Submitting ShuffleMapStage 103 (MapPartitionsRDD[256] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:55.988+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 70.1 KiB, free 432.3 MiB)
[2025-11-12T22:19:55.992+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 432.3 MiB)
[2025-11-12T22:19:55.995+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on eb021f2c8a8b:35921 (size: 27.6 KiB, free: 433.5 MiB)
[2025-11-12T22:19:55.995+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:55.996+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 103 (MapPartitionsRDD[256] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:55.996+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:55 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
[2025-11-12T22:19:56.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:56.026+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:56.029+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:56.029+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:56.031+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:56.031+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:56.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:56.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:56.040+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:56.041+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:56.043+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:56.043+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:56.049+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:56.050+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:56.053+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:56.054+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:56.055+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:56.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:56.060+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:56.060+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:56.064+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:56.064+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:56.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:56.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:56.074+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:56.075+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:56.078+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:56.079+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:19:56.080+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:56.080+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:19:56.083+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:56.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:56.086+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:56.086+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:19:56.087+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:56.088+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:19:56.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:56.093+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:56.098+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:56.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:19:56.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:56.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:19:56.111+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:56.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:56.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO BlockManagerInfo: Removed broadcast_89_piece0 on eb021f2c8a8b:35921 in memory (size: 9.5 KiB, free: 433.6 MiB)
[2025-11-12T22:19:56.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.18.0.5:40603 in memory (size: 9.5 KiB, free: 434.2 MiB)
[2025-11-12T22:19:56.116+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:56.116+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:19:56.118+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 172.18.0.5:45133 in memory (size: 9.5 KiB, free: 434.2 MiB)
[2025-11-12T22:19:56.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:56.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:19:56.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO BlockManagerInfo: Removed broadcast_91_piece0 on eb021f2c8a8b:35921 in memory (size: 21.8 KiB, free: 433.6 MiB)
[2025-11-12T22:19:56.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.18.0.5:45133 in memory (size: 21.8 KiB, free: 434.2 MiB)
[2025-11-12T22:19:56.123+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:56 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 172.18.0.5:40603 in memory (size: 21.8 KiB, free: 434.2 MiB)
[2025-11-12T22:19:57.023+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 88) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 11355 bytes)
[2025-11-12T22:19:57.023+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 86) in 2094 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:19:57.028+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 172.18.0.5:40603 (size: 8.7 KiB, free: 434.2 MiB)
[2025-11-12T22:19:57.081+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 89) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11479 bytes)
[2025-11-12T22:19:57.082+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 88) in 59 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:19:57.134+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 90) (172.18.0.5, executor 1, partition 0, ANY, 10279 bytes)
[2025-11-12T22:19:57.135+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 89) in 54 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:19:57.136+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool
[2025-11-12T22:19:57.136+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: ShuffleMapStage 95 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 9.243 s
[2025-11-12T22:19:57.136+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:57.136+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: running: Set(ShuffleMapStage 96, ShuffleMapStage 103, ShuffleMapStage 100, ShuffleMapStage 101, ShuffleMapStage 94, ResultStage 98)
[2025-11-12T22:19:57.137+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:57.137+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:57.140+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 172.18.0.5:40603 (size: 13.3 KiB, free: 434.2 MiB)
[2025-11-12T22:19:57.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.179+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.180+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.181+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:57.181+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.182+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:57.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:57.187+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.187+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:57.191+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.191+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.193+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.193+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:57.194+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.194+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:57.196+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.196+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.198+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.199+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:57.199+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.200+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:57.204+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.204+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.206+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.206+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:19:57.207+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.207+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:19:57.209+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.209+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.212+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.212+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:19:57.213+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.213+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:19:57.216+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.216+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.218+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.218+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:19:57.219+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.219+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:19:57.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.224+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:19:57.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:19:57.879+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 91) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10152 bytes)
[2025-11-12T22:19:57.880+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 90) in 745 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:57.880+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool
[2025-11-12T22:19:57.881+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: ShuffleMapStage 96 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 9.813 s
[2025-11-12T22:19:57.881+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:57.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: running: Set(ShuffleMapStage 103, ShuffleMapStage 100, ShuffleMapStage 101, ShuffleMapStage 94, ResultStage 98)
[2025-11-12T22:19:57.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:57.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:57.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 172.18.0.5:40603 (size: 4.2 KiB, free: 434.2 MiB)
[2025-11-12T22:19:57.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to 172.18.0.5:34292
[2025-11-12T22:19:57.891+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 92) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:57.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 91) in 12 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:19:57.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool
[2025-11-12T22:19:57.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: ResultStage 98 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 9.260 s
[2025-11-12T22:19:57.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:19:57.893+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished
[2025-11-12T22:19:57.894+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: Job 60 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 9.261524 s
[2025-11-12T22:19:57.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 191.0 B, free 432.4 MiB)
[2025-11-12T22:19:57.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on eb021f2c8a8b:35921 (size: 191.0 B, free: 433.6 MiB)
[2025-11-12T22:19:57.896+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO SparkContext: Created broadcast 100 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:57.897+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.18.0.5:40603 (size: 27.5 KiB, free: 434.2 MiB)
[2025-11-12T22:19:57.904+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.18.0.5:34292
[2025-11-12T22:19:57.905+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO BlockManagerInfo: Removed broadcast_96_piece0 on eb021f2c8a8b:35921 in memory (size: 4.2 KiB, free: 433.6 MiB)
[2025-11-12T22:19:57.906+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 172.18.0.5:40603 in memory (size: 4.2 KiB, free: 434.2 MiB)
[2025-11-12T22:19:57.922+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.923+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.925+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.926+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:57.927+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.927+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:57.930+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Starting task 1.0 in stage 100.0 (TID 93) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:57.931+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSetManager: Finished task 1.0 in stage 94.0 (TID 87) in 2130 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:19:57.934+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool
[2025-11-12T22:19:57.934+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: ShuffleMapStage 94 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 10.046 s
[2025-11-12T22:19:57.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:57.943+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: running: Set(ShuffleMapStage 103, ShuffleMapStage 100, ShuffleMapStage 101)
[2025-11-12T22:19:57.943+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:57.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:57.944+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:57.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:57.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 172.18.0.5:45133 (size: 27.5 KiB, free: 434.2 MiB)
[2025-11-12T22:19:57.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to 172.18.0.5:34294
[2025-11-12T22:19:57.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.956+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:57.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.957+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:57.960+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.960+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.964+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.965+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:57.966+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.966+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:57.974+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.974+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.978+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.979+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:19:57.980+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.981+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:19:57.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.984+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.987+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.988+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:19:57.989+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.990+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:19:57.994+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:57.994+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:57.996+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:57.997+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:19:57.998+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:57.998+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:19:58.000+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:57 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:58.000+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:58.002+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:58.003+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:19:58.004+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:58.004+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:19:58.035+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(29, 30), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.051+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO CodeGenerator: Code generated in 6.875699 ms
[2025-11-12T22:19:58.056+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO CodeGenerator: Code generated in 3.379147 ms
[2025-11-12T22:19:58.067+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Registering RDD 263 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 34
[2025-11-12T22:19:58.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Got map stage job 64 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:58.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Final stage: ShuffleMapStage 106 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:58.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104, ShuffleMapStage 105)
[2025-11-12T22:19:58.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:58.069+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[263] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:58.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 60.5 KiB, free 432.4 MiB)
[2025-11-12T22:19:58.071+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 432.3 MiB)
[2025-11-12T22:19:58.072+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on eb021f2c8a8b:35921 (size: 27.5 KiB, free: 433.5 MiB)
[2025-11-12T22:19:58.072+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:58.072+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[263] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:58.072+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
[2025-11-12T22:19:58.094+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:58.095+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:58.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:58.097+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:58.099+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:58.099+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:58.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:58.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:58.105+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:58.105+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:58.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:58.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:58.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:58.114+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:58.117+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:58.118+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:58.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:58.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:58.126+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:58.127+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:58.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:58.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:58.133+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:58.133+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:58.142+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:58.143+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:58.147+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:58.147+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:19:58.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:58.149+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:19:58.152+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:58.152+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:58.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:58.156+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:19:58.157+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:58.158+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:19:58.162+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:58.162+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:58.166+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:58.166+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:19:58.167+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:58.168+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:19:58.171+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:58.171+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:58.175+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:58.175+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:19:58.177+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:58.177+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:19:58.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.224+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.225+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.228+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.229+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.230+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.231+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.232+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO ShufflePartitionsUtil: For shuffle(28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:19:58.234+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO TorrentBroadcast: Started reading broadcast variable 100 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:19:58.234+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO TorrentBroadcast: Reading broadcast variable 100 took 0 ms
[2025-11-12T22:19:58.245+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO CodeGenerator: Code generated in 10.760167 ms
[2025-11-12T22:19:58.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:58.253+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Got job 65 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:19:58.254+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Final stage: ResultStage 108 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:58.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107)
[2025-11-12T22:19:58.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO CodeGenerator: Code generated in 9.619817 ms
[2025-11-12T22:19:58.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:58.256+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[266] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:58.256+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 44.9 KiB, free 432.3 MiB)
[2025-11-12T22:19:58.257+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 20.0 KiB, free 432.3 MiB)
[2025-11-12T22:19:58.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on eb021f2c8a8b:35921 (size: 20.0 KiB, free: 433.5 MiB)
[2025-11-12T22:19:58.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:58.259+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[266] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:58.259+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0
[2025-11-12T22:19:58.259+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Registering RDD 269 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 35
[2025-11-12T22:19:58.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Got map stage job 66 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:19:58.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Final stage: ShuffleMapStage 110 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:19:58.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)
[2025-11-12T22:19:58.261+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:58.261+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[269] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:19:58.262+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 24.4 KiB, free 432.3 MiB)
[2025-11-12T22:19:58.262+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 432.2 MiB)
[2025-11-12T22:19:58.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on eb021f2c8a8b:35921 (size: 10.1 KiB, free: 433.5 MiB)
[2025-11-12T22:19:58.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:58.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[269] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:19:58.264+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:58 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks resource profile 0
[2025-11-12T22:19:59.586+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 94) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:59.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 92) in 1695 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:19:59.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.18.0.5:40603 (size: 28.0 KiB, free: 434.2 MiB)
[2025-11-12T22:19:59.598+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 95) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:19:59.599+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO TaskSetManager: Finished task 1.0 in stage 100.0 (TID 93) in 1669 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:19:59.600+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-11-12T22:19:59.600+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: ShuffleMapStage 100 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 5.839 s
[2025-11-12T22:19:59.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:19:59.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: running: Set(ShuffleMapStage 103, ShuffleMapStage 101, ResultStage 108, ShuffleMapStage 106, ShuffleMapStage 110)
[2025-11-12T22:19:59.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:19:59.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: failed: Set()
[2025-11-12T22:19:59.608+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 172.18.0.5:45133 (size: 28.0 KiB, free: 434.2 MiB)
[2025-11-12T22:19:59.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:59.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:59.637+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:59.638+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:19:59.638+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:59.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:19:59.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:59.639+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:59.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:59.641+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:19:59.642+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:59.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:19:59.646+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:59.647+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:59.648+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:59.649+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:19:59.650+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:59.650+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:19:59.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:59.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:59.655+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:59.655+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:19:59.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:59.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:19:59.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:59.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:59.664+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:59.664+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:19:59.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:59.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:19:59.667+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:59.667+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:59.669+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:59.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:19:59.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:59.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:19:59.673+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:59.673+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:59.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:59.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:19:59.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:59.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:19:59.678+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:19:59.678+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:19:59.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:19:59.682+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:19:59.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:19:59.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:19:59.728+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:19:59.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:19:59.730+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 2759130, minimum partition size: 1048576
[2025-11-12T22:19:59.732+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:19:59.740+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO CodeGenerator: Code generated in 6.502082 ms
[2025-11-12T22:19:59.748+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:19:59.748+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: Got job 67 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-11-12T22:19:59.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: Final stage: ResultStage 112 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:19:59.749+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 111)
[2025-11-12T22:19:59.750+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:19:59.750+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[272] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:19:59.751+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 60.2 KiB, free 432.2 MiB)
[2025-11-12T22:19:59.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 26.0 KiB, free 432.2 MiB)
[2025-11-12T22:19:59.752+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on eb021f2c8a8b:35921 (size: 26.0 KiB, free: 433.5 MiB)
[2025-11-12T22:19:59.753+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:19:59.753+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 112 (MapPartitionsRDD[272] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:19:59.753+0000] {spark_submit.py:571} INFO - 25/11/12 22:19:59 INFO TaskSchedulerImpl: Adding task set 112.0 with 2 tasks resource profile 0
[2025-11-12T22:20:01.042+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 96) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:20:01.043+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 94) in 1456 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:20:01.048+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 172.18.0.5:40603 (size: 27.6 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.053+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to 172.18.0.5:34292
[2025-11-12T22:20:01.118+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 97) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10404 bytes)
[2025-11-12T22:20:01.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 95) in 1520 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:20:01.120+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool
[2025-11-12T22:20:01.120+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: ShuffleMapStage 101 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 7.329 s
[2025-11-12T22:20:01.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:01.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: running: Set(ShuffleMapStage 103, ResultStage 108, ResultStage 112, ShuffleMapStage 106, ShuffleMapStage 110)
[2025-11-12T22:20:01.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:01.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:01.128+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 172.18.0.5:45133 (size: 27.5 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.144+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to 172.18.0.5:34294
[2025-11-12T22:20:01.174+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.175+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.177+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:20:01.179+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.180+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:20:01.180+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to 172.18.0.5:34294
[2025-11-12T22:20:01.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.187+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:20:01.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 98) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:01.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 96) in 147 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:20:01.191+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.191+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:20:01.191+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-11-12T22:20:01.192+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: ShuffleMapStage 103 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 5.203 s
[2025-11-12T22:20:01.192+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:01.192+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: running: Set(ResultStage 108, ResultStage 112, ShuffleMapStage 106, ShuffleMapStage 110)
[2025-11-12T22:20:01.193+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:01.193+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:01.196+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.196+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.197+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 172.18.0.5:40603 (size: 20.0 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.200+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.200+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:20:01.201+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.202+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:20:01.202+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to 172.18.0.5:34292
[2025-11-12T22:20:01.209+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.210+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.213+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.214+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:20:01.215+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.215+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:20:01.219+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 99) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10138 bytes)
[2025-11-12T22:20:01.220+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 97) in 103 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:20:01.220+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool
[2025-11-12T22:20:01.220+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: ShuffleMapStage 106 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 3.152 s
[2025-11-12T22:20:01.220+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:01.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: running: Set(ResultStage 108, ResultStage 112, ShuffleMapStage 110)
[2025-11-12T22:20:01.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:01.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:01.221+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.222+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.223+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.224+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:20:01.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.226+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:20:01.227+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 172.18.0.5:45133 (size: 10.1 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.229+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.230+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.233+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.234+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:20:01.235+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to 172.18.0.5:34294
[2025-11-12T22:20:01.235+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.236+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:20:01.240+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.241+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 100) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:01.243+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 98) in 55 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:20:01.244+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool
[2025-11-12T22:20:01.245+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: ResultStage 108 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 2.989 s
[2025-11-12T22:20:01.245+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:20:01.246+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 108: Stage finished
[2025-11-12T22:20:01.246+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Job 65 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 2.991809 s
[2025-11-12T22:20:01.248+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.250+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:20:01.251+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.253+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:20:01.256+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 47.0 KiB, free 432.1 MiB)
[2025-11-12T22:20:01.257+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on eb021f2c8a8b:35921 (size: 47.0 KiB, free: 433.4 MiB)
[2025-11-12T22:20:01.257+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_102_piece0 on eb021f2c8a8b:35921 in memory (size: 20.0 KiB, free: 433.5 MiB)
[2025-11-12T22:20:01.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 105 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:01.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 172.18.0.5:40603 in memory (size: 20.0 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.259+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 172.18.0.5:45133 (size: 191.0 B, free: 434.1 MiB)
[2025-11-12T22:20:01.259+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.259+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.18.0.5:40603 (size: 26.0 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_101_piece0 on eb021f2c8a8b:35921 in memory (size: 27.5 KiB, free: 433.5 MiB)
[2025-11-12T22:20:01.260+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 172.18.0.5:45133 in memory (size: 27.5 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.264+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.265+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:20:01.266+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.18.0.5:34292
[2025-11-12T22:20:01.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.272+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:20:01.282+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 1.0 in stage 112.0 (TID 101) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:01.283+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 99) in 64 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:20:01.283+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool
[2025-11-12T22:20:01.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: ShuffleMapStage 110 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 3.022 s
[2025-11-12T22:20:01.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:01.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: running: Set(ResultStage 112)
[2025-11-12T22:20:01.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:01.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:01.288+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 172.18.0.5:45133 (size: 26.0 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to 172.18.0.5:34294
[2025-11-12T22:20:01.319+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(32), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:20:01.320+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(32), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:20:01.321+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(32), advisory target size: 67108864, actual target size 2767962, minimum partition size: 1048576
[2025-11-12T22:20:01.324+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:20:01.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO CodeGenerator: Code generated in 6.862699 ms
[2025-11-12T22:20:01.340+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:01.341+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Got job 68 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-11-12T22:20:01.341+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Final stage: ResultStage 114 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:20:01.342+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
[2025-11-12T22:20:01.342+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:01.342+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[275] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:20:01.344+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 61.5 KiB, free 432.2 MiB)
[2025-11-12T22:20:01.350+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 26.4 KiB, free 432.2 MiB)
[2025-11-12T22:20:01.350+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on eb021f2c8a8b:35921 (size: 26.4 KiB, free: 433.5 MiB)
[2025-11-12T22:20:01.351+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:01.351+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_103_piece0 on eb021f2c8a8b:35921 in memory (size: 10.1 KiB, free: 433.5 MiB)
[2025-11-12T22:20:01.352+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 114 (MapPartitionsRDD[275] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:20:01.352+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Adding task set 114.0 with 2 tasks resource profile 0
[2025-11-12T22:20:01.352+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 172.18.0.5:45133 in memory (size: 10.1 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.380+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.381+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.387+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.388+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:20:01.391+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.391+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:20:01.394+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added taskresult_100 in memory on 172.18.0.5:40603 (size: 1232.2 KiB, free: 432.9 MiB)
[2025-11-12T22:20:01.396+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.396+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.396+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 102) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:01.402+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 100) in 159 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:20:01.403+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed taskresult_100 on 172.18.0.5:40603 in memory (size: 1232.2 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.404+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.404+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.18.0.5:40603 (size: 26.4 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.405+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:20:01.407+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.407+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:20:01.408+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.18.0.5:34292
[2025-11-12T22:20:01.419+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.420+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.421+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added taskresult_101 in memory on 172.18.0.5:45133 (size: 1257.7 KiB, free: 432.9 MiB)
[2025-11-12T22:20:01.421+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 103) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:01.424+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.426+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:20:01.427+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.428+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:20:01.428+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 1.0 in stage 112.0 (TID 101) in 146 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:20:01.429+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool
[2025-11-12T22:20:01.429+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: ResultStage 112 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 1.677 s
[2025-11-12T22:20:01.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:20:01.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 112: Stage finished
[2025-11-12T22:20:01.430+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Job 67 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 1.679875 s
[2025-11-12T22:20:01.431+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed taskresult_101 on 172.18.0.5:45133 in memory (size: 1257.7 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.431+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 172.18.0.5:45133 (size: 26.4 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.431+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.432+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.434+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.435+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:20:01.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to 172.18.0.5:34294
[2025-11-12T22:20:01.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.437+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:20:01.456+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.461+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.462+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:20:01.463+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.463+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:20:01.466+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.467+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.471+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.472+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:20:01.474+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.474+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:20:01.478+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.479+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.483+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.483+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:20:01.486+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.487+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:20:01.494+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.495+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.500+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.501+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:20:01.504+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.504+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:20:01.544+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 428.2 MiB)
[2025-11-12T22:20:01.545+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on eb021f2c8a8b:35921 (size: 4.0 MiB, free: 429.5 MiB)
[2025-11-12T22:20:01.545+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_107_piece1 stored as bytes in memory (estimated size 1049.4 KiB, free 427.2 MiB)
[2025-11-12T22:20:01.545+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_107_piece1 in memory on eb021f2c8a8b:35921 (size: 1049.4 KiB, free: 428.5 MiB)
[2025-11-12T22:20:01.545+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 107 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:01.556+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added taskresult_102 in memory on 172.18.0.5:40603 (size: 1247.9 KiB, free: 432.9 MiB)
[2025-11-12T22:20:01.563+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 102) in 167 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:20:01.565+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed taskresult_102 on 172.18.0.5:40603 in memory (size: 1247.9 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_99_piece0 on eb021f2c8a8b:35921 in memory (size: 27.6 KiB, free: 428.5 MiB)
[2025-11-12T22:20:01.587+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 172.18.0.5:40603 in memory (size: 27.6 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.589+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_97_piece0 on eb021f2c8a8b:35921 in memory (size: 27.5 KiB, free: 428.5 MiB)
[2025-11-12T22:20:01.590+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.18.0.5:40603 in memory (size: 27.5 KiB, free: 434.1 MiB)
[2025-11-12T22:20:01.591+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 172.18.0.5:45133 in memory (size: 27.5 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_98_piece0 on eb021f2c8a8b:35921 in memory (size: 28.0 KiB, free: 428.5 MiB)
[2025-11-12T22:20:01.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.18.0.5:40603 in memory (size: 28.0 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.593+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 172.18.0.5:45133 in memory (size: 28.0 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_95_piece0 on eb021f2c8a8b:35921 in memory (size: 13.3 KiB, free: 428.5 MiB)
[2025-11-12T22:20:01.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 172.18.0.5:40603 in memory (size: 13.3 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.597+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_94_piece0 on eb021f2c8a8b:35921 in memory (size: 8.7 KiB, free: 428.6 MiB)
[2025-11-12T22:20:01.598+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 172.18.0.5:40603 in memory (size: 8.7 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.599+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.600+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_93_piece0 on eb021f2c8a8b:35921 in memory (size: 18.6 KiB, free: 428.6 MiB)
[2025-11-12T22:20:01.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.18.0.5:40603 in memory (size: 18.6 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.601+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 172.18.0.5:45133 in memory (size: 18.6 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.602+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.604+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.604+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added taskresult_103 in memory on 172.18.0.5:45133 (size: 1247.8 KiB, free: 433.0 MiB)
[2025-11-12T22:20:01.605+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.607+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.609+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.610+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 103) in 189 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:20:01.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool
[2025-11-12T22:20:01.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: ResultStage 114 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.269 s
[2025-11-12T22:20:01.611+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:20:01.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 114: Stage finished
[2025-11-12T22:20:01.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Job 68 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.270861 s
[2025-11-12T22:20:01.612+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.613+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed taskresult_103 on 172.18.0.5:45133 in memory (size: 1247.8 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.613+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.615+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.616+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.617+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.619+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.620+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.621+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.622+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.623+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.624+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.627+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.630+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.631+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.633+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.635+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.636+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:01.657+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO CodeGenerator: Code generated in 9.488113 ms
[2025-11-12T22:20:01.658+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO CodeGenerator: Code generated in 10.10204 ms
[2025-11-12T22:20:01.664+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:01.665+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Got job 69 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:20:01.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Final stage: ResultStage 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:20:01.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
[2025-11-12T22:20:01.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:01.666+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:01.667+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[281] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:20:01.669+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 69.6 KiB, free 427.5 MiB)
[2025-11-12T22:20:01.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 27.4 KiB, free 427.5 MiB)
[2025-11-12T22:20:01.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on eb021f2c8a8b:35921 (size: 27.4 KiB, free: 428.5 MiB)
[2025-11-12T22:20:01.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:01.670+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[281] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:20:01.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0
[2025-11-12T22:20:01.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Got job 70 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:20:01.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Final stage: ResultStage 118 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:20:01.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
[2025-11-12T22:20:01.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:01.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 104) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:01.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[283] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:20:01.674+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 66.8 KiB, free 427.4 MiB)
[2025-11-12T22:20:01.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 26.9 KiB, free 427.4 MiB)
[2025-11-12T22:20:01.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on eb021f2c8a8b:35921 (size: 26.9 KiB, free: 428.5 MiB)
[2025-11-12T22:20:01.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:01.675+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[283] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:20:01.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks resource profile 0
[2025-11-12T22:20:01.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 105) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:01.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:20:01.678+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.678+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:20:01.679+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 172.18.0.5:45133 (size: 27.4 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.680+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:20:01.687+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:20:01.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 172.18.0.5:40603 (size: 26.9 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.18.0.5:34294
[2025-11-12T22:20:01.688+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.689+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:20:01.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to 172.18.0.5:34292
[2025-11-12T22:20:01.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.690+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:20:01.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.691+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.693+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:20:01.693+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.693+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:20:01.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:20:01.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.702+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:20:01.703+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.704+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:20:01.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:20:01.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 4.0 MiB, free 423.4 MiB)
[2025-11-12T22:20:01.707+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on eb021f2c8a8b:35921 (size: 4.0 MiB, free: 424.5 MiB)
[2025-11-12T22:20:01.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_110_piece1 stored as bytes in memory (estimated size 1055.1 KiB, free 422.4 MiB)
[2025-11-12T22:20:01.708+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_110_piece1 in memory on eb021f2c8a8b:35921 (size: 1055.1 KiB, free: 423.5 MiB)
[2025-11-12T22:20:01.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 110 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:01.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:20:01.710+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.711+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:20:01.712+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.712+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.713+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.713+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:20:01.713+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.713+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:20:01.721+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 105) in 45 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:20:01.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-11-12T22:20:01.723+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: ResultStage 118 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.049 s
[2025-11-12T22:20:01.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:20:01.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 118: Stage finished
[2025-11-12T22:20:01.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Job 70 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.056184 s
[2025-11-12T22:20:01.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 104) in 51 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:20:01.725+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool
[2025-11-12T22:20:01.726+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: ResultStage 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.056 s
[2025-11-12T22:20:01.726+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:20:01.726+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished
[2025-11-12T22:20:01.727+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Job 69 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.059082 s
[2025-11-12T22:20:01.727+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 56.1 KiB, free 422.3 MiB)
[2025-11-12T22:20:01.728+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 90.5 KiB, free 422.2 MiB)
[2025-11-12T22:20:01.728+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on eb021f2c8a8b:35921 (size: 56.1 KiB, free: 423.4 MiB)
[2025-11-12T22:20:01.728+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on eb021f2c8a8b:35921 (size: 90.5 KiB, free: 423.3 MiB)
[2025-11-12T22:20:01.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 111 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:01.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 112 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:01.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.779+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.780+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.780+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#4526L)
[2025-11-12T22:20:01.780+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.780+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#3836L)
[2025-11-12T22:20:01.781+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#9401L)
[2025-11-12T22:20:01.782+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#10008L)
[2025-11-12T22:20:01.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#11725L)
[2025-11-12T22:20:01.787+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.787+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#12332L)
[2025-11-12T22:20:01.788+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.788+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#16009L)
[2025-11-12T22:20:01.789+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.790+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#16616L)
[2025-11-12T22:20:01.793+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#23329L)
[2025-11-12T22:20:01.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#23936L)
[2025-11-12T22:20:01.796+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.796+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.796+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.797+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#27613L)
[2025-11-12T22:20:01.797+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#28220L)
[2025-11-12T22:20:01.800+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.800+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.801+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.801+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#29449L)
[2025-11-12T22:20:01.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.802+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#30056L)
[2025-11-12T22:20:01.803+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters:
[2025-11-12T22:20:01.803+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-12T22:20:01.804+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(westId)
[2025-11-12T22:20:01.804+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(westId#33733L)
[2025-11-12T22:20:01.804+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Pushed Filters: IsNotNull(eastId)
[2025-11-12T22:20:01.805+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(eastId#34340L)
[2025-11-12T22:20:01.839+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Started reading broadcast variable 107 with 2 pieces (estimated total size 8.0 MiB)
[2025-11-12T22:20:01.840+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Reading broadcast variable 107 took 0 ms
[2025-11-12T22:20:01.841+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_109_piece0 on eb021f2c8a8b:35921 in memory (size: 26.9 KiB, free: 423.4 MiB)
[2025-11-12T22:20:01.841+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 172.18.0.5:40603 in memory (size: 26.9 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.843+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_106_piece0 on eb021f2c8a8b:35921 in memory (size: 26.4 KiB, free: 423.4 MiB)
[2025-11-12T22:20:01.843+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.18.0.5:40603 in memory (size: 26.4 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.844+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 172.18.0.5:45133 in memory (size: 26.4 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.845+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_104_piece0 on eb021f2c8a8b:35921 in memory (size: 26.0 KiB, free: 423.4 MiB)
[2025-11-12T22:20:01.846+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.18.0.5:45133 in memory (size: 26.0 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.846+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 172.18.0.5:40603 in memory (size: 26.0 KiB, free: 434.3 MiB)
[2025-11-12T22:20:01.847+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_108_piece0 on eb021f2c8a8b:35921 in memory (size: 27.4 KiB, free: 423.5 MiB)
[2025-11-12T22:20:01.848+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 172.18.0.5:45133 in memory (size: 27.4 KiB, free: 434.3 MiB)
[2025-11-12T22:20:01.857+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Started reading broadcast variable 112 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:20:01.858+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Reading broadcast variable 112 took 0 ms
[2025-11-12T22:20:01.860+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Started reading broadcast variable 111 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:20:01.860+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Reading broadcast variable 111 took 0 ms
[2025-11-12T22:20:01.875+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO CodeGenerator: Code generated in 11.223189 ms
[2025-11-12T22:20:01.877+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 225.0 KiB, free 422.4 MiB)
[2025-11-12T22:20:01.881+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 38.2 KiB, free 422.3 MiB)
[2025-11-12T22:20:01.881+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on eb021f2c8a8b:35921 (size: 38.2 KiB, free: 423.4 MiB)
[2025-11-12T22:20:01.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 113 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:20:01.882+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:20:01.884+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Registering RDD 287 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 36
[2025-11-12T22:20:01.884+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Got map stage job 71 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:20:01.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Final stage: ShuffleMapStage 119 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:01.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:20:01.885+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:01.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[287] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:01.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 51.5 KiB, free 422.3 MiB)
[2025-11-12T22:20:01.886+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 422.3 MiB)
[2025-11-12T22:20:01.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on eb021f2c8a8b:35921 (size: 16.3 KiB, free: 423.4 MiB)
[2025-11-12T22:20:01.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:01.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[287] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:20:01.887+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Adding task set 119.0 with 2 tasks resource profile 0
[2025-11-12T22:20:01.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 106) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:20:01.892+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSetManager: Starting task 1.0 in stage 119.0 (TID 107) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:20:01.901+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.18.0.5:45133 (size: 16.3 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.901+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 172.18.0.5:40603 (size: 16.3 KiB, free: 434.2 MiB)
[2025-11-12T22:20:01.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO CodeGenerator: Code generated in 16.716427 ms
[2025-11-12T22:20:01.905+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Started reading broadcast variable 105 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:20:01.905+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Reading broadcast variable 105 took 0 ms
[2025-11-12T22:20:01.908+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Started reading broadcast variable 111 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:20:01.908+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Reading broadcast variable 111 took 0 ms
[2025-11-12T22:20:01.916+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO CodeGenerator: Code generated in 5.259428 ms
[2025-11-12T22:20:01.918+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 221.3 KiB, free 422.0 MiB)
[2025-11-12T22:20:01.923+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 422.0 MiB)
[2025-11-12T22:20:01.924+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 423.4 MiB)
[2025-11-12T22:20:01.924+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 115 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:20:01.925+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:20:01.941+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.18.0.5:40603 (size: 4.0 MiB, free: 430.2 MiB)
[2025-11-12T22:20:01.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 172.18.0.5:45133 (size: 4.0 MiB, free: 430.2 MiB)
[2025-11-12T22:20:01.943+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO CodeGenerator: Code generated in 10.085139 ms
[2025-11-12T22:20:01.945+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 221.3 KiB, free 421.8 MiB)
[2025-11-12T22:20:01.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_107_piece1 in memory on 172.18.0.5:45133 (size: 1049.4 KiB, free: 429.2 MiB)
[2025-11-12T22:20:01.949+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_107_piece1 in memory on 172.18.0.5:40603 (size: 1049.4 KiB, free: 429.2 MiB)
[2025-11-12T22:20:01.954+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 37.3 KiB, free 421.8 MiB)
[2025-11-12T22:20:01.954+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on eb021f2c8a8b:35921 (size: 37.3 KiB, free: 423.3 MiB)
[2025-11-12T22:20:01.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 116 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:20:01.955+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:20:01.966+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Registering RDD 296 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 37
[2025-11-12T22:20:01.967+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Got map stage job 72 (javaToPython at NativeMethodAccessorImpl.java:0) with 4 output partitions
[2025-11-12T22:20:01.967+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Final stage: ShuffleMapStage 120 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:01.968+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:20:01.968+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:01.969+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Submitting ShuffleMapStage 120 (MapPartitionsRDD[296] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:01.970+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Started reading broadcast variable 110 with 2 pieces (estimated total size 8.0 MiB)
[2025-11-12T22:20:01.970+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Reading broadcast variable 110 took 0 ms
[2025-11-12T22:20:01.971+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 119.2 KiB, free 421.6 MiB)
[2025-11-12T22:20:01.972+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 43.1 KiB, free 421.6 MiB)
[2025-11-12T22:20:01.972+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on eb021f2c8a8b:35921 (size: 43.1 KiB, free: 423.3 MiB)
[2025-11-12T22:20:01.973+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.18.0.5:40603 (size: 90.5 KiB, free: 429.1 MiB)
[2025-11-12T22:20:01.974+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:01.974+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 172.18.0.5:45133 (size: 90.5 KiB, free: 429.1 MiB)
[2025-11-12T22:20:01.974+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 120 (MapPartitionsRDD[296] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
[2025-11-12T22:20:01.975+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TaskSchedulerImpl: Adding task set 120.0 with 4 tasks resource profile 0
[2025-11-12T22:20:01.981+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.18.0.5:40603 (size: 56.1 KiB, free: 429.1 MiB)
[2025-11-12T22:20:01.986+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 172.18.0.5:45133 (size: 56.1 KiB, free: 429.1 MiB)
[2025-11-12T22:20:01.991+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.18.0.5:45133 (size: 38.2 KiB, free: 429.0 MiB)
[2025-11-12T22:20:01.992+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 172.18.0.5:40603 (size: 38.2 KiB, free: 429.0 MiB)
[2025-11-12T22:20:01.993+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Started reading broadcast variable 112 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:20:01.993+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:01 INFO TorrentBroadcast: Reading broadcast variable 112 took 0 ms
[2025-11-12T22:20:02.016+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO CodeGenerator: Code generated in 17.450559 ms
[2025-11-12T22:20:02.019+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 225.0 KiB, free 421.4 MiB)
[2025-11-12T22:20:02.024+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 421.3 MiB)
[2025-11-12T22:20:02.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on eb021f2c8a8b:35921 (size: 38.3 KiB, free: 423.2 MiB)
[2025-11-12T22:20:02.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO SparkContext: Created broadcast 118 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:20:02.025+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:20:02.029+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Registering RDD 300 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 38
[2025-11-12T22:20:02.030+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Got map stage job 73 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:20:02.030+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Final stage: ShuffleMapStage 121 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:02.031+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:20:02.031+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:02.032+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[300] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:02.032+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 51.5 KiB, free 421.3 MiB)
[2025-11-12T22:20:02.033+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO TorrentBroadcast: Started reading broadcast variable 107 with 2 pieces (estimated total size 8.0 MiB)
[2025-11-12T22:20:02.033+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO TorrentBroadcast: Reading broadcast variable 107 took 0 ms
[2025-11-12T22:20:02.033+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 421.3 MiB)
[2025-11-12T22:20:02.033+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on eb021f2c8a8b:35921 (size: 16.3 KiB, free: 423.2 MiB)
[2025-11-12T22:20:02.034+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:02.034+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[300] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:20:02.034+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO TaskSchedulerImpl: Adding task set 121.0 with 2 tasks resource profile 0
[2025-11-12T22:20:02.068+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO CodeGenerator: Code generated in 14.597435 ms
[2025-11-12T22:20:02.070+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 222.7 KiB, free 421.1 MiB)
[2025-11-12T22:20:02.076+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 421.0 MiB)
[2025-11-12T22:20:02.077+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on eb021f2c8a8b:35921 (size: 37.8 KiB, free: 423.2 MiB)
[2025-11-12T22:20:02.078+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO SparkContext: Created broadcast 120 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:20:02.079+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:20:02.082+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Registering RDD 304 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 39
[2025-11-12T22:20:02.083+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Got map stage job 74 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:20:02.083+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Final stage: ShuffleMapStage 122 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:02.084+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:20:02.090+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:02.090+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[304] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:02.091+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 37.7 KiB, free 421.0 MiB)
[2025-11-12T22:20:02.091+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 421.0 MiB)
[2025-11-12T22:20:02.091+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on eb021f2c8a8b:35921 (size: 13.4 KiB, free: 423.2 MiB)
[2025-11-12T22:20:02.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:02.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[304] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:20:02.092+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO TaskSchedulerImpl: Adding task set 122.0 with 2 tasks resource profile 0
[2025-11-12T22:20:02.100+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO CodeGenerator: Code generated in 10.216045 ms
[2025-11-12T22:20:02.101+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 222.7 KiB, free 420.8 MiB)
[2025-11-12T22:20:02.107+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 37.8 KiB, free 420.7 MiB)
[2025-11-12T22:20:02.107+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on eb021f2c8a8b:35921 (size: 37.8 KiB, free: 423.1 MiB)
[2025-11-12T22:20:02.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO SparkContext: Created broadcast 122 from javaToPython at NativeMethodAccessorImpl.java:0
[2025-11-12T22:20:02.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 29243978 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-12T22:20:02.110+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Registering RDD 308 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 40
[2025-11-12T22:20:02.110+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Got map stage job 75 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:20:02.110+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Final stage: ShuffleMapStage 123 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:02.111+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Parents of final stage: List()
[2025-11-12T22:20:02.111+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:02.111+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[308] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:02.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 37.7 KiB, free 420.7 MiB)
[2025-11-12T22:20:02.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 420.7 MiB)
[2025-11-12T22:20:02.112+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on eb021f2c8a8b:35921 (size: 13.5 KiB, free: 423.1 MiB)
[2025-11-12T22:20:02.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:02.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[308] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:20:02.113+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:02 INFO TaskSchedulerImpl: Adding task set 123.0 with 2 tasks resource profile 0
[2025-11-12T22:20:06.650+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:06 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 108) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:20:06.653+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:06 INFO TaskSetManager: Finished task 1.0 in stage 119.0 (TID 107) in 4758 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:20:06.655+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:06 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.18.0.5:40603 (size: 43.1 KiB, free: 429.0 MiB)
[2025-11-12T22:20:06.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:06 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.18.0.5:40603 (size: 47.0 KiB, free: 428.9 MiB)
[2025-11-12T22:20:06.701+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:06 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 428.9 MiB)
[2025-11-12T22:20:07.946+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:07 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 109) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:20:07.947+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:07 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 108) in 1297 ms on 172.18.0.5 (executor 1) (1/4)
[2025-11-12T22:20:09.287+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 110) (172.18.0.5, executor 1, partition 2, PROCESS_LOCAL, 10903 bytes)
[2025-11-12T22:20:09.288+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 109) in 1343 ms on 172.18.0.5 (executor 1) (2/4)
[2025-11-12T22:20:09.305+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.18.0.5:40603 (size: 37.3 KiB, free: 428.9 MiB)
[2025-11-12T22:20:09.625+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 111) (172.18.0.5, executor 0, partition 3, PROCESS_LOCAL, 11069 bytes)
[2025-11-12T22:20:09.626+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 106) in 7734 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:20:09.627+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool
[2025-11-12T22:20:09.627+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO DAGScheduler: ShuffleMapStage 119 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 7.742 s
[2025-11-12T22:20:09.628+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:09.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO DAGScheduler: running: Set(ShuffleMapStage 121, ShuffleMapStage 122, ShuffleMapStage 123, ShuffleMapStage 120)
[2025-11-12T22:20:09.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:09.629+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:09.632+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 172.18.0.5:45133 (size: 43.1 KiB, free: 429.0 MiB)
[2025-11-12T22:20:09.652+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 172.18.0.5:45133 (size: 47.0 KiB, free: 428.9 MiB)
[2025-11-12T22:20:09.679+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:09 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 172.18.0.5:45133 (size: 37.3 KiB, free: 428.9 MiB)
[2025-11-12T22:20:10.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:10 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 112) (172.18.0.5, executor 1, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:20:10.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:10 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 110) in 1376 ms on 172.18.0.5 (executor 1) (3/4)
[2025-11-12T22:20:10.667+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:10 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.18.0.5:40603 (size: 16.3 KiB, free: 428.9 MiB)
[2025-11-12T22:20:10.685+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:10 INFO BlockManagerInfo: Added broadcast_110_piece1 in memory on 172.18.0.5:40603 (size: 1055.1 KiB, free: 427.8 MiB)
[2025-11-12T22:20:10.692+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:10 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.18.0.5:40603 (size: 4.0 MiB, free: 423.8 MiB)
[2025-11-12T22:20:10.709+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:10 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.18.0.5:40603 (size: 38.3 KiB, free: 423.8 MiB)
[2025-11-12T22:20:11.201+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO TaskSetManager: Starting task 1.0 in stage 121.0 (TID 113) (172.18.0.5, executor 0, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:20:11.201+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 111) in 1576 ms on 172.18.0.5 (executor 0) (4/4)
[2025-11-12T22:20:11.202+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool
[2025-11-12T22:20:11.202+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: ShuffleMapStage 120 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 9.234 s
[2025-11-12T22:20:11.203+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:11.203+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: running: Set(ShuffleMapStage 121, ShuffleMapStage 122, ShuffleMapStage 123)
[2025-11-12T22:20:11.203+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:11.203+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:11.207+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 172.18.0.5:45133 (size: 16.3 KiB, free: 428.9 MiB)
[2025-11-12T22:20:11.237+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO BlockManagerInfo: Added broadcast_110_piece1 in memory on 172.18.0.5:45133 (size: 1055.1 KiB, free: 427.9 MiB)
[2025-11-12T22:20:11.245+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 172.18.0.5:45133 (size: 4.0 MiB, free: 423.9 MiB)
[2025-11-12T22:20:11.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:11.265+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:11.266+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:11.268+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:11.268+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 172.18.0.5:45133 (size: 38.3 KiB, free: 423.8 MiB)
[2025-11-12T22:20:11.273+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:11.274+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO ShufflePartitionsUtil: For shuffle(37), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:11.275+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:20:11.290+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO CodeGenerator: Code generated in 12.548044 ms
[2025-11-12T22:20:11.296+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: Registering RDD 312 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 41
[2025-11-12T22:20:11.297+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: Got map stage job 76 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:20:11.297+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: Final stage: ShuffleMapStage 125 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:11.297+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)
[2025-11-12T22:20:11.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:11.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: Submitting ShuffleMapStage 125 (MapPartitionsRDD[312] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:11.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 132.1 KiB, free 420.5 MiB)
[2025-11-12T22:20:11.300+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 48.0 KiB, free 420.5 MiB)
[2025-11-12T22:20:11.301+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on eb021f2c8a8b:35921 (size: 48.0 KiB, free: 423.1 MiB)
[2025-11-12T22:20:11.301+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:11.301+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 125 (MapPartitionsRDD[312] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:20:11.302+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:11 INFO TaskSchedulerImpl: Adding task set 125.0 with 1 tasks resource profile 0
[2025-11-12T22:20:16.643+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:16 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 114) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:20:16.644+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:16 INFO TaskSetManager: Finished task 1.0 in stage 121.0 (TID 113) in 5443 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:20:16.648+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:16 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.18.0.5:45133 (size: 13.4 KiB, free: 423.8 MiB)
[2025-11-12T22:20:16.679+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:16 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.18.0.5:45133 (size: 37.8 KiB, free: 423.8 MiB)
[2025-11-12T22:20:19.117+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:19 INFO TaskSetManager: Starting task 1.0 in stage 122.0 (TID 115) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:20:19.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:19 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 112) in 8456 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:20:19.119+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:19 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool
[2025-11-12T22:20:19.120+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:19 INFO DAGScheduler: ShuffleMapStage 121 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 17.088 s
[2025-11-12T22:20:19.120+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:19 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:19.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:19 INFO DAGScheduler: running: Set(ShuffleMapStage 125, ShuffleMapStage 122, ShuffleMapStage 123)
[2025-11-12T22:20:19.121+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:19 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:19.122+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:19 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:19.125+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:19 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 172.18.0.5:40603 (size: 13.4 KiB, free: 423.8 MiB)
[2025-11-12T22:20:19.159+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:19 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 172.18.0.5:40603 (size: 37.8 KiB, free: 423.7 MiB)
[2025-11-12T22:20:24.103+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 116) (172.18.0.5, executor 0, partition 0, PROCESS_LOCAL, 10794 bytes)
[2025-11-12T22:20:24.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 114) in 7462 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:20:24.109+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.18.0.5:45133 (size: 13.5 KiB, free: 423.8 MiB)
[2025-11-12T22:20:24.148+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.18.0.5:45133 (size: 37.8 KiB, free: 423.7 MiB)
[2025-11-12T22:20:24.450+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 117) (172.18.0.5, executor 1, partition 1, PROCESS_LOCAL, 10960 bytes)
[2025-11-12T22:20:24.451+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO TaskSetManager: Finished task 1.0 in stage 122.0 (TID 115) in 5333 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:20:24.451+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool
[2025-11-12T22:20:24.452+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO DAGScheduler: ShuffleMapStage 122 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 22.368 s
[2025-11-12T22:20:24.452+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:24.453+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO DAGScheduler: running: Set(ShuffleMapStage 125, ShuffleMapStage 123)
[2025-11-12T22:20:24.453+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:24.453+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:24.457+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 172.18.0.5:40603 (size: 13.5 KiB, free: 423.7 MiB)
[2025-11-12T22:20:24.475+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:24 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 172.18.0.5:40603 (size: 37.8 KiB, free: 423.7 MiB)
[2025-11-12T22:20:29.883+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:29 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 118) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:20:29.883+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:29 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 117) in 5433 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:20:29.889+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:29 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 172.18.0.5:40603 (size: 48.0 KiB, free: 423.6 MiB)
[2025-11-12T22:20:29.895+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:29 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to 172.18.0.5:34292
[2025-11-12T22:20:30.063+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 118) in 181 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:20:30.064+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool
[2025-11-12T22:20:30.065+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: ShuffleMapStage 125 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 18.767 s
[2025-11-12T22:20:30.065+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:30.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: running: Set(ShuffleMapStage 123)
[2025-11-12T22:20:30.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:30.066+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:30.105+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO ShufflePartitionsUtil: For shuffle(41), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:30.106+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO ShufflePartitionsUtil: For shuffle(41), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:30.107+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO ShufflePartitionsUtil: For shuffle(41), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:30.108+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO ShufflePartitionsUtil: For shuffle(41), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:30.116+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO CodeGenerator: Code generated in 3.805556 ms
[2025-11-12T22:20:30.129+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:30.130+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Got job 77 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:20:30.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Final stage: ResultStage 128 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:20:30.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)
[2025-11-12T22:20:30.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:30.132+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[316] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:20:30.137+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 117.6 KiB, free 420.4 MiB)
[2025-11-12T22:20:30.137+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 43.1 KiB, free 420.3 MiB)
[2025-11-12T22:20:30.138+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on eb021f2c8a8b:35921 (size: 43.1 KiB, free: 423.0 MiB)
[2025-11-12T22:20:30.138+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:30.139+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 128 (MapPartitionsRDD[316] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:20:30.139+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks resource profile 0
[2025-11-12T22:20:30.139+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 119) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:30.145+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 172.18.0.5:40603 (size: 43.1 KiB, free: 423.6 MiB)
[2025-11-12T22:20:30.152+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to 172.18.0.5:34292
[2025-11-12T22:20:30.212+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 119) in 72 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:20:30.212+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool
[2025-11-12T22:20:30.217+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: ResultStage 128 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.080 s
[2025-11-12T22:20:30.252+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:20:30.282+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 128: Stage finished
[2025-11-12T22:20:30.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Job 77 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.083710 s
[2025-11-12T22:20:30.309+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_124_piece0 on eb021f2c8a8b:35921 in memory (size: 48.0 KiB, free: 423.1 MiB)
[2025-11-12T22:20:30.320+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 172.18.0.5:40603 in memory (size: 48.0 KiB, free: 423.6 MiB)
[2025-11-12T22:20:30.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 158.7 KiB, free 420.4 MiB)
[2025-11-12T22:20:30.335+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on eb021f2c8a8b:35921 (size: 158.7 KiB, free: 422.9 MiB)
[2025-11-12T22:20:30.337+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO SparkContext: Created broadcast 126 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:30.338+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_114_piece0 on eb021f2c8a8b:35921 in memory (size: 16.3 KiB, free: 423.0 MiB)
[2025-11-12T22:20:30.338+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.18.0.5:40603 in memory (size: 16.3 KiB, free: 423.7 MiB)
[2025-11-12T22:20:30.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 172.18.0.5:45133 in memory (size: 16.3 KiB, free: 423.7 MiB)
[2025-11-12T22:20:30.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_121_piece0 on eb021f2c8a8b:35921 in memory (size: 13.4 KiB, free: 423.0 MiB)
[2025-11-12T22:20:30.340+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 172.18.0.5:40603 in memory (size: 13.4 KiB, free: 423.7 MiB)
[2025-11-12T22:20:30.340+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 172.18.0.5:45133 in memory (size: 13.4 KiB, free: 423.8 MiB)
[2025-11-12T22:20:30.341+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_119_piece0 on eb021f2c8a8b:35921 in memory (size: 16.3 KiB, free: 423.0 MiB)
[2025-11-12T22:20:30.341+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.18.0.5:40603 in memory (size: 16.3 KiB, free: 423.7 MiB)
[2025-11-12T22:20:30.342+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 172.18.0.5:45133 in memory (size: 16.3 KiB, free: 423.8 MiB)
[2025-11-12T22:20:30.342+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_117_piece0 on eb021f2c8a8b:35921 in memory (size: 43.1 KiB, free: 423.0 MiB)
[2025-11-12T22:20:30.343+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 172.18.0.5:40603 in memory (size: 43.1 KiB, free: 423.7 MiB)
[2025-11-12T22:20:30.343+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 172.18.0.5:45133 in memory (size: 43.1 KiB, free: 423.8 MiB)
[2025-11-12T22:20:30.344+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_125_piece0 on eb021f2c8a8b:35921 in memory (size: 43.1 KiB, free: 423.1 MiB)
[2025-11-12T22:20:30.345+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 172.18.0.5:40603 in memory (size: 43.1 KiB, free: 423.8 MiB)
[2025-11-12T22:20:30.345+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO ShufflePartitionsUtil: For shuffle(36), advisory target size: 67108864, actual target size 49230999, minimum partition size: 1048576
[2025-11-12T22:20:30.346+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO ShufflePartitionsUtil: For shuffle(38), advisory target size: 67108864, actual target size 57336303, minimum partition size: 1048576
[2025-11-12T22:20:30.346+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO ShufflePartitionsUtil: For shuffle(36), advisory target size: 67108864, actual target size 49230999, minimum partition size: 1048576
[2025-11-12T22:20:30.347+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO ShufflePartitionsUtil: For shuffle(38), advisory target size: 67108864, actual target size 57336303, minimum partition size: 1048576
[2025-11-12T22:20:30.361+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO CodeGenerator: Code generated in 9.145575 ms
[2025-11-12T22:20:30.396+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO CodeGenerator: Code generated in 23.571068 ms
[2025-11-12T22:20:30.420+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO CodeGenerator: Code generated in 10.130516 ms
[2025-11-12T22:20:30.435+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Registering RDD 324 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 42
[2025-11-12T22:20:30.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Got map stage job 78 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:20:30.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Final stage: ShuffleMapStage 131 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:30.436+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 129, ShuffleMapStage 130)
[2025-11-12T22:20:30.437+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:30.437+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Submitting ShuffleMapStage 131 (MapPartitionsRDD[324] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:30.443+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 309.3 KiB, free 420.6 MiB)
[2025-11-12T22:20:30.444+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 97.7 KiB, free 420.5 MiB)
[2025-11-12T22:20:30.445+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on eb021f2c8a8b:35921 (size: 97.7 KiB, free: 423.0 MiB)
[2025-11-12T22:20:30.445+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:30.446+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[324] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:20:30.446+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO TaskSchedulerImpl: Adding task set 131.0 with 2 tasks resource profile 0
[2025-11-12T22:20:30.446+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 120) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10247 bytes)
[2025-11-12T22:20:30.452+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 172.18.0.5:40603 (size: 97.7 KiB, free: 423.7 MiB)
[2025-11-12T22:20:30.461+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to 172.18.0.5:34292
[2025-11-12T22:20:30.482+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:30 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 172.18.0.5:40603 (size: 158.7 KiB, free: 423.5 MiB)
[2025-11-12T22:20:31.800+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:31 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 121) (172.18.0.5, executor 1, partition 1, NODE_LOCAL, 10247 bytes)
[2025-11-12T22:20:31.800+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:31 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 120) in 1354 ms on 172.18.0.5 (executor 1) (1/2)
[2025-11-12T22:20:31.809+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to 172.18.0.5:34292
[2025-11-12T22:20:32.793+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 116) in 8689 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:20:32.793+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool
[2025-11-12T22:20:32.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: ShuffleMapStage 123 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 30.683 s
[2025-11-12T22:20:32.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:32.794+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: running: Set(ShuffleMapStage 131)
[2025-11-12T22:20:32.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:32.795+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:32.824+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO ShufflePartitionsUtil: For shuffle(39), advisory target size: 67108864, actual target size 20897623, minimum partition size: 1048576
[2025-11-12T22:20:32.825+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO ShufflePartitionsUtil: For shuffle(40), advisory target size: 67108864, actual target size 22766139, minimum partition size: 1048576
[2025-11-12T22:20:32.826+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO ShufflePartitionsUtil: For shuffle(39), advisory target size: 67108864, actual target size 20897623, minimum partition size: 1048576
[2025-11-12T22:20:32.827+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO ShufflePartitionsUtil: For shuffle(40), advisory target size: 67108864, actual target size 22766139, minimum partition size: 1048576
[2025-11-12T22:20:32.833+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO CodeGenerator: Code generated in 4.014365 ms
[2025-11-12T22:20:32.844+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO CodeGenerator: Code generated in 6.766178 ms
[2025-11-12T22:20:32.855+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO CodeGenerator: Code generated in 6.303259 ms
[2025-11-12T22:20:32.862+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: Registering RDD 332 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 43
[2025-11-12T22:20:32.863+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: Got map stage job 79 (javaToPython at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2025-11-12T22:20:32.863+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: Final stage: ShuffleMapStage 134 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:32.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132, ShuffleMapStage 133)
[2025-11-12T22:20:32.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:32.864+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[332] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:32.867+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 258.0 KiB, free 420.2 MiB)
[2025-11-12T22:20:32.868+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 85.7 KiB, free 420.1 MiB)
[2025-11-12T22:20:32.868+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on eb021f2c8a8b:35921 (size: 85.7 KiB, free: 422.9 MiB)
[2025-11-12T22:20:32.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:32.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[332] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:20:32.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO TaskSchedulerImpl: Adding task set 134.0 with 2 tasks resource profile 0
[2025-11-12T22:20:32.869+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 122) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10247 bytes)
[2025-11-12T22:20:32.875+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 172.18.0.5:45133 (size: 85.7 KiB, free: 423.7 MiB)
[2025-11-12T22:20:32.883+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to 172.18.0.5:34294
[2025-11-12T22:20:32.899+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:32 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 172.18.0.5:45133 (size: 158.7 KiB, free: 423.6 MiB)
[2025-11-12T22:20:33.323+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 123) (172.18.0.5, executor 1, partition 1, NODE_LOCAL, 10247 bytes)
[2025-11-12T22:20:33.324+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 121) in 1524 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:20:33.324+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool
[2025-11-12T22:20:33.325+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: ShuffleMapStage 131 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 2.887 s
[2025-11-12T22:20:33.325+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:33.326+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: running: Set(ShuffleMapStage 134)
[2025-11-12T22:20:33.326+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:33.326+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:33.329+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 172.18.0.5:40603 (size: 85.7 KiB, free: 423.4 MiB)
[2025-11-12T22:20:33.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to 172.18.0.5:34292
[2025-11-12T22:20:33.358+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO ShufflePartitionsUtil: For shuffle(42), advisory target size: 67108864, actual target size 1273352, minimum partition size: 1048576
[2025-11-12T22:20:33.360+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO ShufflePartitionsUtil: For shuffle(42), advisory target size: 67108864, actual target size 1273352, minimum partition size: 1048576
[2025-11-12T22:20:33.371+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO CodeGenerator: Code generated in 5.299427 ms
[2025-11-12T22:20:33.378+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO CodeGenerator: Code generated in 4.20428 ms
[2025-11-12T22:20:33.403+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:33.404+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Got job 80 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 2 output partitions
[2025-11-12T22:20:33.404+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Final stage: ResultStage 138 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:20:33.405+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 137)
[2025-11-12T22:20:33.405+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:33.406+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[338] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:20:33.411+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 281.0 KiB, free 419.8 MiB)
[2025-11-12T22:20:33.412+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 87.7 KiB, free 419.8 MiB)
[2025-11-12T22:20:33.412+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on eb021f2c8a8b:35921 (size: 87.7 KiB, free: 422.8 MiB)
[2025-11-12T22:20:33.412+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:33.413+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 138 (MapPartitionsRDD[338] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0, 1))
[2025-11-12T22:20:33.413+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSchedulerImpl: Adding task set 138.0 with 2 tasks resource profile 0
[2025-11-12T22:20:33.590+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 124) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:33.591+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 122) in 721 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:20:33.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 172.18.0.5:45133 (size: 87.7 KiB, free: 423.5 MiB)
[2025-11-12T22:20:33.606+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to 172.18.0.5:34294
[2025-11-12T22:20:33.662+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSetManager: Starting task 1.0 in stage 138.0 (TID 125) (172.18.0.5, executor 0, partition 1, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:33.663+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 124) in 72 ms on 172.18.0.5 (executor 0) (1/2)
[2025-11-12T22:20:33.705+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSetManager: Finished task 1.0 in stage 138.0 (TID 125) in 42 ms on 172.18.0.5 (executor 0) (2/2)
[2025-11-12T22:20:33.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool
[2025-11-12T22:20:33.706+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: ResultStage 138 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.300 s
[2025-11-12T22:20:33.707+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:20:33.707+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 138: Stage finished
[2025-11-12T22:20:33.707+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Job 80 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.302630 s
[2025-11-12T22:20:33.718+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 1028.5 KiB, free 418.8 MiB)
[2025-11-12T22:20:33.719+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on eb021f2c8a8b:35921 (size: 1028.5 KiB, free: 421.8 MiB)
[2025-11-12T22:20:33.719+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO SparkContext: Created broadcast 130 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:33.735+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO ShufflePartitionsUtil: For shuffle(35), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:33.767+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO CodeGenerator: Code generated in 17.555052 ms
[2025-11-12T22:20:33.783+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Registering RDD 342 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 44
[2025-11-12T22:20:33.784+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Got map stage job 81 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:20:33.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Final stage: ShuffleMapStage 141 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:33.785+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 140)
[2025-11-12T22:20:33.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:33.786+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Submitting ShuffleMapStage 141 (MapPartitionsRDD[342] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:33.796+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 416.6 KiB, free 418.4 MiB)
[2025-11-12T22:20:33.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 126.7 KiB, free 418.2 MiB)
[2025-11-12T22:20:33.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on eb021f2c8a8b:35921 (size: 126.7 KiB, free: 421.7 MiB)
[2025-11-12T22:20:33.798+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:33.799+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 141 (MapPartitionsRDD[342] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:20:33.799+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks resource profile 0
[2025-11-12T22:20:33.800+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 126) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10141 bytes)
[2025-11-12T22:20:33.807+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 172.18.0.5:45133 (size: 126.7 KiB, free: 423.4 MiB)
[2025-11-12T22:20:33.829+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to 172.18.0.5:34294
[2025-11-12T22:20:33.874+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:33 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 172.18.0.5:45133 (size: 1028.5 KiB, free: 422.4 MiB)
[2025-11-12T22:20:34.051+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 126) in 251 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:20:34.051+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool
[2025-11-12T22:20:34.052+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: ShuffleMapStage 141 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 0.267 s
[2025-11-12T22:20:34.053+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:34.053+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: running: Set(ShuffleMapStage 134)
[2025-11-12T22:20:34.053+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:34.054+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:34.129+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 123) in 807 ms on 172.18.0.5 (executor 1) (2/2)
[2025-11-12T22:20:34.130+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool
[2025-11-12T22:20:34.130+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: ShuffleMapStage 134 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 1.266 s
[2025-11-12T22:20:34.130+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:34.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: running: Set()
[2025-11-12T22:20:34.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:34.131+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:34.142+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO ShufflePartitionsUtil: For shuffle(43), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:34.143+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO ShufflePartitionsUtil: For shuffle(43), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:34.149+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO CodeGenerator: Code generated in 3.007628 ms
[2025-11-12T22:20:34.154+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO CodeGenerator: Code generated in 3.537051 ms
[2025-11-12T22:20:34.176+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:34.177+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Got job 82 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:20:34.177+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Final stage: ResultStage 145 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:20:34.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 144)
[2025-11-12T22:20:34.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:34.178+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[348] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:20:34.183+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 240.9 KiB, free 418.0 MiB)
[2025-11-12T22:20:34.184+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 80.6 KiB, free 417.9 MiB)
[2025-11-12T22:20:34.185+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on eb021f2c8a8b:35921 (size: 80.6 KiB, free: 421.6 MiB)
[2025-11-12T22:20:34.185+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:34.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[348] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:20:34.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks resource profile 0
[2025-11-12T22:20:34.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 127) (172.18.0.5, executor 1, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:34.192+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 172.18.0.5:40603 (size: 80.6 KiB, free: 423.4 MiB)
[2025-11-12T22:20:34.199+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to 172.18.0.5:34292
[2025-11-12T22:20:34.255+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 127) in 68 ms on 172.18.0.5 (executor 1) (1/1)
[2025-11-12T22:20:34.256+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool
[2025-11-12T22:20:34.258+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: ResultStage 145 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.078 s
[2025-11-12T22:20:34.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:20:34.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 145: Stage finished
[2025-11-12T22:20:34.263+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Job 82 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.080101 s
[2025-11-12T22:20:34.264+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 350.2 KiB, free 417.6 MiB)
[2025-11-12T22:20:34.264+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on eb021f2c8a8b:35921 (size: 350.2 KiB, free: 421.3 MiB)
[2025-11-12T22:20:34.264+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO SparkContext: Created broadcast 133 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:34.281+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_131_piece0 on eb021f2c8a8b:35921 in memory (size: 126.7 KiB, free: 421.4 MiB)
[2025-11-12T22:20:34.282+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:34.282+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 172.18.0.5:45133 in memory (size: 126.7 KiB, free: 422.5 MiB)
[2025-11-12T22:20:34.284+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_132_piece0 on eb021f2c8a8b:35921 in memory (size: 80.6 KiB, free: 421.5 MiB)
[2025-11-12T22:20:34.285+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TorrentBroadcast: Started reading broadcast variable 133 with 1 pieces (estimated total size 4.0 MiB)
[2025-11-12T22:20:34.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TorrentBroadcast: Reading broadcast variable 133 took 0 ms
[2025-11-12T22:20:34.286+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 172.18.0.5:40603 in memory (size: 80.6 KiB, free: 423.4 MiB)
[2025-11-12T22:20:34.288+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_127_piece0 on eb021f2c8a8b:35921 in memory (size: 97.7 KiB, free: 421.5 MiB)
[2025-11-12T22:20:34.289+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 172.18.0.5:40603 in memory (size: 97.7 KiB, free: 423.5 MiB)
[2025-11-12T22:20:34.291+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_128_piece0 on eb021f2c8a8b:35921 in memory (size: 85.7 KiB, free: 421.6 MiB)
[2025-11-12T22:20:34.292+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 172.18.0.5:40603 in memory (size: 85.7 KiB, free: 423.6 MiB)
[2025-11-12T22:20:34.293+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 172.18.0.5:45133 in memory (size: 85.7 KiB, free: 422.6 MiB)
[2025-11-12T22:20:34.295+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_129_piece0 on eb021f2c8a8b:35921 in memory (size: 87.7 KiB, free: 421.7 MiB)
[2025-11-12T22:20:34.296+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 172.18.0.5:45133 in memory (size: 87.7 KiB, free: 422.7 MiB)
[2025-11-12T22:20:34.298+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_123_piece0 on eb021f2c8a8b:35921 in memory (size: 13.5 KiB, free: 421.7 MiB)
[2025-11-12T22:20:34.299+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 172.18.0.5:40603 in memory (size: 13.5 KiB, free: 423.6 MiB)
[2025-11-12T22:20:34.299+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 172.18.0.5:45133 in memory (size: 13.5 KiB, free: 422.7 MiB)
[2025-11-12T22:20:34.323+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO CodeGenerator: Code generated in 26.427432 ms
[2025-11-12T22:20:34.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Registering RDD 351 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 45
[2025-11-12T22:20:34.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Got map stage job 83 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:20:34.332+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Final stage: ShuffleMapStage 149 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:34.333+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 148)
[2025-11-12T22:20:34.333+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:34.333+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Submitting ShuffleMapStage 149 (MapPartitionsRDD[351] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:34.337+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 369.4 KiB, free 419.2 MiB)
[2025-11-12T22:20:34.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 118.4 KiB, free 419.1 MiB)
[2025-11-12T22:20:34.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on eb021f2c8a8b:35921 (size: 118.4 KiB, free: 421.6 MiB)
[2025-11-12T22:20:34.339+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:34.340+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 149 (MapPartitionsRDD[351] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:20:34.340+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks resource profile 0
[2025-11-12T22:20:34.340+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 128) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10141 bytes)
[2025-11-12T22:20:34.345+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 172.18.0.5:45133 (size: 118.4 KiB, free: 422.5 MiB)
[2025-11-12T22:20:34.354+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to 172.18.0.5:34294
[2025-11-12T22:20:34.386+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 172.18.0.5:45133 (size: 350.2 KiB, free: 422.2 MiB)
[2025-11-12T22:20:34.439+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 128) in 99 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:20:34.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool
[2025-11-12T22:20:34.440+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: ShuffleMapStage 149 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 0.108 s
[2025-11-12T22:20:34.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:34.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: running: Set()
[2025-11-12T22:20:34.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:34.441+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:34.449+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO ShufflePartitionsUtil: For shuffle(45), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:34.456+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO CodeGenerator: Code generated in 2.881323 ms
[2025-11-12T22:20:34.461+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-11-12T22:20:34.518+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO CodeGenerator: Code generated in 35.498521 ms
[2025-11-12T22:20:34.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:34.580+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Got job 84 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2025-11-12T22:20:34.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Final stage: ResultStage 154 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2025-11-12T22:20:34.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 153)
[2025-11-12T22:20:34.581+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:34.582+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Submitting ResultStage 154 (MapPartitionsRDD[357] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2025-11-12T22:20:34.592+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 490.6 KiB, free 418.6 MiB)
[2025-11-12T22:20:34.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 152.1 KiB, free 418.5 MiB)
[2025-11-12T22:20:34.594+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on eb021f2c8a8b:35921 (size: 152.1 KiB, free: 421.5 MiB)
[2025-11-12T22:20:34.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:34.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[357] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:20:34.595+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks resource profile 0
[2025-11-12T22:20:34.596+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 129) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:34.603+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 172.18.0.5:45133 (size: 152.1 KiB, free: 422.1 MiB)
[2025-11-12T22:20:34.958+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:34 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to 172.18.0.5:34294
[2025-11-12T22:20:35.374+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:35 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 172.18.0.5:45133 (size: 569.7 KiB, free: 421.5 MiB)
[2025-11-12T22:20:35.389+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:35 INFO BlockManagerInfo: Added broadcast_84_python on disk on 172.18.0.5:45133 (size: 1071.5 KiB)
[2025-11-12T22:20:36.938+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 129) in 2343 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:20:36.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool
[2025-11-12T22:20:36.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO DAGScheduler: ResultStage 154 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 2.357 s
[2025-11-12T22:20:36.939+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:20:36.940+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 154: Stage finished
[2025-11-12T22:20:36.940+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO DAGScheduler: Job 84 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 2.359580 s
[2025-11-12T22:20:36.942+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 785.0 B, free 418.5 MiB)
[2025-11-12T22:20:36.943+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on eb021f2c8a8b:35921 (size: 785.0 B, free: 421.5 MiB)
[2025-11-12T22:20:36.943+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO SparkContext: Created broadcast 136 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2025-11-12T22:20:36.948+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO ShufflePartitionsUtil: For shuffle(44), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:36.977+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO CodeGenerator: Code generated in 20.31017 ms
[2025-11-12T22:20:36.981+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO DAGScheduler: Registering RDD 362 (javaToPython at NativeMethodAccessorImpl.java:0) as input to shuffle 46
[2025-11-12T22:20:36.981+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO DAGScheduler: Got map stage job 85 (javaToPython at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-12T22:20:36.981+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO DAGScheduler: Final stage: ShuffleMapStage 158 (javaToPython at NativeMethodAccessorImpl.java:0)
[2025-11-12T22:20:36.982+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 157)
[2025-11-12T22:20:36.982+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:36.982+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO DAGScheduler: Submitting ShuffleMapStage 158 (MapPartitionsRDD[362] at javaToPython at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-12T22:20:36.990+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 526.6 KiB, free 417.9 MiB)
[2025-11-12T22:20:36.991+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 151.2 KiB, free 417.8 MiB)
[2025-11-12T22:20:36.992+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on eb021f2c8a8b:35921 (size: 151.2 KiB, free: 421.3 MiB)
[2025-11-12T22:20:36.992+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:36.993+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 158 (MapPartitionsRDD[362] at javaToPython at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:20:36.993+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO TaskSchedulerImpl: Adding task set 158.0 with 1 tasks resource profile 0
[2025-11-12T22:20:36.993+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 130) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10122 bytes)
[2025-11-12T22:20:36.998+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:36 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 172.18.0.5:45133 (size: 151.2 KiB, free: 421.4 MiB)
[2025-11-12T22:20:37.009+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to 172.18.0.5:34294
[2025-11-12T22:20:37.167+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 172.18.0.5:45133 (size: 785.0 B, free: 421.4 MiB)
[2025-11-12T22:20:37.186+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 130) in 193 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:20:37.187+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool
[2025-11-12T22:20:37.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: ShuffleMapStage 158 (javaToPython at NativeMethodAccessorImpl.java:0) finished in 0.206 s
[2025-11-12T22:20:37.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: looking for newly runnable stages
[2025-11-12T22:20:37.188+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: running: Set()
[2025-11-12T22:20:37.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: waiting: Set()
[2025-11-12T22:20:37.189+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: failed: Set()
[2025-11-12T22:20:37.190+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO ShufflePartitionsUtil: For shuffle(46), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-12T22:20:37.209+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO SparkContext: Starting job: foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883
[2025-11-12T22:20:37.210+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: Got job 86 (foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883) with 1 output partitions
[2025-11-12T22:20:37.210+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: Final stage: ResultStage 163 (foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883)
[2025-11-12T22:20:37.210+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 162)
[2025-11-12T22:20:37.211+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: Missing parents: List()
[2025-11-12T22:20:37.211+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: Submitting ResultStage 163 (PythonRDD[367] at foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883), which has no missing parents
[2025-11-12T22:20:37.212+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 27.5 KiB, free 417.8 MiB)
[2025-11-12T22:20:37.212+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 12.5 KiB, free 417.8 MiB)
[2025-11-12T22:20:37.212+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on eb021f2c8a8b:35921 (size: 12.5 KiB, free: 421.3 MiB)
[2025-11-12T22:20:37.213+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1585
[2025-11-12T22:20:37.213+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (PythonRDD[367] at foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883) (first 15 tasks are for partitions Vector(0))
[2025-11-12T22:20:37.213+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO TaskSchedulerImpl: Adding task set 163.0 with 1 tasks resource profile 0
[2025-11-12T22:20:37.214+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 131) (172.18.0.5, executor 0, partition 0, NODE_LOCAL, 10133 bytes)
[2025-11-12T22:20:37.220+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 172.18.0.5:45133 (size: 12.5 KiB, free: 421.3 MiB)
[2025-11-12T22:20:37.271+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to 172.18.0.5:34294
[2025-11-12T22:20:37.671+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 131) in 457 ms on 172.18.0.5 (executor 0) (1/1)
[2025-11-12T22:20:37.672+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool
[2025-11-12T22:20:37.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: ResultStage 163 (foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883) finished in 0.461 s
[2025-11-12T22:20:37.676+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-12T22:20:37.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 163: Stage finished
[2025-11-12T22:20:37.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO DAGScheduler: Job 86 finished: foreachPartition at /opt/airflow/jobs/spark_mongoNewMatches.py:883, took 0.463796 s
[2025-11-12T22:20:37.677+0000] {spark_submit.py:571} INFO - Executor-side pymongo: scheduled partitioned updates for basho_pages.id=202511
[2025-11-12T22:20:37.677+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-11-12T22:20:37.684+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO SparkUI: Stopped Spark web UI at http://eb021f2c8a8b:4040
[2025-11-12T22:20:37.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO StandaloneSchedulerBackend: Shutting down all executors
[2025-11-12T22:20:37.686+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Asking each executor to shut down
[2025-11-12T22:20:37.700+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-11-12T22:20:37.722+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO MemoryStore: MemoryStore cleared
[2025-11-12T22:20:37.724+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO BlockManager: BlockManager stopped
[2025-11-12T22:20:37.728+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-11-12T22:20:37.729+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-11-12T22:20:37.757+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:37 INFO SparkContext: Successfully stopped SparkContext
[2025-11-12T22:20:38.902+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:38 INFO ShutdownHookManager: Shutdown hook called
[2025-11-12T22:20:38.903+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-efd57fad-c442-4fb7-8520-f30b93603153
[2025-11-12T22:20:38.908+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-4e867b47-00f6-4c3b-b4d3-328d9247193b/pyspark-c1f51d65-10cf-430d-a280-f25eeb420584
[2025-11-12T22:20:38.917+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-4e867b47-00f6-4c3b-b4d3-328d9247193b
[2025-11-12T22:20:38.925+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:38 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2025-11-12T22:20:38.926+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:38 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2025-11-12T22:20:38.927+0000] {spark_submit.py:571} INFO - 25/11/12 22:20:38 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2025-11-12T22:20:39.169+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=sumo_data_pipeline, task_id=run_new_matches_mongo, execution_date=20251107T085511, start_date=20251112T221813, end_date=20251112T222039
[2025-11-12T22:20:39.199+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-11-12T22:20:39.216+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
